#!/usr/bin/env python3
"""
nnU-Net v2 Cross-Validation ã‚¨ãƒ©ãƒ¼ä¿®æ­£çµ±åˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
'n_splits=5 greater than the number of samples: n_samples=3' ã‚¨ãƒ©ãƒ¼ã‚’å®Œå…¨è§£æ±º
"""

import os
import sys
import subprocess
import json
from pathlib import Path
import argparse


class NnuNetCVErrorFixer:
    """nnU-Net v2 CV ã‚¨ãƒ©ãƒ¼ä¿®æ­£ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, dataset_id: int = 1, verbose: bool = True):
        self.dataset_id = dataset_id
        self.verbose = verbose
        self.dataset_name = f"Dataset{dataset_id:03d}_Vesuvius"
        
        # ç’°å¢ƒå¤‰æ•°ç¢ºèªãƒ»è¨­å®š
        self.setup_environment()
    
    def setup_environment(self):
        """nnU-Netç’°å¢ƒç¢ºèªãƒ»è¨­å®š"""
        required_vars = ['nnUNet_raw', 'nnUNet_preprocessed', 'nnUNet_results']
        
        for var in required_vars:
            if var not in os.environ:
                default_path = f"./nnUNet_data/{var.split('_')[1]}"
                os.environ[var] = default_path
                Path(default_path).mkdir(parents=True, exist_ok=True)
                
                if self.verbose:
                    print(f"ğŸ”§ ç’°å¢ƒå¤‰æ•°è¨­å®š: {var} = {default_path}")
    
    def diagnose_dataset(self) -> dict:
        """ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨ºæ–­"""
        if self.verbose:
            print("ğŸ” ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè¨ºæ–­ä¸­...")
        
        raw_path = Path(os.environ['nnUNet_raw'])
        dataset_path = raw_path / self.dataset_name
        
        diagnosis = {
            'dataset_exists': dataset_path.exists(),
            'num_samples': 0,
            'has_dataset_json': False,
            'issues': []
        }
        
        if not dataset_path.exists():
            diagnosis['issues'].append("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return diagnosis
        
        # dataset.jsonç¢ºèª
        json_path = dataset_path / "dataset.json"
        if json_path.exists():
            diagnosis['has_dataset_json'] = True
            
            try:
                with open(json_path, 'r') as f:
                    dataset_config = json.load(f)
                    diagnosis['num_samples'] = dataset_config.get('numTraining', 0)
                    
                    if diagnosis['num_samples'] < 5:
                        diagnosis['issues'].append(f"ã‚µãƒ³ãƒ—ãƒ«æ•°ä¸è¶³: {diagnosis['num_samples']} < 5")
                    
            except Exception as e:
                diagnosis['issues'].append(f"dataset.jsonèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            diagnosis['issues'].append("dataset.jsonãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        
        # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°ç¢ºèª
        images_dir = dataset_path / "imagesTr"
        if images_dir.exists():
            actual_files = len(list(images_dir.glob("*.nii.gz")) + list(images_dir.glob("*.npy")))
            if actual_files != diagnosis['num_samples']:
                diagnosis['issues'].append(f"ãƒ•ã‚¡ã‚¤ãƒ«æ•°ä¸ä¸€è‡´: å®Ÿéš›={actual_files}, JSON={diagnosis['num_samples']}")
        
        if self.verbose:
            print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {diagnosis['num_samples']}")
            print(f"   å•é¡Œæ•°: {len(diagnosis['issues'])}")
        
        return diagnosis
    
    def fix_dataset_json(self, diagnosis: dict) -> bool:
        """dataset.jsonä¿®æ­£"""
        if not diagnosis['dataset_exists']:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå­˜åœ¨ã—ãªã„ãŸã‚ä¿®æ­£ä¸å¯")
            return False
        
        dataset_path = Path(os.environ['nnUNet_raw']) / self.dataset_name
        json_path = dataset_path / "dataset.json"
        
        if not json_path.exists():
            print("âŒ dataset.jsonãŒå­˜åœ¨ã—ãªã„ãŸã‚ä¿®æ­£ä¸å¯")
            return False
        
        if self.verbose:
            print("ğŸ”§ dataset.jsonä¿®æ­£ä¸­...")
        
        try:
            with open(json_path, 'r') as f:
                config = json.load(f)
            
            num_samples = diagnosis['num_samples']
            
            # foldæ•°ã‚’å‹•çš„èª¿æ•´
            if num_samples < 5:
                optimal_folds = 1
                config['disable_cross_validation'] = True
            elif num_samples < 10:
                optimal_folds = min(3, num_samples)
                config['disable_cross_validation'] = False
            else:
                optimal_folds = 5
                config['disable_cross_validation'] = False
            
            # ã‚«ã‚¹ã‚¿ãƒ è¨­å®šè¿½åŠ 
            config['vesuvius_custom'] = {
                'optimal_folds': optimal_folds,
                'small_dataset_mode': num_samples < 10,
                'single_fold_mode': num_samples < 5,
                'original_samples': num_samples
            }
            
            # ä¿å­˜
            with open(json_path, 'w') as f:
                json.dump(config, f, indent=2)
            
            if self.verbose:
                print(f"âœ… dataset.jsonä¿®æ­£å®Œäº†")
                print(f"   æ¨å¥¨foldæ•°: {optimal_folds}")
                print(f"   CVç„¡åŠ¹åŒ–: {config.get('disable_cross_validation', False)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ dataset.jsonä¿®æ­£ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def generate_fixed_training_commands(self, num_samples: int) -> list:
        """ä¿®æ­£æ¸ˆã¿å­¦ç¿’ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆ"""
        commands = []
        
        # å‰å‡¦ç†ã‚³ãƒãƒ³ãƒ‰
        preprocess_cmd = [
            "nnUNetv2_plan_and_preprocess",
            "-d", str(self.dataset_id),
            "--verify_dataset_integrity"
        ]
        commands.append(("å‰å‡¦ç†", " ".join(preprocess_cmd)))
        
        # å­¦ç¿’ã‚³ãƒãƒ³ãƒ‰ï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ã«å¿œã˜ã¦èª¿æ•´ï¼‰
        if num_samples < 5:
            # å˜ä¸€foldå¼·åˆ¶
            train_cmd = [
                "nnUNetv2_train",
                str(self.dataset_id),
                "3d_fullres", 
                "0",
                "-tr", "VesuviusSingleFoldTrainer",
                "--disable_cross_validation",
                "--val_freq", "10",
                "--save_freq", "25"
            ]
            commands.append(("å­¦ç¿’ï¼ˆå˜ä¸€foldï¼‰", " ".join(train_cmd)))
            
        elif num_samples < 10:
            # 3-fold CV
            for fold in [0, 1, 2]:
                train_cmd = [
                    "nnUNetv2_train",
                    str(self.dataset_id),
                    "3d_fullres",
                    str(fold),
                    "-tr", "VesuviusCustomTrainer",
                    "--val_freq", "10"
                ]
                commands.append((f"å­¦ç¿’ï¼ˆfold {fold}/3ï¼‰", " ".join(train_cmd)))
        
        else:
            # æ¨™æº–5-fold CV
            commands.append(("å­¦ç¿’ï¼ˆå…¨foldï¼‰", f"nnUNetv2_train {self.dataset_id} 3d_fullres all"))
        
        return commands
    
    def apply_fixes(self) -> bool:
        """å…¨ä¿®æ­£ã‚’é©ç”¨"""
        print("ğŸ”§ nnU-Net v2 CV ã‚¨ãƒ©ãƒ¼ä¿®æ­£é–‹å§‹...")
        
        # 1. è¨ºæ–­
        diagnosis = self.diagnose_dataset()
        
        if not diagnosis['dataset_exists']:
            print("âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚ã¾ãšãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            return False
        
        if len(diagnosis['issues']) == 0:
            print("âœ… å•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
            return True
        
        print(f"\nğŸš¨ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
        for issue in diagnosis['issues']:
            print(f"   - {issue}")
        
        # 2. dataset.jsonä¿®æ­£
        if not self.fix_dataset_json(diagnosis):
            print("âŒ dataset.jsonä¿®æ­£ã«å¤±æ•—")
            return False
        
        # 3. ä¿®æ­£æ¸ˆã¿ã‚³ãƒãƒ³ãƒ‰ç”Ÿæˆãƒ»è¡¨ç¤º
        commands = self.generate_fixed_training_commands(diagnosis['num_samples'])
        
        print(f"\nğŸš€ ä¿®æ­£æ¸ˆã¿å®Ÿè¡Œã‚³ãƒãƒ³ãƒ‰:")
        for label, cmd in commands:
            print(f"\n{label}:")
            print(f"  {cmd}")
        
        # 4. ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        current_dir = Path(__file__).parent
        trainer_file = current_dir / "training" / "02_nnunet_v2" / "vesuvius_custom_trainer.py"
        
        if not trainer_file.exists():
            print(f"\nâš ï¸ ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {trainer_file}")
            print("   vesuvius_custom_trainer.pyã‚’åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„")
        else:
            print(f"âœ… ã‚«ã‚¹ã‚¿ãƒ ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ç¢ºèª: {trainer_file}")
        
        print(f"\nâœ… nnU-Net v2 CV ã‚¨ãƒ©ãƒ¼ä¿®æ­£å®Œäº†!")
        print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {diagnosis['num_samples']}")
        print(f"   æ¨å¥¨å®Ÿè¡Œ: ä¸Šè¨˜ã‚³ãƒãƒ³ãƒ‰ã‚’é †ç•ªã«å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
        return True


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    parser = argparse.ArgumentParser(description="nnU-Net v2 Cross-Validation ã‚¨ãƒ©ãƒ¼ä¿®æ­£")
    parser.add_argument("--dataset_id", type=int, default=1, help="ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆID")
    parser.add_argument("--verbose", action="store_true", help="è©³ç´°å‡ºåŠ›")
    parser.add_argument("--auto_run", action="store_true", help="ä¿®æ­£å¾Œã«è‡ªå‹•å®Ÿè¡Œ")
    
    args = parser.parse_args()
    
    print("=" * 80)
    print("ğŸ›ï¸ VESUVIUS CHALLENGE - nnU-Net v2 CV ã‚¨ãƒ©ãƒ¼ä¿®æ­£ãƒ„ãƒ¼ãƒ«")
    print("=" * 80)
    print("'n_splits=5 greater than the number of samples' ã‚¨ãƒ©ãƒ¼ã‚’è§£æ±ºã—ã¾ã™\n")
    
    fixer = NnuNetCVErrorFixer(
        dataset_id=args.dataset_id,
        verbose=args.verbose
    )
    
    success = fixer.apply_fixes()
    
    if success and args.auto_run:
        print("\nğŸš€ è‡ªå‹•å®Ÿè¡Œã‚ªãƒ—ã‚·ãƒ§ãƒ³ãŒæœ‰åŠ¹ã§ã™")
        # TODO: å®Ÿéš›ã®è‡ªå‹•å®Ÿè¡Œãƒ­ã‚¸ãƒƒã‚¯ã‚’è¿½åŠ 
        print("   æ‰‹å‹•å®Ÿè¡Œã‚’æ¨å¥¨ï¼ˆç¾åœ¨ã¯è‡ªå‹•å®Ÿè¡Œæœªå®Ÿè£…ï¼‰")
    
    return 0 if success else 1


if __name__ == "__main__":
    sys.exit(main())
