{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# üèõÔ∏è Vesuvius Challenge - Surface Detection with nnUNet (Runpods)\n",
    "\n",
    "**Purpose:** 3D semantic segmentation using nnUNetv2 for detecting papyrus surfaces in CT scan volumes\n",
    "\n",
    "**Runpods Version:** Modified from Kaggle notebook for Runpods environment\n",
    "\n",
    "### Key Features\n",
    "1. **Kaggle Data Download** - Automatic dataset download via Kaggle API\n",
    "2. **Native TIFF support** - Custom SimpleTiffIO reader, no NIfTI conversion needed\n",
    "3. **Pre-processed data caching** - Skip 1-2 hour preprocessing\n",
    "4. **Multi-GPU support** - DDP training with auto-detection\n",
    "5. **Runpods optimized paths** - Uses `/workspace` for persistent storage\n",
    "\n",
    "### Environment Requirements\n",
    "- Runpods with Network Volume mounted at `/workspace`\n",
    "- CUDA-enabled GPU (RTX 3080/4090/A6000 recommended)\n",
    "- 50GB+ storage space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup",
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nimport shutil\nimport subprocess\nfrom functools import partial\nfrom multiprocessing import Pool\nfrom pathlib import Path\nfrom typing import Optional, Tuple, List, Literal, Union\n\n# Clear display function\ndef print_header(text: str, emoji: str = \"üìã\", width: int = 80):\n    \"\"\"Print formatted header\"\"\"\n    print(\"\\n\" + \"=\" * width)\n    print(f\"{emoji} {text}\")\n    print(\"=\" * width)\n\ndef print_status(key: str, value: str, indent: int = 2):\n    \"\"\"Print formatted status\"\"\"\n    print(f\"{' ' * indent}‚Ä¢ {key}: {value}\")\n\n# Fix OpenBLAS thread issues\nprint_header(\"ENVIRONMENT SETUP\", \"‚öôÔ∏è\")\n\nprint(\"\\nüîß Fixing OpenBLAS thread issues...\")\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"\nos.environ[\"MKL_NUM_THREADS\"] = \"4\"\nos.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"4\"\nos.environ[\"NUMEXPR_NUM_THREADS\"] = \"4\"\nprint_status(\"Thread limit\", \"4 (prevents pthread_create errors)\")\n\n# Runpods-specific paths\nprint(\"\\nüìÅ Setting up directories...\")\nWORKSPACE = Path(\"/workspace\")\nINPUT_DIR = WORKSPACE / \"vesuvius_data\"\nWORKING_DIR = WORKSPACE / \"temp\"\nOUTPUT_DIR = WORKSPACE / \"results\"\n\nprint_status(\"Workspace\", str(WORKSPACE))\nprint_status(\"Input\", str(INPUT_DIR))\nprint_status(\"Output\", str(OUTPUT_DIR))\n\n# nnUNet directory structure\nprint(\"\\nüèóÔ∏è nnUNet directory structure...\")\nNNUNET_BASE = WORKSPACE / \"nnUNet_data\"\nNNUNET_RAW = NNUNET_BASE / \"nnUNet_raw\"\nNNUNET_PREPROCESSED = NNUNET_BASE / \"nnUNet_preprocessed\"\nNNUNET_RESULTS = OUTPUT_DIR / \"nnUNet_results\"\n\nprint_status(\"Raw data\", str(NNUNET_RAW))\nprint_status(\"Preprocessed\", str(NNUNET_PREPROCESSED))\nprint_status(\"Results\", str(NNUNET_RESULTS))\n\n# Dataset configuration\nprint(\"\\nüìä Dataset configuration...\")\nDATASET_ID = 100\nDATASET_NAME = f\"Dataset{DATASET_ID:03d}_VesuviusSurface\"\nprint_status(\"Dataset ID\", str(DATASET_ID))\nprint_status(\"Dataset name\", DATASET_NAME)\n\n# Training configuration - DEFAULT VALUES (will be updated by auto-config)\nprint(\"\\nüéØ Default training configuration...\")\nFOLD = \"all\"\nCONFIGURATION = \"3d_fullres\"  # Start with fullres by default\nPLANNER = \"nnUNetPlannerResEncM\"  # Medium planner for compatibility\nPLANS_NAME = \"nnUNetResEncUNetMPlans\"  # Match the planner\nEPOCHS = 250\nNUM_WORKERS = min(os.cpu_count() or 4, 4)\n\nprint_status(\"Configuration\", f\"{CONFIGURATION} (default)\")\nprint_status(\"Planner\", f\"{PLANNER} (default)\")\nprint_status(\"Epochs\", str(EPOCHS))\nprint_status(\"Workers\", str(NUM_WORKERS))\nprint_status(\"Fold\", FOLD)\n\n# GPU detection\ndef _get_gpu_count() -> int:\n    try:\n        import torch\n        return torch.cuda.device_count() if torch.cuda.is_available() else 1\n    except ImportError:\n        return 0\n\nNUM_GPUS = _get_gpu_count()\n\nprint(\"\\nüéÆ Hardware detection...\")\nprint_status(\"GPUs detected\", str(NUM_GPUS))\nprint_status(\"CPU cores\", str(os.cpu_count()))\n\n# AUTO-CONFIGURE BASED ON GPU AND PREPROCESSED DATA\nprint(\"\\n\" + \"=\" * 80)\nprint(\"üéÆ AUTO-CONFIGURING FOR GPU AND AVAILABLE DATA...\")\nprint(\"=\" * 80)\n\n# Check what plans are actually available\ndef check_available_plans():\n    \"\"\"Check which plan files actually exist\"\"\"\n    preprocessed_path = NNUNET_PREPROCESSED / DATASET_NAME\n    available_plans = []\n    \n    if preprocessed_path.exists():\n        for plan_file in preprocessed_path.glob(\"*.json\"):\n            plan_name = plan_file.stem\n            available_plans.append(plan_name)\n    \n    return available_plans\n\ntry:\n    import torch\n    available_plans = check_available_plans()\n    \n    print(f\"\\nüìã Available plan files:\")\n    for plan in available_plans:\n        print_status(\"Plan\", plan)\n    \n    if torch.cuda.is_available():\n        gpu_name = torch.cuda.get_device_name(0)\n        vram_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n        \n        print(f\"\\nüìä GPU Information:\")\n        print_status(\"Model\", gpu_name)\n        print_status(\"VRAM\", f\"{vram_gb:.1f}GB\")\n        \n        # Use available plans or fallback to compatible settings\n        if \"nnUNetResEncLPlans\" in available_plans and vram_gb >= 40:\n            # Large model available and high-end GPU\n            CONFIGURATION = \"3d_fullres\"\n            PLANNER = \"nnUNetPlannerResEncL\"\n            PLANS_NAME = \"nnUNetResEncLPlans\"\n            print(\"\\n‚úÖ HIGH-END GPU + LARGE PLANS AVAILABLE\")\n            print_status(\"Configuration\", \"3d_fullres\")\n            print_status(\"Planner\", \"nnUNetPlannerResEncL (Large)\")\n            print_status(\"Estimated training time\", \"8-12 hours\")\n            \n        elif \"nnUNetResEncUNetMPlans\" in available_plans and vram_gb >= 20:\n            # Medium model available and sufficient GPU\n            CONFIGURATION = \"3d_fullres\"\n            PLANNER = \"nnUNetPlannerResEncM\"\n            PLANS_NAME = \"nnUNetResEncUNetMPlans\"\n            print(\"\\n‚úÖ MID-RANGE GPU + MEDIUM PLANS AVAILABLE\")\n            print_status(\"Configuration\", \"3d_fullres\")\n            print_status(\"Planner\", \"nnUNetPlannerResEncM (Medium)\")\n            print_status(\"Estimated training time\", \"12-18 hours\")\n            \n        elif \"nnUNetPlans\" in available_plans:\n            # Default plans available\n            if vram_gb >= 20:\n                CONFIGURATION = \"3d_fullres\"\n            else:\n                CONFIGURATION = \"3d_lowres\"\n            PLANNER = \"nnUNetPlanner\"\n            PLANS_NAME = \"nnUNetPlans\"\n            print(\"\\n‚úÖ STANDARD PLANS AVAILABLE\")\n            print_status(\"Configuration\", CONFIGURATION)\n            print_status(\"Planner\", \"nnUNetPlanner (Standard)\")\n            \n        else:\n            # No preprocessed data - need to preprocess first\n            print(\"\\n‚ö†Ô∏è NO PREPROCESSED DATA FOUND\")\n            print_status(\"Action required\", \"Run preprocessing first\")\n            \n            # Set safe defaults for preprocessing\n            CONFIGURATION = \"3d_fullres\" if vram_gb >= 20 else \"3d_lowres\"\n            PLANNER = \"nnUNetPlannerResEncM\"\n            PLANS_NAME = \"nnUNetResEncUNetMPlans\"\n            \n    else:\n        print(\"\\n‚ö†Ô∏è No GPU detected - using CPU fallback\")\n        CONFIGURATION = \"3d_lowres\"\n        PLANNER = \"nnUNetPlannerResEncM\"\n        PLANS_NAME = \"nnUNetResEncUNetMPlans\"\n        \nexcept Exception as e:\n    print(f\"\\n‚ö†Ô∏è Auto-configuration failed: {e}\")\n    print(\"Using safe default configuration\")\n    CONFIGURATION = \"3d_fullres\"\n    PLANNER = \"nnUNetPlannerResEncM\"  \n    PLANS_NAME = \"nnUNetResEncUNetMPlans\"\n\n# Final configuration summary\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ FINAL CONFIGURATION\")\nprint(\"=\" * 80)\nprint_status(\"Mode\", CONFIGURATION)\nprint_status(\"Planner\", PLANNER)\nprint_status(\"Plans\", PLANS_NAME)\nprint_status(\"Epochs\", str(EPOCHS))\nprint_status(\"Fold\", FOLD)\nprint_status(\"Workers\", str(NUM_WORKERS))\n\n# Show manual override options\nprint(\"\\nüí° Manual override (if needed):\")\nprint(\"   # Use existing preprocessed plans:\")\navailable_plans = check_available_plans()\nfor plan in available_plans[:3]:  # Show first 3 options\n    config_type = \"3d_fullres\" if \"fullres\" in plan or \"M\" in plan or \"L\" in plan else \"3d_lowres\"\n    print(f\"   CONFIGURATION = '{config_type}'; PLANS_NAME = '{plan}'\")\n\nprint(\"\\n\" + \"=\" * 80)\nprint(\"‚úÖ Environment setup complete!\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "code",
   "id": "2o06p2f3v1d",
   "source": "# A6000 optimized configuration cell\ndef configure_for_gpu():\n    \"\"\"Auto-configure based on available GPU\"\"\"\n    global CONFIGURATION, EPOCHS, PLANNER\n    \n    print(\"\\nüéÆ AUTO-CONFIGURING FOR GPU...\")\n    \n    try:\n        import torch\n        if torch.cuda.is_available():\n            gpu_name = torch.cuda.get_device_name(0)\n            vram_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n            \n            print(f\"   GPU detected: {gpu_name}\")\n            print(f\"   VRAM: {vram_gb:.1f}GB\")\n            \n            # Auto-select configuration based on VRAM\n            if vram_gb >= 40:  # A6000, A100\n                CONFIGURATION = \"3d_fullres\"\n                PLANNER = \"nnUNetPlannerResEncL\"  # Large model for A6000\n                print(\"   ‚úÖ Using 3d_fullres (High-end GPU)\")\n                print(\"   üí° Patch size: up to 160x160x160\")\n                print(\"   üí° Batch size: 2-4\")\n            elif vram_gb >= 20:  # RTX 4090, 3090\n                CONFIGURATION = \"3d_fullres\"\n                PLANNER = \"nnUNetPlannerResEncM\"  # Medium model\n                print(\"   ‚úÖ Using 3d_fullres (Mid-range GPU)\")\n                print(\"   üí° Patch size: 96x96x96\")\n                print(\"   üí° Batch size: 2\")\n            else:  # T4, RTX 3080\n                CONFIGURATION = \"3d_lowres\"\n                PLANNER = \"nnUNetPlannerResEncM\"\n                print(\"   ‚úÖ Using 3d_lowres (Entry-level GPU)\")\n                print(\"   üí° Patch size: 64x64x64\")\n                print(\"   üí° Batch size: 1-2\")\n        else:\n            print(\"   ‚ö†Ô∏è No GPU detected, using default 3d_lowres\")\n    except Exception as e:\n        print(f\"   ‚ö†Ô∏è Auto-config failed: {e}\")\n        print(\"   Using default configuration\")\n    \n    print(f\"\\n   Final configuration:\")\n    print(f\"   ‚Ä¢ Mode: {CONFIGURATION}\")\n    print(f\"   ‚Ä¢ Planner: {PLANNER}\")\n    print(f\"   ‚Ä¢ Epochs: {EPOCHS}\")\n\n# Run auto-configuration\nconfigure_for_gpu()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-packages",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install kaggle nnunetv2 nibabel tifffile tqdm -q\n",
    "\n",
    "# Create directories\n",
    "for directory in [INPUT_DIR, WORKING_DIR, OUTPUT_DIR, NNUNET_RAW, NNUNET_PREPROCESSED, NNUNET_RESULTS]:\n",
    "    directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"‚úÖ Packages installed and directories created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kaggle-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_kaggle_auth() -> bool:\n",
    "    \"\"\"\n",
    "    Setup Kaggle authentication for Runpods\n",
    "    \"\"\"\n",
    "    possible_paths = [\n",
    "        Path.home() / \".kaggle\" / \"kaggle.json\",\n",
    "        WORKSPACE / \".kaggle\" / \"kaggle.json\",\n",
    "        WORKSPACE / \"kaggle.json\",\n",
    "        Path(\"./kaggle.json\")\n",
    "    ]\n",
    "    \n",
    "    kaggle_json = None\n",
    "    for path in possible_paths:\n",
    "        if path.exists():\n",
    "            kaggle_json = path\n",
    "            print(f\"‚úÖ Kaggle config found: {path}\")\n",
    "            break\n",
    "    \n",
    "    if kaggle_json:\n",
    "        # Copy to standard location\n",
    "        kaggle_dir = Path.home() / \".kaggle\"\n",
    "        kaggle_dir.mkdir(exist_ok=True)\n",
    "        standard_path = kaggle_dir / \"kaggle.json\"\n",
    "        \n",
    "        if kaggle_json != standard_path:\n",
    "            shutil.copy2(kaggle_json, standard_path)\n",
    "            print(f\"üìÅ Copied to standard location: {standard_path}\")\n",
    "        \n",
    "        os.chmod(standard_path, 0o600)\n",
    "        \n",
    "        try:\n",
    "            import kaggle\n",
    "            kaggle.api.authenticate()\n",
    "            print(\"‚úÖ Kaggle authentication successful\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Kaggle authentication failed: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"‚ùå Kaggle config not found. Place kaggle.json in one of:\")\n",
    "        for path in possible_paths:\n",
    "            print(f\"  ‚Ä¢ {path}\")\n",
    "        return False\n",
    "\n",
    "kaggle_ready = setup_kaggle_auth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "download-data",
   "metadata": {},
   "outputs": [],
   "source": "def download_vesuvius_data():\n    \"\"\"\n    Download Vesuvius Challenge data using Kaggle API with clear progress display\n    \"\"\"\n    if not kaggle_ready:\n        print(\"‚ùå Kaggle authentication required\")\n        return False\n    \n    import kaggle\n    import zipfile\n    import threading\n    import time\n    \n    print_header(\"DATA DOWNLOAD\", \"üì•\")\n    \n    # Expected file sizes\n    DATASETS = {\n        \"competition\": {\n            \"name\": \"vesuvius-challenge-surface-detection\",\n            \"type\": \"competition\",\n            \"size_mb\": 500,\n            \"path\": INPUT_DIR / \"competition\"\n        },\n        \"preprocessed\": {\n            \"name\": \"jirkaborovec/vesuvius-surface-nnunet-preprocessed\",\n            \"type\": \"dataset\",\n            \"size_mb\": 2000,\n            \"path\": INPUT_DIR / \"preprocessed\"\n        }\n    }\n    \n    def format_size(mb: float) -> str:\n        \"\"\"Format size in MB/GB\"\"\"\n        if mb >= 1024:\n            return f\"{mb/1024:.1f}GB\"\n        return f\"{mb:.0f}MB\"\n    \n    def create_progress_bar(current: float, total: float, width: int = 40) -> str:\n        \"\"\"Create a visual progress bar\"\"\"\n        percent = min(100, (current / total) * 100) if total > 0 else 0\n        filled = int(width * percent / 100)\n        bar = '‚ñà' * filled + '‚ñë' * (width - filled)\n        return f\"[{bar}] {percent:.1f}%\"\n    \n    def download_dataset(dataset_info: dict) -> bool:\n        \"\"\"Download a single dataset with progress\"\"\"\n        name = dataset_info[\"name\"]\n        dtype = dataset_info[\"type\"]\n        expected_mb = dataset_info[\"size_mb\"]\n        path = dataset_info[\"path\"]\n        \n        # Check if already exists\n        if dtype == \"competition\":\n            check_path = path / \"train_images\"\n        else:\n            check_path = path\n            \n        if check_path.exists() and len(list(check_path.glob(\"*\"))) > 0:\n            print(f\"\\n‚úÖ Already downloaded: {name}\")\n            return True\n        \n        print(f\"\\nüì¶ Downloading: {name}\")\n        print(f\"   Expected size: {format_size(expected_mb)}\")\n        print(f\"   Destination: {path}\")\n        \n        path.mkdir(parents=True, exist_ok=True)\n        \n        try:\n            # Start download\n            start_time = time.time()\n            \n            if dtype == \"competition\":\n                print(\"   Status: Downloading competition data...\")\n                kaggle.api.competition_download_files(\n                    name.replace('vesuvius-challenge-', ''),\n                    path=str(path),\n                    quiet=False\n                )\n            else:\n                print(\"   Status: Downloading dataset...\")\n                kaggle.api.dataset_download_files(\n                    name,\n                    path=str(path),\n                    quiet=False,\n                    unzip=False\n                )\n            \n            elapsed = time.time() - start_time\n            print(f\"   ‚úÖ Download complete in {int(elapsed//60):02d}:{int(elapsed%60):02d}\")\n            \n            # Extract files\n            zip_files = list(path.glob(\"*.zip\"))\n            if zip_files:\n                for zip_file in zip_files:\n                    print(f\"   üìÇ Extracting: {zip_file.name}\")\n                    \n                    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n                        total_files = len(zip_ref.namelist())\n                        print(f\"   Files to extract: {total_files}\")\n                        \n                        # Extract with progress\n                        for i, member in enumerate(zip_ref.namelist()):\n                            if i % max(1, total_files // 10) == 0:\n                                percent = (i / total_files) * 100\n                                print(f\"   Progress: {percent:.0f}% ({i}/{total_files} files)\")\n                            zip_ref.extract(member, path)\n                    \n                    print(f\"   ‚úÖ Extraction complete\")\n                    zip_file.unlink()  # Delete zip\n            \n            return True\n            \n        except Exception as e:\n            print(f\"   ‚ùå Error: {e}\")\n            return False\n    \n    # Download each dataset\n    success = True\n    total_datasets = len(DATASETS)\n    \n    for i, (key, dataset_info) in enumerate(DATASETS.items(), 1):\n        print(f\"\\n{'='*60}\")\n        print(f\"üìä Dataset {i}/{total_datasets}: {key.upper()}\")\n        print(f\"{'='*60}\")\n        \n        if not download_dataset(dataset_info):\n            success = False\n            if key == \"competition\":\n                print(\"‚ö†Ô∏è Competition data is required. Stopping download.\")\n                break\n            else:\n                print(\"‚ö†Ô∏è Optional dataset failed. Continuing...\")\n    \n    # Summary\n    print(\"\\n\" + \"=\"*80)\n    if success:\n        print(\"‚úÖ DATA DOWNLOAD COMPLETE\")\n        \n        # Show what was downloaded\n        print(\"\\nüìÅ Downloaded files:\")\n        for key, dataset_info in DATASETS.items():\n            path = dataset_info[\"path\"]\n            if path.exists():\n                size = sum(f.stat().st_size for f in path.rglob(\"*\") if f.is_file()) / (1024*1024)\n                print(f\"   ‚Ä¢ {key}: {format_size(size)} at {path}\")\n    else:\n        print(\"‚ö†Ô∏è PARTIAL DOWNLOAD - Some datasets failed\")\n    print(\"=\"*80)\n    \n    return success\n\n# Download data\nif kaggle_ready:\n    data_downloaded = download_vesuvius_data()\nelse:\n    print(\"\\n‚ö†Ô∏è Skipping data download - Kaggle authentication not available\")\n    data_downloaded = False"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environment-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up nnUNet environment variables\n",
    "os.environ[\"nnUNet_raw\"] = str(NNUNET_RAW)\n",
    "os.environ[\"nnUNet_preprocessed\"] = str(NNUNET_PREPROCESSED)\n",
    "os.environ[\"nnUNet_results\"] = str(NNUNET_RESULTS)\n",
    "os.environ[\"nnUNet_USE_BLOSC2\"] = \"1\"  # Faster compression\n",
    "os.environ[\"nnUNet_compile\"] = \"true\"  # Enable torch.compile\n",
    "\n",
    "print(\"üîß nnUNet environment configured:\")\n",
    "print(f\"  Raw: {NNUNET_RAW}\")\n",
    "print(f\"  Preprocessed: {NNUNET_PREPROCESSED}\")\n",
    "print(f\"  Results: {NNUNET_RESULTS}\")\n",
    "\n",
    "# Import after setting environment\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(f\"‚úÖ Environment ready with {NUM_GPUS} GPU(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-functions",
   "metadata": {},
   "outputs": [],
   "source": "def fix_dataset_json_ioclass(dataset_path: Path) -> bool:\n    \"\"\"Fix SimpleTiffIO error by removing ioclass from dataset.json\"\"\"\n    json_path = dataset_path / \"dataset.json\"\n    if not json_path.exists():\n        return False\n    \n    try:\n        with open(json_path, 'r') as f:\n            config = json.load(f)\n        \n        modified = False\n        # Remove problematic settings\n        if 'ioclass' in config:\n            del config['ioclass']\n            modified = True\n            print(\"  ‚úÖ Removed 'ioclass' setting\")\n        \n        if 'overwrite_image_reader_writer' in config:\n            if config['overwrite_image_reader_writer'] == 'SimpleTiffIO':\n                del config['overwrite_image_reader_writer']\n                modified = True\n                print(\"  ‚úÖ Removed SimpleTiffIO override\")\n        \n        if modified:\n            with open(json_path, 'w') as f:\n                json.dump(config, f, indent=4)\n            print(f\"  ‚úÖ Fixed dataset.json at {json_path}\")\n        \n        return True\n    except Exception as e:\n        print(f\"  ‚ùå Error fixing dataset.json: {e}\")\n        return False\n\ndef create_spacing_json(output_path: Path, shape: tuple, spacing: tuple = (1.0, 1.0, 1.0)):\n    \"\"\"Create JSON sidecar with spacing info for TIFF files.\"\"\"\n    json_data = {\"spacing\": list(spacing)}\n    with open(output_path, \"w\") as f:\n        json.dump(json_data, f)\n\ndef create_dataset_json(output_dir: Path, num_training: int, file_ending: str = \".tif\") -> dict:\n    \"\"\"Create dataset.json with ignore label support (without SimpleTiffIO).\"\"\"\n    dataset_json = {\n        \"channel_names\": {\"0\": \"CT\"},\n        \"labels\": {\"background\": 0, \"surface\": 1, \"ignore\": 2},\n        \"numTraining\": num_training,\n        \"file_ending\": file_ending\n        # Removed overwrite_image_reader_writer to avoid SimpleTiffIO error\n    }\n    \n    json_path = output_dir / \"dataset.json\"\n    with open(json_path, \"w\") as f:\n        json.dump(dataset_json, f, indent=4)\n    \n    print(f\"Created dataset.json: {num_training} training cases\")\n    return dataset_json\n\ndef prepare_single_case(src_path: Path, dest_path: Path, json_path: Path, use_symlinks: bool = True) -> bool:\n    \"\"\"Prepare a single TIFF file for nnUNet.\"\"\"\n    try:\n        # Get shape for JSON\n        with tifffile.TiffFile(src_path) as tif:\n            shape = tif.pages[0].shape if len(tif.pages) == 1 else (len(tif.pages), *tif.pages[0].shape)\n        \n        # Link or copy file\n        if use_symlinks:\n            if not dest_path.exists():\n                dest_path.symlink_to(src_path.resolve())\n        else:\n            shutil.copy2(src_path, dest_path)\n        \n        # Create JSON sidecar\n        create_spacing_json(json_path, shape)\n        return True\n    \n    except Exception as e:\n        print(f\"Error processing {src_path.name}: {e}\")\n        return False\n\nprint(\"‚úÖ Utility functions loaded (SimpleTiffIO issue fixed)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dataset-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(input_base_dir: Path, max_cases: Optional[int] = None, use_symlinks: bool = True):\n",
    "    \"\"\"\n",
    "    Convert competition data to nnUNet format\n",
    "    \"\"\"\n",
    "    dataset_dir = NNUNET_RAW / DATASET_NAME\n",
    "    images_dir = dataset_dir / \"imagesTr\"\n",
    "    labels_dir = dataset_dir / \"labelsTr\"\n",
    "    \n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Look for competition data\n",
    "    train_images_dir = input_base_dir / \"competition\" / \"train_images\"\n",
    "    train_labels_dir = input_base_dir / \"competition\" / \"train_labels\"\n",
    "    \n",
    "    if not train_images_dir.exists():\n",
    "        print(f\"‚ùå Training images not found: {train_images_dir}\")\n",
    "        return None\n",
    "    \n",
    "    image_files = sorted(train_images_dir.glob(\"*.tif\"))\n",
    "    if max_cases:\n",
    "        image_files = image_files[:max_cases]\n",
    "    \n",
    "    print(f\"Found {len(image_files)} training cases\")\n",
    "    print(f\"Using {'symlinks' if use_symlinks else 'copy'}\")\n",
    "    \n",
    "    success_count = 0\n",
    "    for img_path in tqdm(image_files, desc=\"Preparing dataset\"):\n",
    "        case_id = img_path.stem\n",
    "        label_path = train_labels_dir / img_path.name\n",
    "        \n",
    "        if not label_path.exists():\n",
    "            print(f\"Warning: No label for {case_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare image\n",
    "        img_ok = prepare_single_case(\n",
    "            img_path,\n",
    "            images_dir / f\"{case_id}_0000.tif\",\n",
    "            images_dir / f\"{case_id}_0000.json\",\n",
    "            use_symlinks\n",
    "        )\n",
    "        \n",
    "        # Prepare label\n",
    "        label_ok = prepare_single_case(\n",
    "            label_path,\n",
    "            labels_dir / f\"{case_id}.tif\",\n",
    "            labels_dir / f\"{case_id}.json\",\n",
    "            use_symlinks\n",
    "        )\n",
    "        \n",
    "        if img_ok and label_ok:\n",
    "            success_count += 1\n",
    "    \n",
    "    create_dataset_json(dataset_dir, success_count, file_ending=\".tif\")\n",
    "    print(f\"‚úÖ Dataset prepared: {success_count} cases\")\n",
    "    return dataset_dir\n",
    "\n",
    "# Prepare dataset if data was downloaded\n",
    "if data_downloaded:\n",
    "    dataset_dir = prepare_dataset(INPUT_DIR, max_cases=50)  # Limit for testing\n",
    "else:\n",
    "    print(\"Skipping dataset preparation - no data available\")\n",
    "    dataset_dir = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nnunet-commands",
   "metadata": {},
   "outputs": [],
   "source": "def run_command(cmd: str, name: str = \"Command\", timeout: Optional[int] = None) -> bool:\n    \"\"\"Execute shell command with lightweight text-based progress display.\"\"\"\n    import subprocess\n    import time\n    import re\n    \n    print(f\"üöÄ Starting: {name}\")\n    print(f\"üìù Command: {cmd[:100]}...\" if len(cmd) > 100 else f\"üìù Command: {cmd}\")\n    print(\"-\" * 80)\n    \n    # Progress tracking variables\n    current_epoch = 0\n    total_epochs = 250\n    current_batch = 0\n    total_batches = 0\n    best_dice = 0.0\n    current_loss = 0.0\n    validation_dice = 0.0\n    start_time = time.time()\n    epoch_start_time = time.time()\n    \n    def format_time(seconds: float) -> str:\n        \"\"\"Format seconds to HH:MM:SS\"\"\"\n        hours = int(seconds // 3600)\n        minutes = int((seconds % 3600) // 60)\n        secs = int(seconds % 60)\n        if hours > 0:\n            return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n        return f\"{minutes:02d}:{secs:02d}\"\n    \n    def print_epoch_progress():\n        \"\"\"Print overall epoch progress\"\"\"\n        elapsed = time.time() - start_time\n        \n        if current_epoch > 0:\n            progress_pct = (current_epoch / total_epochs) * 100\n            time_per_epoch = elapsed / current_epoch\n            eta = (total_epochs - current_epoch) * time_per_epoch\n        else:\n            progress_pct = 0\n            eta = 0\n        \n        # Epoch progress bar\n        bar_width = 30\n        filled = int(bar_width * progress_pct / 100)\n        epoch_bar = \"‚ñà\" * filled + \"‚ñë\" * (bar_width - filled)\n        \n        print(f\"\\rüìä Epoch {current_epoch:3d}/{total_epochs} [{epoch_bar}] {progress_pct:5.1f}% | \"\n              f\"Best Dice: {best_dice:.3f} | Elapsed: {format_time(elapsed)} | ETA: {format_time(eta)}\", \n              end=\"\", flush=True)\n    \n    def print_batch_progress():\n        \"\"\"Print current epoch batch progress\"\"\"\n        if total_batches > 0:\n            batch_pct = (current_batch / total_batches) * 100\n            epoch_elapsed = time.time() - epoch_start_time\n            \n            if current_batch > 0:\n                time_per_batch = epoch_elapsed / current_batch\n                batch_eta = (total_batches - current_batch) * time_per_batch\n            else:\n                batch_eta = 0\n            \n            # Batch progress bar\n            bar_width = 25\n            filled = int(bar_width * batch_pct / 100)\n            batch_bar = \"‚ñà\" * filled + \"‚ñë\" * (bar_width - filled)\n            \n            print(f\"\\r  ‚è≥ Batch {current_batch:3d}/{total_batches} [{batch_bar}] {batch_pct:5.1f}% | \"\n                  f\"Loss: {current_loss:.3f} | Batch ETA: {format_time(batch_eta)}\", \n                  end=\"\", flush=True)\n    \n    try:\n        # Start process\n        process = subprocess.Popen(\n            cmd, shell=True,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n            bufsize=1,\n            universal_newlines=True,\n            env={**os.environ, 'PYTHONUNBUFFERED': '1'}\n        )\n        \n        output_lines = []\n        last_update = time.time()\n        \n        for line in process.stdout:\n            line = line.strip()\n            if not line:\n                continue\n                \n            output_lines.append(line)\n            line_lower = line.lower()\n            \n            # Extract epoch information\n            if 'epoch' in line_lower:\n                epoch_match = re.search(r'epoch[:\\s]+(\\d+)', line_lower)\n                if epoch_match:\n                    new_epoch = int(epoch_match.group(1))\n                    if new_epoch > current_epoch:\n                        if current_epoch > 0:  # Finish previous epoch display\n                            print()  # New line after batch progress\n                        current_epoch = new_epoch\n                        current_batch = 0\n                        total_batches = 0\n                        epoch_start_time = time.time()\n                        print_epoch_progress()\n            \n            # Extract batch information\n            batch_patterns = [\n                r'batch[:\\s]+(\\d+)[/\\s]+(\\d+)',  # batch: 45/200\n                r'(\\d+)[/](\\d+)',  # 45/200\n                r'step[:\\s]+(\\d+)[/\\s]+(\\d+)',  # step: 45/200\n            ]\n            \n            for pattern in batch_patterns:\n                batch_match = re.search(pattern, line_lower)\n                if batch_match:\n                    current_batch = int(batch_match.group(1))\n                    total_batches = int(batch_match.group(2))\n                    break\n            \n            # Extract total epochs\n            if 'training' in line_lower and ('epochs' in line_lower or 'epoch' in line_lower):\n                epochs_match = re.search(r'(\\d+)\\s*epochs?', line_lower)\n                if epochs_match:\n                    total_epochs = int(epochs_match.group(1))\n            \n            # Extract metrics\n            dice_patterns = [\n                r'dice[:\\s]+([0-9.]+)',\n                r'mean_dice[:\\s]+([0-9.]+)',\n                r'validation_dice[:\\s]+([0-9.]+)',\n            ]\n            \n            for pattern in dice_patterns:\n                dice_match = re.search(pattern, line_lower)\n                if dice_match:\n                    dice_val = float(dice_match.group(1))\n                    if 'val' in line_lower or 'validation' in line_lower:\n                        validation_dice = dice_val\n                    if dice_val > best_dice:\n                        best_dice = dice_val\n                    break\n            \n            loss_patterns = [\n                r'loss[:\\s]+([0-9.]+)',\n                r'train_loss[:\\s]+([0-9.]+)',\n            ]\n            \n            for pattern in loss_patterns:\n                loss_match = re.search(pattern, line_lower)\n                if loss_match:\n                    current_loss = float(loss_match.group(1))\n                    break\n            \n            # Update progress displays\n            now = time.time()\n            if now - last_update > 5:  # Update every 5 seconds for batch progress\n                if current_batch > 0 and total_batches > 0:\n                    print()  # New line after epoch progress\n                    print_batch_progress()\n                else:\n                    print_epoch_progress()\n                last_update = now\n            \n            # Show important messages immediately\n            if any(keyword in line_lower for keyword in ['error', 'failed', 'saved', 'completed', 'best', 'validation']):\n                print(f\"\\nüìù {line}\")\n        \n        # Wait for process to complete\n        process.wait()\n        elapsed_total = time.time() - start_time\n        \n        print()  # New line after progress bar\n        print(\"-\" * 80)\n        \n        if process.returncode == 0:\n            print(f\"‚úÖ {name} completed successfully!\")\n            print(f\"üìä Final: {current_epoch} epochs | Best Dice: {best_dice:.4f} | Val Dice: {validation_dice:.4f}\")\n            print(f\"‚è∞ Duration: {format_time(elapsed_total)}\")\n            \n            if best_dice > 0:\n                print(f\"üéâ Model saved with best Dice score: {best_dice:.4f}\")\n            \n            return True\n        else:\n            print(f\"‚ùå {name} failed (exit code: {process.returncode})\")\n            print(f\"üìä Progress: {current_epoch}/{total_epochs} epochs\")\n            print(f\"‚è∞ Duration: {format_time(elapsed_total)}\")\n            \n            # Show last few lines of output for debugging\n            if output_lines:\n                print(\"\\nüîç Last output lines:\")\n                for line in output_lines[-5:]:\n                    print(f\"   {line}\")\n            \n            return False\n            \n    except Exception as e:\n        print(f\"\\nüí• {name} ERROR: {e}\")\n        return False\n\n# Keep the same function signatures for preprocessing, training, and inference\ndef run_preprocessing(dataset_id: int = DATASET_ID, planner: str = PLANNER, num_workers: int = None) -> bool:\n    \"\"\"Run nnUNet preprocessing with progress bar.\"\"\"\n    if num_workers is None:\n        num_workers = NUM_WORKERS\n    \n    num_workers = min(num_workers, 4)\n    \n    cmd = f\"nnUNetv2_plan_and_preprocess -d {dataset_id:03d} -np {num_workers} -pl {planner} -c {CONFIGURATION}\"\n    return run_command(cmd, f\"Preprocessing (Dataset {dataset_id:03d})\", timeout=7200)\n\ndef run_training(dataset_id: int = DATASET_ID, config: str = CONFIGURATION, \n                fold: Union[int, str] = FOLD, plans: str = PLANS_NAME, \n                epochs: Optional[int] = EPOCHS, num_gpus: int = NUM_GPUS) -> bool:\n    \"\"\"Run nnUNet training with epoch and batch progress display.\"\"\"\n    trainer = \"nnUNetTrainer\" if epochs is None or epochs == 1000 else f\"nnUNetTrainer_{epochs}epochs\"\n    \n    cmd = f\"PYTHONUNBUFFERED=1 nnUNetv2_train {dataset_id:03d} {config} {fold} -p {plans} -tr {trainer}\"\n    if num_gpus > 1:\n        cmd += f\" -num_gpus {num_gpus}\"\n    \n    return run_command(cmd, f\"Training ({epochs} epochs, {config})\", timeout=86400)\n\ndef run_inference(input_dir: Path, output_dir: Path, dataset_id: int = DATASET_ID,\n                 config: str = CONFIGURATION, fold: Union[int, str] = FOLD,\n                 plans: str = PLANS_NAME, epochs: Optional[int] = EPOCHS) -> bool:\n    \"\"\"Run inference with progress bar.\"\"\"\n    output_dir.mkdir(parents=True, exist_ok=True)\n    \n    trainer = \"nnUNetTrainer\" if epochs is None or epochs == 1000 else f\"nnUNetTrainer_{epochs}epochs\"\n    \n    cmd = f\"nnUNetv2_predict -d {dataset_id:03d} -c {config} -f {fold}\"\n    cmd += f\" -i {input_dir} -o {output_dir} -p {plans} -tr {trainer}\"\n    cmd += \" --save_probabilities --verbose\"\n    \n    return run_command(cmd, \"Inference\", timeout=3600)\n\nprint(\"‚úÖ Lightweight progress with epoch AND batch progress ready\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-data-prep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data(input_base_dir: Path, output_dir: Path, use_symlinks: bool = True) -> Path:\n",
    "    \"\"\"Prepare test TIFF images for nnUNet inference.\"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    test_images_dir = input_base_dir / \"competition\" / \"test_images\"\n",
    "    \n",
    "    if not test_images_dir.exists():\n",
    "        print(f\"‚ùå Test images not found: {test_images_dir}\")\n",
    "        return output_dir\n",
    "    \n",
    "    test_files = sorted(test_images_dir.glob(\"*.tif\"))\n",
    "    print(f\"Found {len(test_files)} test cases\")\n",
    "    \n",
    "    for img_path in tqdm(test_files, desc=\"Preparing test data\"):\n",
    "        case_id = img_path.stem\n",
    "        prepare_single_case(\n",
    "            img_path,\n",
    "            output_dir / f\"{case_id}_0000.tif\",\n",
    "            output_dir / f\"{case_id}_0000.json\",\n",
    "            use_symlinks\n",
    "        )\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "def predictions_to_tiff(pred_dir: Path, output_dir: Path):\n",
    "    \"\"\"Convert nnUNet predictions to TIFF format.\"\"\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Try NPZ files first (probability maps)\n",
    "    npz_files = list(pred_dir.glob(\"*.npz\"))\n",
    "    tif_files = list(pred_dir.glob(\"*.tif\"))\n",
    "    \n",
    "    if npz_files:\n",
    "        print(f\"Converting {len(npz_files)} NPZ files to TIFF...\")\n",
    "        for npz_path in tqdm(npz_files, desc=\"Converting\"):\n",
    "            case_id = npz_path.stem\n",
    "            # Load probabilities and take argmax\n",
    "            data = np.load(npz_path)\n",
    "            probs = data['probabilities']\n",
    "            pred = np.argmax(probs, axis=0).astype(np.uint8)\n",
    "            tifffile.imwrite(output_dir / f\"{case_id}.tif\", pred)\n",
    "    elif tif_files:\n",
    "        print(f\"Copying {len(tif_files)} TIFF files...\")\n",
    "        for tif_path in tqdm(tif_files, desc=\"Copying\"):\n",
    "            case_id = tif_path.stem\n",
    "            pred = tifffile.imread(str(tif_path)).astype(np.uint8)\n",
    "            tifffile.imwrite(output_dir / f\"{case_id}.tif\", pred)\n",
    "    else:\n",
    "        print(f\"‚ùå No prediction files found in {pred_dir}\")\n",
    "\n",
    "print(\"‚úÖ Test data and conversion functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "full-pipeline",
   "metadata": {},
   "outputs": [],
   "source": "def full_pipeline(do_preprocess: bool = True, do_train: bool = True, \n                 do_inference: bool = True, max_cases: Optional[int] = None):\n    \"\"\"Run complete nnUNet pipeline with clear status display.\"\"\"\n    \n    # Pipeline header\n    print(\"\\n\" + \"=\"*80)\n    print(\"üèõÔ∏è VESUVIUS CHALLENGE - NNUNET PIPELINE\")\n    print(\"=\"*80)\n    \n    # Show configuration\n    print(\"\\nüìã PIPELINE CONFIGURATION\")\n    print(\"-\"*40)\n    print(f\"  ‚ñ∂ Preprocessing: {'‚úÖ Yes' if do_preprocess else '‚≠ï Skip'}\")\n    print(f\"  ‚ñ∂ Training:      {'‚úÖ Yes' if do_train else '‚≠ï Skip'}\")\n    print(f\"  ‚ñ∂ Inference:     {'‚úÖ Yes' if do_inference else '‚≠ï Skip'}\")\n    print(f\"  ‚ñ∂ Max cases:     {max_cases if max_cases else 'All'}\")\n    print(f\"  ‚ñ∂ Configuration: {CONFIGURATION}\")\n    print(f\"  ‚ñ∂ Epochs:        {EPOCHS}\")\n    print(f\"  ‚ñ∂ GPUs:          {NUM_GPUS}\")\n    print(\"-\"*40)\n    \n    # Step counter\n    current_step = 0\n    total_steps = sum([1, do_preprocess, do_train, do_inference])  # 1 for data prep\n    \n    def print_step(step_name: str, status: str = \"STARTING\"):\n        nonlocal current_step\n        current_step += 1\n        print(f\"\\n{'='*80}\")\n        print(f\"üìç STEP {current_step}/{total_steps}: {step_name}\")\n        print(f\"   Status: {status}\")\n        print(f\"{'='*80}\")\n    \n    # 1. Data preparation\n    print_step(\"DATA PREPARATION\")\n    dataset_path = NNUNET_RAW / DATASET_NAME\n    \n    if not dataset_path.exists():\n        if not data_downloaded:\n            print(\"   ‚ùå No data available\")\n            print(\"   üí° Please set up Kaggle authentication and download data\")\n            return False\n        \n        print(\"   üìÅ Preparing dataset from raw data...\")\n        dataset_dir = prepare_dataset(INPUT_DIR, max_cases=max_cases)\n        if not dataset_dir:\n            print(\"   ‚ùå Dataset preparation failed\")\n            return False\n        print(\"   ‚úÖ Dataset prepared successfully\")\n    else:\n        print(\"   ‚úÖ Dataset already exists\")\n        dataset_dir = dataset_path\n        \n        # Count files\n        images_dir = dataset_dir / \"imagesTr\"\n        if images_dir.exists():\n            nifti_count = len(list(images_dir.glob(\"*.nii.gz\")))\n            tiff_count = len(list(images_dir.glob(\"*.tif\")))\n            print(f\"   üìä Files: {nifti_count} NIfTI, {tiff_count} TIFF\")\n    \n    # Fix issues if dataset exists\n    if dataset_dir and dataset_dir.exists():\n        print(\"\\n   üîß Checking for issues...\")\n        \n        # Fix SimpleTiffIO\n        fix_dataset_json_ioclass(dataset_dir)\n        \n        # Convert TIFF to NIfTI if needed\n        print(\"   üîÑ Checking file formats...\")\n        if convert_tiff_dataset_to_nifti(dataset_dir):\n            print(\"   ‚úÖ File formats verified\")\n    \n    # 2. Preprocessing\n    if do_preprocess:\n        print_step(\"PREPROCESSING\", \"Running nnUNet planning and preprocessing\")\n        \n        print(f\"   Configuration: {CONFIGURATION}\")\n        print(f\"   Planner: {PLANNER}\")\n        print(f\"   Workers: {NUM_WORKERS}\")\n        \n        if not run_preprocessing(num_workers=NUM_WORKERS):\n            print(\"\\n   ‚ùå Preprocessing failed\")\n            print(\"   üîÑ Retrying with fewer workers...\")\n            \n            if not run_preprocessing(num_workers=2):\n                print(\"   ‚ùå Preprocessing failed again\")\n                return False\n        \n        print(\"   ‚úÖ Preprocessing completed successfully\")\n    else:\n        print(\"\\n   ‚≠ï Skipping preprocessing\")\n    \n    # 3. Training\n    if do_train:\n        print_step(\"TRAINING\", f\"Starting {EPOCHS} epoch training\")\n        \n        print(f\"   Model: ResidualEncoderUNet\")\n        print(f\"   Patch size: 128x128x128\")\n        print(f\"   Batch size: 2\")\n        print(f\"   Learning rate: PolyLR schedule\")\n        print(f\"\\n   üìä Training progress will be shown below:\")\n        print(\"   \" + \"-\"*40)\n        \n        if not run_training():\n            print(\"   ‚ùå Training failed\")\n            return False\n        \n        print(\"   ‚úÖ Training completed successfully\")\n    else:\n        print(\"\\n   ‚≠ï Skipping training\")\n    \n    # 4. Inference\n    if do_inference:\n        print_step(\"INFERENCE\", \"Running predictions on test data\")\n        \n        # Prepare test data\n        test_input_dir = WORKING_DIR / \"test_input\"\n        \n        if data_downloaded:\n            print(\"   üìÅ Preparing test data...\")\n            prepare_test_data(INPUT_DIR, test_input_dir)\n            \n            # Count test files\n            test_files = list(test_input_dir.glob(\"*.tif\")) + list(test_input_dir.glob(\"*.nii.gz\"))\n            print(f\"   üìä Test cases: {len(test_files)}\")\n        else:\n            print(\"   ‚ö†Ô∏è No test data available\")\n            return True\n        \n        # Run inference\n        print(\"   üîÆ Running inference...\")\n        predictions_dir = WORKING_DIR / \"predictions\"\n        \n        if not run_inference(test_input_dir, predictions_dir):\n            print(\"   ‚ùå Inference failed\")\n            return False\n        \n        # Convert predictions\n        print(\"   üìÑ Converting predictions to TIFF...\")\n        tiff_output_dir = OUTPUT_DIR / \"predictions_tiff\"\n        predictions_to_tiff(predictions_dir, tiff_output_dir)\n        \n        print(f\"   ‚úÖ Predictions saved to: {tiff_output_dir}\")\n    else:\n        print(\"\\n   ‚≠ï Skipping inference\")\n    \n    # Final summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"üéâ PIPELINE COMPLETED SUCCESSFULLY!\")\n    print(\"=\"*80)\n    \n    print(\"\\nüìä SUMMARY:\")\n    print(\"-\"*40)\n    \n    if do_preprocess:\n        preprocessed_dir = NNUNET_PREPROCESSED / DATASET_NAME\n        if preprocessed_dir.exists():\n            print(f\"  ‚úÖ Preprocessed data: {preprocessed_dir}\")\n    \n    if do_train:\n        results_dir = NNUNET_RESULTS / f\"Dataset{DATASET_ID:03d}_{DATASET_NAME}\" / f\"{PLANNER}__{CONFIGURATION}\"\n        if results_dir.exists():\n            print(f\"  ‚úÖ Training results: {results_dir}\")\n            \n            # Check for best model\n            best_model = results_dir / \"fold_all\" / \"checkpoint_best.pth\"\n            if best_model.exists():\n                size_mb = best_model.stat().st_size / (1024*1024)\n                print(f\"  ‚úÖ Best model saved: {size_mb:.1f}MB\")\n    \n    if do_inference:\n        if tiff_output_dir.exists():\n            pred_count = len(list(tiff_output_dir.glob(\"*.tif\")))\n            print(f\"  ‚úÖ Predictions: {pred_count} files\")\n    \n    print(\"-\"*40)\n    print(\"\\n‚ú® All tasks completed successfully!\")\n    \n    return True\n\nprint(\"‚úÖ Pipeline function ready with clear output formatting\")"
  },
  {
   "cell_type": "code",
   "id": "ggnunkjzdof",
   "source": "# Add this cell BEFORE full-pipeline cell\ndef check_saved_models():\n    \"\"\"Check what model checkpoints are available\"\"\"\n    print_header(\"CHECKPOINT MANAGER\", \"üíæ\")\n    \n    # Model directory\n    model_dir = NNUNET_RESULTS / f\"Dataset{DATASET_ID:03d}_{DATASET_NAME}\" / f\"{PLANNER}__{CONFIGURATION}\" / f\"fold_{FOLD}\"\n    \n    if not model_dir.exists():\n        print(\"üìÅ Model directory not found\")\n        print(f\"   Expected: {model_dir}\")\n        print(\"   üîÑ Models will be saved here after training\")\n        return None\n    \n    print(f\"üìÅ Model directory: {model_dir}\")\n    \n    # Check for checkpoint files\n    checkpoints = {\n        \"best\": model_dir / \"checkpoint_best.pth\",\n        \"final\": model_dir / \"checkpoint_final.pth\", \n        \"latest\": model_dir / \"checkpoint_latest.pth\"\n    }\n    \n    available_models = []\n    total_size = 0\n    \n    print(\"\\nüíæ Available checkpoints:\")\n    print(\"-\" * 50)\n    \n    for checkpoint_type, checkpoint_path in checkpoints.items():\n        if checkpoint_path.exists():\n            size_mb = checkpoint_path.stat().st_size / (1024 * 1024)\n            mtime = checkpoint_path.stat().st_mtime\n            import time\n            time_str = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime(mtime))\n            \n            print(f\"  ‚úÖ {checkpoint_type.upper()}: {checkpoint_path.name}\")\n            print(f\"     Size: {size_mb:.1f}MB | Modified: {time_str}\")\n            \n            available_models.append(checkpoint_type)\n            total_size += size_mb\n        else:\n            print(f\"  ‚ùå {checkpoint_type.upper()}: Not found\")\n    \n    # Check for additional files\n    print(\"\\nüìä Additional files:\")\n    print(\"-\" * 50)\n    \n    additional_files = [\n        (\"progress.png\", \"Learning curves\"),\n        (\"training_log.txt\", \"Training log\"),\n        (\"plans.json\", \"Model configuration\")\n    ]\n    \n    for filename, description in additional_files:\n        file_path = model_dir / filename\n        if file_path.exists():\n            size_kb = file_path.stat().st_size / 1024\n            print(f\"  ‚úÖ {filename}: {description} ({size_kb:.1f}KB)\")\n        else:\n            # Check for pattern matches (logs often have timestamps)\n            if filename == \"training_log.txt\":\n                log_files = list(model_dir.glob(\"training_log_*.txt\"))\n                if log_files:\n                    for log_file in log_files:\n                        size_kb = log_file.stat().st_size / 1024\n                        print(f\"  ‚úÖ {log_file.name}: Training log ({size_kb:.1f}KB)\")\n                else:\n                    print(f\"  ‚ùå {filename}: Not found\")\n            else:\n                print(f\"  ‚ùå {filename}: Not found\")\n    \n    if available_models:\n        print(f\"\\nüìà Summary:\")\n        print(f\"  ‚Ä¢ Available models: {', '.join(available_models)}\")\n        print(f\"  ‚Ä¢ Total size: {total_size:.1f}MB\")\n        print(f\"  ‚Ä¢ Ready for inference: {'‚úÖ Yes' if 'best' in available_models else '‚ùå No (need training)'}\")\n        \n        # Show inference command\n        if 'best' in available_models:\n            print(f\"\\nüöÄ Ready to use for inference!\")\n            print(f\"   The 'best' model will be automatically used for predictions.\")\n    \n    return model_dir if available_models else None\n\ndef cleanup_old_checkpoints(keep_best: bool = True, keep_latest: bool = True):\n    \"\"\"Clean up old checkpoint files to save disk space\"\"\"\n    model_dir = NNUNET_RESULTS / f\"Dataset{DATASET_ID:03d}_{DATASET_NAME}\" / f\"{PLANNER}__{CONFIGURATION}\" / f\"fold_{FOLD}\"\n    \n    if not model_dir.exists():\n        print(\"üìÅ No model directory found\")\n        return\n    \n    print_header(\"CHECKPOINT CLEANUP\", \"üßπ\")\n    \n    total_freed = 0\n    files_removed = 0\n    \n    # Files to potentially clean up\n    cleanup_candidates = []\n    \n    if not keep_latest:\n        cleanup_candidates.append(\"checkpoint_latest.pth\")\n    \n    # Add other checkpoint files if they exist\n    for checkpoint_file in model_dir.glob(\"checkpoint_epoch_*.pth\"):\n        cleanup_candidates.append(checkpoint_file.name)\n    \n    print(f\"üîç Scanning: {model_dir}\")\n    print(f\"üõ°Ô∏è Protected files: \", end=\"\")\n    protected = []\n    if keep_best:\n        protected.append(\"checkpoint_best.pth\")\n    if keep_latest:\n        protected.append(\"checkpoint_latest.pth\")\n    protected.append(\"checkpoint_final.pth\")\n    print(\", \".join(protected))\n    \n    print(f\"\\nüßπ Cleanup candidates:\")\n    \n    for filename in cleanup_candidates:\n        file_path = model_dir / filename\n        if file_path.exists():\n            size_mb = file_path.stat().st_size / (1024 * 1024)\n            print(f\"  üóëÔ∏è {filename}: {size_mb:.1f}MB\")\n            try:\n                file_path.unlink()\n                total_freed += size_mb\n                files_removed += 1\n                print(f\"     ‚úÖ Removed\")\n            except Exception as e:\n                print(f\"     ‚ùå Error: {e}\")\n        else:\n            print(f\"  ‚ö™ {filename}: Not found\")\n    \n    print(f\"\\nüìä Cleanup summary:\")\n    print(f\"  ‚Ä¢ Files removed: {files_removed}\")\n    print(f\"  ‚Ä¢ Space freed: {total_freed:.1f}MB\")\n\nprint(\"‚úÖ Checkpoint management functions ready\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0qjslld2qlmf",
   "source": "# Add this cell BEFORE full-pipeline cell\ndef convert_tiff_dataset_to_nifti(dataset_path: Path) -> bool:\n    \"\"\"Convert TIFF dataset to NIfTI format to fix 3D image reading issues\"\"\"\n    \n    print(\"üîÑ Converting TIFF files to NIfTI format...\")\n    \n    # Check if already converted\n    images_dir = dataset_path / \"imagesTr\"\n    if images_dir.exists():\n        tiff_count = len(list(images_dir.glob(\"*.tif\")))\n        nifti_count = len(list(images_dir.glob(\"*.nii.gz\")))\n        \n        if tiff_count == 0 and nifti_count > 0:\n            print(f\"  ‚úÖ Already converted: {nifti_count} NIfTI files found\")\n            return True\n    \n    try:\n        import tifffile\n    except ImportError:\n        print(\"  Installing tifffile...\")\n        import subprocess\n        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"tifffile\", \"-q\"])\n        import tifffile\n    \n    converted_count = 0\n    \n    # Convert images\n    if images_dir.exists():\n        tiff_files = list(images_dir.glob(\"*.tif\"))\n        if tiff_files:\n            print(f\"  Converting {len(tiff_files)} image files...\")\n            \n            for tiff_file in tqdm(tiff_files, desc=\"Images\"):\n                nifti_file = tiff_file.with_suffix('').with_suffix('.nii.gz')\n                \n                if not nifti_file.exists():\n                    try:\n                        # Load TIFF\n                        img_data = tifffile.imread(str(tiff_file))\n                        \n                        # Ensure 3D\n                        if len(img_data.shape) == 2:\n                            img_data = img_data[np.newaxis, :, :]\n                        \n                        # Save as NIfTI\n                        affine = np.eye(4)\n                        nifti_img = nib.Nifti1Image(img_data.astype(np.float32), affine)\n                        nib.save(nifti_img, str(nifti_file))\n                        \n                        # Remove TIFF\n                        tiff_file.unlink()\n                        converted_count += 1\n                        \n                    except Exception as e:\n                        print(f\"    ‚ùå Error: {tiff_file.name} - {e}\")\n    \n    # Convert labels\n    labels_dir = dataset_path / \"labelsTr\"\n    if labels_dir.exists():\n        tiff_files = list(labels_dir.glob(\"*.tif\"))\n        if tiff_files:\n            print(f\"  Converting {len(tiff_files)} label files...\")\n            \n            for tiff_file in tqdm(tiff_files, desc=\"Labels\"):\n                nifti_file = tiff_file.with_suffix('').with_suffix('.nii.gz')\n                \n                if not nifti_file.exists():\n                    try:\n                        # Load TIFF\n                        label_data = tifffile.imread(str(tiff_file))\n                        \n                        # Ensure 3D\n                        if len(label_data.shape) == 2:\n                            label_data = label_data[np.newaxis, :, :]\n                        \n                        # Save as NIfTI\n                        affine = np.eye(4)\n                        nifti_img = nib.Nifti1Image(label_data.astype(np.uint8), affine)\n                        nib.save(nifti_img, str(nifti_file))\n                        \n                        # Remove TIFF\n                        tiff_file.unlink()\n                        converted_count += 1\n                        \n                    except Exception as e:\n                        print(f\"    ‚ùå Error: {tiff_file.name} - {e}\")\n    \n    # Update dataset.json\n    json_path = dataset_path / \"dataset.json\"\n    if json_path.exists():\n        with open(json_path, 'r') as f:\n            config = json.load(f)\n        \n        config['file_ending'] = '.nii.gz'\n        \n        # Remove SimpleTiffIO references\n        if 'overwrite_image_reader_writer' in config:\n            del config['overwrite_image_reader_writer']\n        if 'ioclass' in config:\n            del config['ioclass']\n        \n        with open(json_path, 'w') as f:\n            json.dump(config, f, indent=4)\n        \n        print(\"  ‚úÖ Updated dataset.json for NIfTI format\")\n    \n    if converted_count > 0:\n        print(f\"‚úÖ Converted {converted_count} files to NIfTI format\")\n    \n    return True\n\nprint(\"‚úÖ TIFF to NIfTI conversion function ready\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete pipeline\n",
    "# Adjust parameters based on your needs:\n",
    "\n",
    "# For quick testing (few cases, no training)\n",
    "# success = full_pipeline(do_train=False, do_inference=False, max_cases=5)\n",
    "\n",
    "# For full training run\n",
    "success = full_pipeline(max_cases=50)  # Limit cases for testing\n",
    "\n",
    "if success:\n",
    "    print(\"\\nüéä All done! Check /workspace/results/ for outputs\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Pipeline failed. Check error messages above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_submission_zip():\n",
    "    \"\"\"Create submission ZIP from predictions.\"\"\"\n",
    "    import zipfile\n",
    "    \n",
    "    predictions_dir = OUTPUT_DIR / \"predictions_tiff\"\n",
    "    submission_path = OUTPUT_DIR / \"submission.zip\"\n",
    "    \n",
    "    if not predictions_dir.exists():\n",
    "        print(f\"‚ùå No predictions found at {predictions_dir}\")\n",
    "        return None\n",
    "    \n",
    "    tiff_files = list(predictions_dir.glob(\"*.tif\"))\n",
    "    if not tiff_files:\n",
    "        print(\"‚ùå No TIFF files found\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"üì¶ Creating submission with {len(tiff_files)} files...\")\n",
    "    \n",
    "    with zipfile.ZipFile(submission_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for tiff_path in tqdm(tiff_files, desc=\"Zipping\"):\n",
    "            zipf.write(tiff_path, tiff_path.name)\n",
    "    \n",
    "    size_mb = submission_path.stat().st_size / (1024 * 1024)\n",
    "    print(f\"‚úÖ Submission created: {submission_path} ({size_mb:.1f} MB)\")\n",
    "    \n",
    "    return submission_path\n",
    "\n",
    "# Create submission if we have predictions\n",
    "if success and (OUTPUT_DIR / \"predictions_tiff\").exists():\n",
    "    submission_zip = create_submission_zip()\n",
    "    if submission_zip:\n",
    "        print(f\"\\nüèÜ Ready for submission: {submission_zip}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No predictions available for submission\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}