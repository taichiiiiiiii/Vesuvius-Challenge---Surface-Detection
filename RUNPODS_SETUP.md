# Runpods Setup Guide for Vesuvius Challenge PyTorch Training

Runpodsã§Vesuvius Challenge PyTorchãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å®Ÿè¡Œã™ã‚‹ãŸã‚ã®å®Œå…¨ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¬ã‚¤ãƒ‰

## ğŸš€ Quick Start

### 1. Runpodsã§ãƒãƒƒãƒ‰ã‚’ä½œæˆ

1. **[Runpods](https://www.runpods.io/)ã«ãƒ­ã‚°ã‚¤ãƒ³**
2. **"Deploy"ã‚’ã‚¯ãƒªãƒƒã‚¯**
3. **æ¨å¥¨GPUè¨­å®š:**

| GPU | VRAM | æ¨å¥¨è¨­å®š | æ™‚é–“å˜ä¾¡ç›®å®‰ |
|-----|------|----------|-------------|
| RTX 3080 | 10GB | input_shape=(64,64,64) | $0.3-0.4/h |
| RTX 3090 | 24GB | input_shape=(128,128,128) | $0.4-0.6/h |
| RTX 4090 | 24GB | input_shape=(128,128,128) | $0.6-0.8/h |
| A100 80GB | 80GB | input_shape=(128,128,128), batch_size=4 | $1.5-2.5/h |

4. **Templateã‚’é¸æŠ:**
   - **PyTorch 2.0** ã¾ãŸã¯ **RunPod PyTorch**
   - **Jupyter Lab** ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚’é¸æŠ

### 2. ç’°å¢ƒã®æº–å‚™

ãƒãƒƒãƒ‰ãŒèµ·å‹•ã—ãŸã‚‰ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ä»¥ä¸‹ã‚’å®Ÿè¡Œ:

```bash
# 1. å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install keras>=3.0
pip install git+https://github.com/innat/medic-ai.git
pip install tensorflow  # tf.dataã®ã¿ä½¿ç”¨
pip install matplotlib seaborn tqdm

# 2. PyTorchãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

### 3. ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™

```bash
# GitHubã‹ã‚‰ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å–å¾—
git clone https://github.com/taichiiiiiiii/Vesuvius-Challenge---Surface-Detection.git
cd "Vesuvius-Challenge---Surface-Detection"

# Jupyter Labã‚’èµ·å‹• (ã™ã§ã«èµ·å‹•ã—ã¦ã„ã‚Œã°ä¸è¦)
jupyter lab --ip=0.0.0.0 --port=8888 --allow-root --no-browser
```

## ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™

### Option 1: Kaggle Dataset (æ¨å¥¨)

```bash
# 1. Kaggle APIã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install kaggle

# 2. Kaggleèªè¨¼è¨­å®š
# Kaggle -> Account -> API -> Create New API Token
# kaggle.jsonãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
mkdir ~/.kaggle
# kaggle.jsonã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (Runpods File Managerä½¿ç”¨)
chmod 600 ~/.kaggle/kaggle.json

# 3. Vesuvius TFRecordãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
kaggle datasets download -d your-username/vesuvius-tfrecords
unzip vesuvius-tfrecords.zip -d ./data/
```

### Option 2: Direct Upload

```bash
# Runpodsã®File Managerã‚’ä½¿ç”¨ã—ã¦TFRecordãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç›´æ¥ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
mkdir -p ./data/
# TFRecordãƒ•ã‚¡ã‚¤ãƒ« (*.tfrec) ã‚’ ./data/ ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
```

### Option 3: Google Drive Mount

```bash
# Google Driveãƒã‚¦ãƒ³ãƒˆ (ãƒ‡ãƒ¼ã‚¿ãŒå¤§ãã„å ´åˆ)
pip install gdown
# Google Driveã®ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’ä½¿ç”¨
gdown --id YOUR_DRIVE_FILE_ID
```

## âš™ï¸ ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯è¨­å®šã®èª¿æ•´

### GPU ãƒ¡ãƒ¢ãƒªã«å¿œã˜ãŸè¨­å®šèª¿æ•´

ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®Cell 10ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«ä¿®æ­£:

```python
# === GPU ãƒ¡ãƒ¢ãƒªåˆ¥æ¨å¥¨è¨­å®š ===

# RTX 3080 (10GB) ã®å ´åˆ
input_shape = (64, 64, 64)
batch_size = 1 * total_device
epochs = 200

# RTX 3090/4090 (24GB) ã®å ´åˆ
input_shape = (96, 96, 96)  # ã¾ãŸã¯ (128, 128, 128)
batch_size = 1 * total_device
epochs = 200

# A100 (80GB) ã®å ´åˆ
input_shape = (128, 128, 128)
batch_size = 2 * total_device  # ã‚ˆã‚Šå¤§ããªãƒãƒƒãƒã‚µã‚¤ã‚º
epochs = 200
```

### ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ã®ä¿®æ­£

ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®Cell 17ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«ä¿®æ­£:

```python
# Runpodsç’°å¢ƒç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹
all_tfrec = sorted(
    glob.glob("./data/*.tfrec"),  # Kaggleãƒ‘ã‚¹ã‹ã‚‰å¤‰æ›´
    key=lambda x: int(x.split("_")[-1].replace(".tfrec", ""))
)

# ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
if not all_tfrec:
    print("TFRecord files not found in ./data/")
    print("Please upload TFRecord files to ./data/ directory")
    print("Available files:", glob.glob("./data/*"))
```

### é«˜é€ŸåŒ–è¨­å®š (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)

```python
# Cell 34ã®æå¤±é–¢æ•°ã‚’è»½é‡åŒ– (å¿…è¦ã«å¿œã˜ã¦)
cldice_loss_fn = SparseCenterlineDiceLoss(
    from_logits=False, 
    num_classes=num_classes,
    target_class_ids=1,
    ignore_class_ids=2,
    iters=25  # 50ã‹ã‚‰25ã«å‰Šæ¸› (é«˜é€ŸåŒ–)
)

# ã‚¨ãƒãƒƒã‚¯æ•°ã‚’èª¿æ•´ (ãƒ†ã‚¹ãƒˆç”¨)
epochs = 50  # 200ã‹ã‚‰50ã«å‰Šæ¸›
```

## ğŸ”§ Runpodså›ºæœ‰ã®æœ€é©åŒ–

### 1. æ°¸ç¶šã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã®è¨­å®š

```bash
# æ°¸ç¶šã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ãƒã‚¦ãƒ³ãƒˆ (æœ‰æ–™ãƒ—ãƒ©ãƒ³ã®å ´åˆ)
# Network Storage ã‚’ä½œæˆã—ã€ãƒãƒƒãƒ‰ä½œæˆæ™‚ã«ã‚¢ã‚¿ãƒƒãƒ
# ãƒ¢ãƒ‡ãƒ«ã¨çµæœã‚’æ°¸ç¶šã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜
ln -s /workspace/persistent_storage ./models
```

### 2. è‡ªå‹•ä¿å­˜ã®å¼·åŒ–

ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«ä»¥ä¸‹ã®ã‚»ãƒ«ã‚’è¿½åŠ :

```python
# å®šæœŸä¿å­˜è¨­å®š (Runpodsç”¨)
import shutil
from pathlib import Path

def setup_runpods_saving():
    """Runpodsç”¨ã®è‡ªå‹•ä¿å­˜è¨­å®š"""
    
    # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    save_dirs = ['./checkpoints', './results', './logs']
    for dir_path in save_dirs:
        Path(dir_path).mkdir(exist_ok=True)
    
    # å®šæœŸãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ (10ã‚¨ãƒãƒƒã‚¯æ¯)
    checkpoint_callback = keras.callbacks.ModelCheckpoint(
        filepath='./checkpoints/model_epoch_{epoch:03d}_dice_{val_dice:.4f}.h5',
        monitor='val_dice',
        mode='max',
        save_best_only=False,
        save_freq=10 * steps_per_epoch,  # 10ã‚¨ãƒãƒƒã‚¯æ¯
        verbose=1
    )
    
    return checkpoint_callback

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒªã‚¹ãƒˆã«è¿½åŠ 
enhanced_callbacks.append(setup_runpods_saving())
```

### 3. ãƒ¡ãƒ¢ãƒªç›£è¦–ã®å¼·åŒ–

```python
# Runpodsç”¨ãƒ¡ãƒ¢ãƒªç›£è¦–
class RunpodsMonitorCallback(keras.callbacks.Callback):
    def __init__(self):
        super().__init__()
        self.start_time = None
        
    def on_train_begin(self, logs=None):
        self.start_time = time.time()
        
    def on_epoch_end(self, epoch, logs=None):
        if torch.cuda.is_available():
            allocated = torch.cuda.memory_allocated(0) / 1024**3
            reserved = torch.cuda.memory_reserved(0) / 1024**3
            free = torch.cuda.get_device_properties(0).total_memory / 1024**3 - reserved
            
            elapsed = time.time() - self.start_time
            epoch_time = elapsed / (epoch + 1)
            remaining = epoch_time * (epochs - epoch - 1)
            
            print(f"Epoch {epoch+1} - GPU: {allocated:.2f}GB used, {free:.2f}GB free")
            print(f"Time: {elapsed/3600:.1f}h elapsed, {remaining/3600:.1f}h remaining")
            
            # ãƒ¡ãƒ¢ãƒªä¸è¶³è­¦å‘Š
            if allocated > torch.cuda.get_device_properties(0).total_memory / 1024**3 * 0.9:
                print("âš ï¸  GPU memory usage is high! Consider reducing input_shape or batch_size.")

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«è¿½åŠ 
enhanced_callbacks.append(RunpodsMonitorCallback())
```

## ğŸš¨ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### CUDA/PyTorché–¢é€£

```bash
# CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
nvidia-smi

# PyTorchã¨CUDAã®äº’æ›æ€§ç¢ºèª
python -c "import torch; print(torch.version.cuda, torch.cuda.is_available())"

# CUDAå†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« (å¿…è¦ã«å¿œã˜ã¦)
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### ãƒ¡ãƒ¢ãƒªã‚¨ãƒ©ãƒ¼

```python
# Cell 10ã®è¨­å®šã‚’å°ã•ã
input_shape = (32, 64, 64)  # ã‚ˆã‚Šå°ã•ã
batch_size = 1
cldice_loss_fn = SparseCenterlineDiceLoss(iters=10)  # ã‚ˆã‚Šå°‘ãªã
```

### ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼

```bash
# TFRecordãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
ls -la ./data/
python -c "
import glob
files = glob.glob('./data/*.tfrec')
print(f'Found {len(files)} TFRecord files')
for f in files[:5]: print(f)
"
```

### æ¥ç¶šãŒåˆ‡ã‚Œã‚‹å ´åˆ

```bash
# tmux/screenã‚’ä½¿ç”¨ (é•·æ™‚é–“è¨“ç·´ç”¨)
tmux new-session -d -s training
tmux send-keys -t training 'cd /workspace && jupyter lab' Enter

# ã‚»ãƒƒã‚·ãƒ§ãƒ³å¾©å¸°
tmux attach -t training
```

## ğŸ’° ã‚³ã‚¹ãƒˆæœ€é©åŒ–ã®ãƒ’ãƒ³ãƒˆ

### 1. é©åˆ‡ãªGPUé¸æŠ

```python
# ã‚³ã‚¹ãƒˆåŠ¹ç‡ã®è‰¯ã„è¨­å®š
# RTX 3080: $0.3/h, input_shape=(64,64,64)
# 24æ™‚é–“ã§ç´„$7.2, Diceã‚¹ã‚³ã‚¢ 0.7-0.8 æœŸå¾…

# é«˜æ€§èƒ½è¨­å®š  
# A100: $2/h, input_shape=(128,128,128), batch_size=4
# 12æ™‚é–“ã§ç´„$24, Diceã‚¹ã‚³ã‚¢ 0.8+ æœŸå¾…
```

### 2. æ®µéšçš„å­¦ç¿’

```python
# Phase 1: å°ã•ãªã‚µã‚¤ã‚ºã§é«˜é€Ÿãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ— (2-3æ™‚é–“)
input_shape = (64, 64, 64)
epochs = 50

# Phase 2: æœ¬æ ¼è¨“ç·´ (8-12æ™‚é–“)
input_shape = (128, 128, 128)  
epochs = 200
```

### 3. Auto-Stopè¨­å®š

```python
# æ—©æœŸåœæ­¢ã‚’ç©æ¥µçš„ã«ä½¿ç”¨
keras.callbacks.EarlyStopping(
    monitor='val_dice',
    patience=15,  # ã‚ˆã‚ŠçŸ­ã
    mode='max',
    restore_best_weights=True,
    min_delta=0.001  # æ”¹å–„é–¾å€¤
)
```

## ğŸ¯ å®Ÿè¡Œæ‰‹é †ã¾ã¨ã‚

1. **Runpodsã§ãƒãƒƒãƒ‰ä½œæˆ** (RTX 3090æ¨å¥¨)
2. **ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—** (pip install)
3. **ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³** 
4. **ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰** (TFRecordãƒ•ã‚¡ã‚¤ãƒ«)
5. **è¨­å®šèª¿æ•´** (GPU ãƒ¡ãƒ¢ãƒªã«å¿œã˜ã¦)
6. **ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Ÿè¡Œ** (train-vesuvius-surface-3d-detection-pytorch-backend.ipynb)
7. **çµæœä¿å­˜** (checkpoints, models)

## â±ï¸ æœŸå¾…ã•ã‚Œã‚‹å®Ÿè¡Œæ™‚é–“

| GPU | è¨­å®š | æ™‚é–“ç›®å®‰ | ã‚³ã‚¹ãƒˆç›®å®‰ |
|-----|------|----------|------------|
| RTX 3080 | (64,64,64), 200ep | 18-24h | $5-10 |
| RTX 3090 | (96,96,96), 200ep | 12-18h | $5-11 |
| RTX 4090 | (128,128,128), 200ep | 8-12h | $5-10 |
| A100 | (128,128,128), 200ep, bs=4 | 6-8h | $10-20 |

ã“ã‚Œã§Runpodsã§åŠ¹ç‡çš„ã«å­¦ç¿’ã‚’å®Ÿè¡Œã§ãã¾ã™ï¼
