{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸº SwinUNETR for Vesuvius Challenge - Runpodså®Œå…¨ç‰ˆ\n",
    "\n",
    "**1ã¤ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§å®Œçµ** - å¤–éƒ¨ä¾å­˜ãªã—ã€å®Ÿãƒ‡ãƒ¼ã‚¿å®Œå…¨å¯¾å¿œ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Step 1: ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨Kaggleèªè¨¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®è‡ªå‹•ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\"\"\"\n",
    "    requirements = [\n",
    "        \"torch>=1.12.0\",\n",
    "        \"torchvision>=0.13.0\", \n",
    "        \"torchaudio>=0.12.0\",\n",
    "        \"kaggle\",\n",
    "        \"numpy\",\n",
    "        \"matplotlib\",\n",
    "        \"scipy\",\n",
    "        \"pillow\",\n",
    "        \"tqdm\",\n",
    "        \"tensorboard\",\n",
    "        \"einops\",\n",
    "        \"opencv-python\"\n",
    "    ]\n",
    "    \n",
    "    for req in requirements:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", req, \"-q\"], \n",
    "                          check=True, capture_output=True)\n",
    "            print(f\"âœ… {req}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"âš ï¸ {req} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—\")\n",
    "\n",
    "print(\"ğŸ“¦ Runpods SwinUNETRç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...\")\n",
    "install_requirements()\n",
    "print(\"âœ… ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggleèªè¨¼è¨­å®šï¼ˆRunpodså¯¾å¿œï¼‰\n",
    "import json\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def setup_kaggle_auth_runpods(username=None, key=None):\n",
    "    \"\"\"Runpodsç’°å¢ƒã§Kaggleèªè¨¼è¨­å®š\"\"\"\n",
    "    \n",
    "    # Runpodsç’°å¢ƒã§ã®èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«å€™è£œ\n",
    "    possible_locations = [\n",
    "        Path(\"/workspace/kaggle.json\"),\n",
    "        Path(\"/workspace/.kaggle/kaggle.json\"),\n",
    "        Path.home() / \".kaggle\" / \"kaggle.json\",\n",
    "        Path(\"./kaggle.json\"),\n",
    "        Path(\"/content/kaggle.json\")\n",
    "    ]\n",
    "    \n",
    "    # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª\n",
    "    for location in possible_locations:\n",
    "        if location.exists():\n",
    "            print(f\"âœ… Kaggleèªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {location}\")\n",
    "            # ç’°å¢ƒå¤‰æ•°è¨­å®šï¼ˆå¿…è¦ãªå ´åˆï¼‰\n",
    "            if location.parent.name != \".kaggle\":\n",
    "                os.environ['KAGGLE_CONFIG_DIR'] = str(location.parent)\n",
    "            return True\n",
    "    \n",
    "    # èªè¨¼æƒ…å ±ãŒæä¾›ã•ã‚ŒãŸå ´åˆã¯ä½œæˆ\n",
    "    if username and key:\n",
    "        kaggle_config = {\"username\": username, \"key\": key}\n",
    "        \n",
    "        # Runpodsç’°å¢ƒãƒã‚§ãƒƒã‚¯\n",
    "        if Path(\"/workspace\").exists():\n",
    "            kaggle_path = Path(\"/workspace/kaggle.json\")\n",
    "        else:\n",
    "            kaggle_path = Path(\"./kaggle.json\")\n",
    "        \n",
    "        # ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ\n",
    "        with open(kaggle_path, 'w') as f:\n",
    "            json.dump(kaggle_config, f)\n",
    "        \n",
    "        # ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³è¨­å®š\n",
    "        kaggle_path.chmod(0o600)\n",
    "        \n",
    "        # ç’°å¢ƒå¤‰æ•°è¨­å®š\n",
    "        os.environ['KAGGLE_CONFIG_DIR'] = str(kaggle_path.parent)\n",
    "        \n",
    "        print(f\"âœ… Kaggleèªè¨¼è¨­å®šå®Œäº†: {kaggle_path}\")\n",
    "        return True\n",
    "    \n",
    "    print(\"âš ï¸ Kaggleèªè¨¼ãŒå¿…è¦ã§ã™\")\n",
    "    print(\"æ¬¡ã®ã‚»ãƒ«ã§: setup_kaggle_auth_runpods(username='YOUR_USERNAME', key='YOUR_KEY')\")\n",
    "    return False\n",
    "\n",
    "# èªè¨¼ç¢ºèª\n",
    "auth_ready = setup_kaggle_auth_runpods()\n",
    "print(f\"Kaggleèªè¨¼çŠ¶æ³: {'âœ… æº–å‚™å®Œäº†' if auth_ready else 'âŒ è¨­å®šå¿…è¦'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# èªè¨¼æƒ…å ±è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦å®Ÿè¡Œï¼‰\n",
    "# setup_kaggle_auth_runpods(username=\"YOUR_KAGGLE_USERNAME\", key=\"YOUR_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Step 2: Vesuviusãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Vesuvius ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆRunpodsæœ€é©åŒ–ï¼‰\nimport zipfile\nimport subprocess\nfrom pathlib import Path\nfrom tqdm.auto import tqdm\nimport time\n\ndef download_vesuvius_runpods():\n    \"\"\"Runpodsç’°å¢ƒã§Vesuviusãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\"\"\"\n    \n    # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®šï¼ˆRunpodsç’°å¢ƒï¼‰\n    if Path(\"/workspace\").exists():\n        data_dir = Path(\"/workspace/data\")\n    else:\n        data_dir = Path(\"./data\")\n    \n    data_dir.mkdir(parents=True, exist_ok=True)\n    dataset_dir = data_dir / \"vesuvius-challenge-surface-detection\"\n    \n    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n    print(\"ğŸ” æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ç¢ºèªä¸­...\")\n    if dataset_dir.exists():\n        train_images = dataset_dir / \"train_images\"\n        if train_images.exists():\n            tiff_files = list(train_images.glob(\"*.tif\"))\n            if len(tiff_files) > 0:\n                print(f\"âœ… ãƒ‡ãƒ¼ã‚¿æ—¢å­˜ç¢ºèª: {len(tiff_files)}ç”»åƒ\")\n                return str(dataset_dir)\n    \n    print(\"ğŸ“¥ Vesuviusãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹...\")\n    print(f\"   ä¿å­˜å…ˆ: {data_dir}\")\n    \n    try:\n        # Kaggle CLIã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\n        cmd = f\"kaggle competitions download -c vesuvius-challenge-surface-detection -p {data_dir}\"\n        \n        print(\"â³ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é–‹å§‹... (ç´„10-20åˆ†ã‹ã‹ã‚Šã¾ã™)\")\n        \n        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ä»˜ããƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n        with tqdm(total=100, desc=\"ğŸ“¥ Kaggleãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\", unit=\"%\") as pbar:\n            start_time = time.time()\n            process = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE, \n                                     stderr=subprocess.PIPE, text=True)\n            \n            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€²æ—ç›£è¦–\n            while process.poll() is None:\n                zip_file = data_dir / \"vesuvius-challenge-surface-detection.zip\"\n                if zip_file.exists():\n                    size_mb = zip_file.stat().st_size / (1024 * 1024)\n                    # æ¦‚ç®—é€²æ—ï¼ˆæ¨å®š15GBï¼‰\n                    progress = min(100, (size_mb / 15000) * 100)\n                    pbar.n = int(progress)\n                    pbar.set_postfix({\n                        'ã‚µã‚¤ã‚º': f'{size_mb:.0f}MB',\n                        'æ™‚é–“': f'{(time.time() - start_time)/60:.1f}åˆ†'\n                    })\n                    pbar.refresh()\n                time.sleep(10)\n            \n            pbar.n = 100\n            pbar.refresh()\n        \n        result = process.communicate()\n        \n        if process.returncode == 0:\n            print(\"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n            \n            # ZIPè§£å‡ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\n            zip_file = data_dir / \"vesuvius-challenge-surface-detection.zip\"\n            if zip_file.exists():\n                print(\"ğŸ“¦ ãƒ‡ãƒ¼ã‚¿è§£å‡ä¸­...\")\n                \n                with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n                    files_list = zip_ref.infolist()\n                    \n                    with tqdm(total=len(files_list), desc=\"ğŸ“¦ è§£å‡é€²è¡Œ\", unit=\"file\") as pbar:\n                        for file_info in files_list:\n                            zip_ref.extract(file_info, data_dir)\n                            pbar.update(1)\n                            pbar.set_postfix({\n                                'ãƒ•ã‚¡ã‚¤ãƒ«': file_info.filename.split('/')[-1][:20] + '...'\n                            })\n                \n                # ZIPå‰Šé™¤ï¼ˆå®¹é‡ç¯€ç´„ï¼‰\n                zip_file.unlink()\n                print(\"âœ… è§£å‡å®Œäº†ãƒ»ZIPå‰Šé™¤\")\n            \n            return str(dataset_dir)\n            \n        else:\n            print(f\"âŒ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {result[1] if result[1] else 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼'}\")\n            return None\n            \n    except Exception as e:\n        print(f\"âŒ ã‚¨ãƒ©ãƒ¼: {e}\")\n        return None\n\n# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Ÿè¡Œ\nvesuvius_data_path = download_vesuvius_runpods()\n\nif vesuvius_data_path:\n    print(f\"ğŸ‰ ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†: {vesuvius_data_path}\")\n    DATA_READY = True\nelse:\n    print(\"âš ï¸ å®Ÿãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•— - ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ç¶™ç¶š\")\n    DATA_READY = False"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”§ Step 3: ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆã¨è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import warnings\n",
    "import math\n",
    "from datetime import datetime\n",
    "from typing import Tuple, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "\n",
    "# PyTorchãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from einops import rearrange\n",
    "\n",
    "# è­¦å‘Šéè¡¨ç¤º\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸº SwinUNETR Vesuvius Challenge - Runpodså®Œå…¨ç‰ˆ\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "    print(f\"VRAM: {gpu_memory:.1f} GB\")\n",
    "\n",
    "# å†ç¾æ€§ç¢ºä¿\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUè‡ªå‹•è¨­å®šã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿\n",
    "def setup_runpods_config():\n",
    "    \"\"\"Runpodsç’°å¢ƒã«æœ€é©åŒ–ã•ã‚ŒãŸè¨­å®š\"\"\"\n",
    "    \n",
    "    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        \n",
    "        print(f\"ğŸ”§ GPUè‡ªå‹•æ¤œå‡º: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "        \n",
    "        # GPUåˆ¥æœ€é©åŒ–ï¼ˆRunpodså‘ã‘ï¼‰\n",
    "        if 'A100' in gpu_name:\n",
    "            batch_size, embed_dim, depths = 3, 96, [2, 2, 6, 2]\n",
    "            print(\"ğŸš€ A100æ¤œå‡º - æœ€é«˜æ€§èƒ½è¨­å®š\")\n",
    "        elif 'A6000' in gpu_name or 'A5000' in gpu_name:\n",
    "            batch_size, embed_dim, depths = 2, 72, [2, 2, 4, 2]\n",
    "            print(\"ğŸ’ª A6000/A5000æ¤œå‡º - é«˜æ€§èƒ½è¨­å®š\")\n",
    "        elif 'RTX 4090' in gpu_name or 'RTX 3090' in gpu_name:\n",
    "            batch_size, embed_dim, depths = 2, 64, [1, 2, 4, 1]\n",
    "            print(\"âš¡ RTX 40/30ã‚·ãƒªãƒ¼ã‚ºæ¤œå‡º - æ¨™æº–è¨­å®š\")\n",
    "        else:\n",
    "            batch_size, embed_dim, depths = 1, 48, [1, 1, 3, 1]\n",
    "            print(\"ğŸ“Š æ¨™æº–GPU - ã‚»ãƒ¼ãƒ•è¨­å®š\")\n",
    "            \n",
    "        use_amp = True\n",
    "        num_workers = 4\n",
    "    else:\n",
    "        print(\"âŒ GPUæœªæ¤œå‡º - CPUè¨­å®š\")\n",
    "        batch_size, embed_dim, depths = 1, 24, [1, 1, 1, 1]\n",
    "        use_amp = False\n",
    "        num_workers = 0\n",
    "    \n",
    "    config = {\n",
    "        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
    "        'device': device,\n",
    "        'use_amp': use_amp,\n",
    "        'num_workers': num_workers,\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿è¨­å®š\n",
    "        'input_shape': (96, 96, 96),  # SwinUNETRæ¨å¥¨ã‚µã‚¤ã‚º\n",
    "        'in_channels': 1,\n",
    "        'out_channels': 2,\n",
    "        'batch_size': batch_size,\n",
    "        'validation_split': 0.2,\n",
    "        \n",
    "        # å­¦ç¿’è¨­å®š\n",
    "        'epochs': 30,\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-5,\n",
    "        \n",
    "        # SwinUNETRè¨­å®šï¼ˆGPUåˆ¥æœ€é©åŒ–ï¼‰\n",
    "        'img_size': (96, 96, 96),\n",
    "        'patch_size': (2, 2, 2),\n",
    "        'embed_dim': embed_dim,\n",
    "        'depths': depths,\n",
    "        'num_heads': [embed_dim//24, embed_dim//12, embed_dim//6, embed_dim//3],\n",
    "        'window_size': [7, 7, 7],\n",
    "        'mlp_ratio': 4.0,\n",
    "        'drop_rate': 0.0,\n",
    "        'drop_path_rate': 0.1,\n",
    "        \n",
    "        # æå¤±é–¢æ•°è¨­å®š\n",
    "        'dice_weight': 0.5,\n",
    "        'ce_weight': 0.5,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æœ€é©åŒ–è¨­å®šå®Œäº†:\")\n",
    "    print(f\"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {batch_size}\")\n",
    "    print(f\"   Embedæ¬¡å…ƒ: {embed_dim}\")\n",
    "    print(f\"   Transformeræ·±åº¦: {depths}\")\n",
    "    print(f\"   Mixed Precision: {use_amp}\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "# è¨­å®šå®Ÿè¡Œ\n",
    "CONFIG = setup_runpods_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ï¸ Step 4: SwinUNETR ãƒ¢ãƒ‡ãƒ«å®Ÿè£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D SwinUNETRå®Ÿè£…ï¼ˆå®Œå…¨ç‰ˆï¼‰\n",
    "class WindowAttention3D(nn.Module):\n",
    "    \"\"\"3D Window based multi-head self attention (W-MSA)\"\"\"\n",
    "    \n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = head_dim ** -0.5\n",
    "        \n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv.unbind(0)\n",
    "        \n",
    "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "        \n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class SwinTransformerBlock3D(nn.Module):\n",
    "    \"\"\"Swin Transformer Block for 3D\"\"\"\n",
    "    \n",
    "    def __init__(self, dim, num_heads, window_size=(7,7,7), shift_size=(0,0,0), \n",
    "                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0., drop_path=0.):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "        self.mlp_ratio = mlp_ratio\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = WindowAttention3D(\n",
    "            dim, window_size=window_size, num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, attn_drop=attn_drop, proj_drop=drop\n",
    "        )\n",
    "        \n",
    "        self.drop_path = nn.Dropout(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        \n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, mlp_hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(drop),\n",
    "            nn.Linear(mlp_hidden_dim, dim),\n",
    "            nn.Dropout(drop)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.attn(x)\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        \n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.mlp(x)\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class BasicLayer3D(nn.Module):\n",
    "    \"\"\"A basic Swin Transformer layer for 3D\"\"\"\n",
    "    \n",
    "    def __init__(self, dim, depth, num_heads, window_size,\n",
    "                 mlp_ratio=4., qkv_bias=True, drop=0., attn_drop=0., drop_path=0., downsample=None):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.depth = depth\n",
    "        \n",
    "        # build blocks\n",
    "        self.blocks = nn.ModuleList([\n",
    "            SwinTransformerBlock3D(\n",
    "                dim=dim,\n",
    "                num_heads=num_heads,\n",
    "                window_size=window_size,\n",
    "                shift_size=(0,0,0) if (i % 2 == 0) else tuple(ws//2 for ws in window_size),\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop=drop,\n",
    "                attn_drop=attn_drop,\n",
    "                drop_path=drop_path[i] if isinstance(drop_path, list) else drop_path\n",
    "            )\n",
    "            for i in range(depth)\n",
    "        ])\n",
    "        \n",
    "        # patch merging layer\n",
    "        if downsample is not None:\n",
    "            self.downsample = downsample(dim=dim)\n",
    "        else:\n",
    "            self.downsample = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        for blk in self.blocks:\n",
    "            x = blk(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class PatchEmbed3D(nn.Module):\n",
    "    \"\"\"3D Patch Embedding\"\"\"\n",
    "    \n",
    "    def __init__(self, patch_size=(2,2,2), in_chans=1, embed_dim=96):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.in_chans = in_chans\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        self.proj = nn.Conv3d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # (B, embed_dim, H', W', D')\n",
    "        x = rearrange(x, 'b c h w d -> b (h w d) c')  # (B, N, embed_dim)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "class SwinUNETR3D(nn.Module):\n",
    "    \"\"\"3D Swin-UNET for Vesuvius Challenge\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=(96,96,96), patch_size=(2,2,2), in_chans=1, out_chans=2,\n",
    "                 embed_dim=96, depths=[2,2,6,2], num_heads=[3,6,12,24],\n",
    "                 window_size=[7,7,7], mlp_ratio=4., qkv_bias=True,\n",
    "                 drop_rate=0., attn_drop_rate=0., drop_path_rate=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_layers = len(depths)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.patch_size = patch_size\n",
    "        \n",
    "        # patch embedding\n",
    "        self.patch_embed = PatchEmbed3D(\n",
    "            patch_size=patch_size, in_chans=in_chans, embed_dim=embed_dim\n",
    "        )\n",
    "        \n",
    "        # stochastic depth\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "        \n",
    "        # encoder layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i_layer in range(self.num_layers):\n",
    "            layer = BasicLayer3D(\n",
    "                dim=int(embed_dim * 2 ** i_layer),\n",
    "                depth=depths[i_layer],\n",
    "                num_heads=num_heads[i_layer],\n",
    "                window_size=window_size,\n",
    "                mlp_ratio=mlp_ratio,\n",
    "                qkv_bias=qkv_bias,\n",
    "                drop=drop_rate,\n",
    "                attn_drop=attn_drop_rate,\n",
    "                drop_path=dpr[sum(depths[:i_layer]):sum(depths[:i_layer + 1])],\n",
    "                downsample=nn.Linear(int(embed_dim * 2 ** i_layer), int(embed_dim * 2 ** (i_layer + 1))) \n",
    "                          if i_layer < self.num_layers - 1 else None\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "        # decoder (simplified U-Net style)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose3d(int(embed_dim * 2 ** (self.num_layers-1)), 256, 4, 2, 1),\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose3d(256, 128, 4, 2, 1),\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose3d(128, 64, 4, 2, 1),\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv3d(64, out_chans, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        B, C, H, W, D = x.shape\n",
    "        \n",
    "        # patch embedding\n",
    "        x = self.patch_embed(x)\n",
    "        \n",
    "        # encoder\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # reshape for decoder\n",
    "        H_p, W_p, D_p = H//self.patch_size[0]//8, W//self.patch_size[1]//8, D//self.patch_size[2]//8\n",
    "        x = rearrange(x, 'b (h w d) c -> b c h w d', h=H_p, w=W_p, d=D_p)\n",
    "        \n",
    "        # decoder\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "print(\"âœ… SwinUNETR3Då®Ÿè£…å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 5: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®Ÿè£…ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿+ãƒ‡ãƒ¢å¯¾å¿œï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# å®Ÿãƒ‡ãƒ¼ã‚¿å¯¾å¿œVesuviusãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\nclass VesuviusDataset3D(Dataset):\n    \"\"\"Vesuviuså®Ÿãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿å„ªå…ˆã€ãƒ‡ãƒ¢ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\"\"\"\n    \n    def __init__(self, split='train', volume_size=(96, 96, 96), num_samples=20):\n        self.split = split\n        self.volume_size = volume_size\n        self.num_samples = num_samples\n        \n        # ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹æ¤œå‡º\n        self.data_path = self._find_real_data()\n        \n        # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰\n        if self.data_path:\n            print(f\"ğŸ¯ å®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨: {self.data_path}\")\n            self.volumes, self.labels = self._load_real_data()\n        else:\n            print(f\"ğŸ­ ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ\")\n            self.volumes, self.labels = self._generate_demo_data()\n        \n        print(f\"ğŸ“Š {split}ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(self.volumes)}ã‚µãƒ³ãƒ—ãƒ«\")\n    \n    def _find_real_data(self):\n        \"\"\"å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹è‡ªå‹•æ¤œå‡º\"\"\"\n        candidates = [\n            \"/workspace/data/vesuvius-challenge-surface-detection\",\n            \"./data/vesuvius-challenge-surface-detection\",\n            \"/content/vesuvius-challenge-surface-detection\",\n            \"../input/vesuvius-challenge-surface-detection\",\n            \"./vesuvius-challenge-surface-detection\"\n        ]\n        \n        for candidate in candidates:\n            path = Path(candidate)\n            if path.exists():\n                train_images = path / \"train_images\"\n                if train_images.exists():\n                    tiff_files = list(train_images.glob(\"*.tif\"))\n                    if len(tiff_files) > 0:\n                        return str(path)\n        \n        return None\n    \n    def _load_real_data(self):\n        \"\"\"å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒœãƒªãƒ¥ãƒ¼ãƒ ä½œæˆï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\"\"\"\n        data_path = Path(self.data_path)\n        train_images_dir = data_path / \"train_images\"\n        train_labels_dir = data_path / \"train_labels\"\n        \n        tiff_files = sorted(list(train_images_dir.glob(\"*.tif\")))\n        \n        if len(tiff_files) == 0:\n            return self._generate_demo_data()\n        \n        print(f\"ğŸ“‚ {len(tiff_files)}å€‹ã®TIFFãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹\")\n        \n        volumes = []\n        labels = []\n        \n        H, W, D = self.volume_size\n        \n        # ãƒœãƒªãƒ¥ãƒ¼ãƒ ä½œæˆï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\n        num_volumes = min(self.num_samples, max(1, len(tiff_files) // D))\n        \n        with tqdm(total=num_volumes, desc=\"ğŸ“Š å®Ÿãƒ‡ãƒ¼ã‚¿å‡¦ç†\", unit=\"volume\") as volume_pbar:\n            for vol_idx in range(num_volumes):\n                start_idx = (vol_idx * D) % max(1, len(tiff_files) - D)\n                selected_files = tiff_files[start_idx:start_idx + D]\n                \n                if len(selected_files) < D:\n                    # å¾ªç’°ä½¿ç”¨ã§ãƒœãƒªãƒ¥ãƒ¼ãƒ è£œå®Œ\n                    selected_files = (selected_files * ((D // len(selected_files)) + 1))[:D]\n                \n                volume_slices = []\n                label_slices = []\n                \n                # ã‚¹ãƒ©ã‚¤ã‚¹å‡¦ç†ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼\n                with tqdm(total=len(selected_files), desc=f\"Vol{vol_idx:02d} ã‚¹ãƒ©ã‚¤ã‚¹\", \n                         unit=\"slice\", leave=False) as slice_pbar:\n                    \n                    for tiff_file in selected_files:\n                        try:\n                            # ç”»åƒèª­ã¿è¾¼ã¿\n                            img = Image.open(tiff_file)\n                            img_array = np.array(img, dtype=np.float32)\n                            \n                            # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›\n                            if len(img_array.shape) == 3:\n                                img_array = img_array.mean(axis=2)\n                            \n                            # ãƒªã‚µã‚¤ã‚º\n                            img_resized = cv2.resize(img_array, (W, H))\n                            \n                            # æ­£è¦åŒ–\n                            img_normalized = (img_resized - img_resized.mean()) / (img_resized.std() + 1e-8)\n                            \n                            volume_slices.append(img_normalized)\n                            \n                            # ãƒ©ãƒ™ãƒ«å‡¦ç†ï¼ˆç°¡æ˜“ç‰ˆï¼‰\n                            if train_labels_dir.exists():\n                                label_file = train_labels_dir / tiff_file.name\n                                if label_file.exists():\n                                    label_img = Image.open(label_file)\n                                    label_array = np.array(label_img, dtype=np.uint8)\n                                    if len(label_array.shape) == 3:\n                                        label_array = label_array[:, :, 0]\n                                    label_resized = cv2.resize(label_array, (W, H), interpolation=cv2.INTER_NEAREST)\n                                    label_binary = (label_resized > 127).astype(np.int64)\n                                else:\n                                    # ç°¡æ˜“ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³\n                                    label_binary = (img_normalized > np.percentile(img_normalized, 80)).astype(np.int64)\n                            else:\n                                # ãƒ©ãƒ™ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã„å ´åˆ\n                                label_binary = (img_normalized > np.percentile(img_normalized, 80)).astype(np.int64)\n                            \n                            label_slices.append(label_binary)\n                            \n                        except Exception as e:\n                            if vol_idx == 0:  # æœ€åˆã®ãƒœãƒªãƒ¥ãƒ¼ãƒ ã§ã®ã¿ã‚¨ãƒ©ãƒ¼è¡¨ç¤º\n                                tqdm.write(f\"âš ï¸ {tiff_file.name}ã‚¨ãƒ©ãƒ¼: {e}\")\n                            # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ€ãƒŸãƒ¼ã‚¹ãƒ©ã‚¤ã‚¹\n                            volume_slices.append(np.random.randn(H, W).astype(np.float32))\n                            label_slices.append(np.zeros((H, W), dtype=np.int64))\n                        \n                        slice_pbar.update(1)\n                        slice_pbar.set_postfix({\n                            'ãƒ•ã‚¡ã‚¤ãƒ«': tiff_file.name[:15] + '...'\n                        })\n                \n                # 3Dãƒœãƒªãƒ¥ãƒ¼ãƒ æ§‹ç¯‰\n                if len(volume_slices) == D:\n                    volume = np.stack(volume_slices, axis=2)  # (H, W, D)\n                    label = np.stack(label_slices, axis=2)    # (H, W, D)\n                    \n                    volumes.append(volume)\n                    labels.append(label)\n                    \n                    if vol_idx == 0:\n                        fg_ratio = (label == 1).mean()\n                        tqdm.write(f\"  ã‚µãƒ³ãƒ—ãƒ«: {volume.shape}, å‰æ™¯ç‡: {fg_ratio:.2%}\")\n                \n                volume_pbar.update(1)\n                volume_pbar.set_postfix({\n                    'ãƒœãƒªãƒ¥ãƒ¼ãƒ ': f'{len(volumes)}/{num_volumes}',\n                    'å‰æ™¯ç‡': f'{(labels[-1] == 1).mean():.1%}' if volumes else '0%'\n                })\n        \n        print(f\"âœ… {len(volumes)}å€‹ã®å®Ÿãƒ‡ãƒ¼ã‚¿ãƒœãƒªãƒ¥ãƒ¼ãƒ ä½œæˆå®Œäº†\")\n        return volumes, labels\n    \n    def _generate_demo_data(self):\n        \"\"\"é«˜å“è³ªãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\"\"\"\n        volumes = []\n        labels = []\n        \n        H, W, D = self.volume_size\n        \n        with tqdm(total=self.num_samples, desc=\"ğŸ­ ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ\", unit=\"sample\") as pbar:\n            for i in range(self.num_samples):\n                # ãƒªã‚¢ãƒ«ãª3Dãƒœãƒªãƒ¥ãƒ¼ãƒ ç”Ÿæˆ\n                volume = np.random.randn(H, W, D).astype(np.float32)\n                \n                # è¤‡é›‘ãª3Dãƒ†ã‚¯ã‚¹ãƒãƒ£\n                for z in range(D):\n                    x, y = np.meshgrid(np.linspace(0, 3*np.pi, H), np.linspace(0, 3*np.pi, W))\n                    pattern = np.sin(x + i + z/10) * np.cos(y + z/10) * np.sin(z/5)\n                    volume[:, :, z] += pattern * 0.5\n                    volume[:, :, z] += np.random.randn(H, W) * 0.3\n                \n                # æ­£è¦åŒ–\n                volume = (volume - volume.mean()) / (volume.std() + 1e-8)\n                \n                # 3Dã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ©ãƒ™ãƒ«\n                label = np.zeros((H, W, D), dtype=np.int64)\n                \n                # è¤‡æ•°ã®3Dæ¥•å††ä½“\n                num_regions = np.random.randint(3, 7)\n                for _ in range(num_regions):\n                    cx = np.random.randint(H//4, 3*H//4)\n                    cy = np.random.randint(W//4, 3*W//4)\n                    cz = np.random.randint(D//4, 3*D//4)\n                    \n                    rx = np.random.randint(8, 20)\n                    ry = np.random.randint(8, 20)\n                    rz = np.random.randint(5, 15)\n                    \n                    # 3Dæ¥•å††ä½“ç”Ÿæˆ\n                    x, y, z = np.ogrid[:H, :W, :D]\n                    ellipsoid = ((x-cx)**2/rx**2 + (y-cy)**2/ry**2 + (z-cz)**2/rz**2) <= 1\n                    label[ellipsoid] = 1\n                \n                volumes.append(volume)\n                labels.append(label)\n                \n                pbar.update(1)\n                pbar.set_postfix({\n                    'ãƒœãƒªãƒ¥ãƒ¼ãƒ ': f'{len(volumes)}/{self.num_samples}',\n                    'å‰æ™¯ç‡': f'{(label == 1).mean():.1%}'\n                })\n        \n        print(f\"âœ… {len(volumes)}å€‹ã®ãƒ‡ãƒ¢ãƒœãƒªãƒ¥ãƒ¼ãƒ ç”Ÿæˆå®Œäº†\")\n        return volumes, labels\n    \n    def __len__(self):\n        return len(self.volumes)\n    \n    def __getitem__(self, idx):\n        volume = torch.FloatTensor(self.volumes[idx]).unsqueeze(0)  # (1, H, W, D)\n        label = torch.LongTensor(self.labels[idx])  # (H, W, D)\n        \n        return volume, label\n\nprint(\"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå®Ÿè£…å®Œäº†\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Step 6: ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ\nprint(\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆä¸­...\\n\")\n\n# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\nwith tqdm(total=3, desc=\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼æº–å‚™\", unit=\"step\") as prep_pbar:\n    \n    # Step 1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\n    prep_pbar.set_description(\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ\")\n    full_dataset = VesuviusDataset3D(\n        split='full',\n        volume_size=CONFIG['input_shape'],\n        num_samples=30  # è¨“ç·´ç”¨ã«ååˆ†ãªæ•°\n    )\n    prep_pbar.update(1)\n    \n    # Step 2: Train/Validationåˆ†å‰²\n    prep_pbar.set_description(\"ğŸ”€ Train/Valåˆ†å‰²\")\n    dataset_size = len(full_dataset)\n    val_size = max(1, int(dataset_size * CONFIG['validation_split']))\n    train_size = dataset_size - val_size\n\n    train_dataset, val_dataset = torch.utils.data.random_split(\n        full_dataset, [train_size, val_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n    prep_pbar.update(1)\n    \n    # Step 3: DataLoaderä½œæˆ\n    prep_pbar.set_description(\"âš™ï¸ DataLoaderä½œæˆ\")\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=CONFIG['batch_size'],\n        shuffle=True,\n        num_workers=CONFIG['num_workers'],\n        pin_memory=CONFIG['device'].type == 'cuda',\n        drop_last=True\n    )\n\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=CONFIG['batch_size'],\n        shuffle=False,\n        num_workers=CONFIG['num_workers'],\n        pin_memory=CONFIG['device'].type == 'cuda',\n        drop_last=False\n    )\n    prep_pbar.update(1)\n\nprint(f\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:\")\nprint(f\"   ç·ãƒ‡ãƒ¼ã‚¿: {dataset_size}\")\nprint(f\"   è¨“ç·´: {train_size}ã‚µãƒ³ãƒ—ãƒ«\")\nprint(f\"   æ¤œè¨¼: {val_size}ã‚µãƒ³ãƒ—ãƒ«\")\n\nprint(f\"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆå®Œäº†\")\nprint(f\"   è¨“ç·´ãƒãƒƒãƒæ•°: {len(train_loader)}\")\nprint(f\"   æ¤œè¨¼ãƒãƒƒãƒæ•°: {len(val_loader)}\")\n\n# ãƒ‡ãƒ¼ã‚¿ç¢ºèª\nprint(f\"\\nğŸ” ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ç¢ºèªä¸­...\")\nwith tqdm(total=1, desc=\"ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª\", unit=\"batch\") as check_pbar:\n    sample_batch = next(iter(train_loader))\n    check_pbar.update(1)\n\nprint(f\"ğŸ“ ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ç¢ºèª:\")\nprint(f\"   å…¥åŠ›: {sample_batch[0].shape}\")\nprint(f\"   ãƒ©ãƒ™ãƒ«: {sample_batch[1].shape}\")\nprint(f\"   å‰æ™¯æ¯”ç‡: {(sample_batch[1] == 1).float().mean():.3f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Step 7: å­¦ç¿’è¨­å®š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ãƒ¢ãƒ‡ãƒ«ä½œæˆ\nprint(\"ğŸ—ï¸ SwinUNETR3Dãƒ¢ãƒ‡ãƒ«ä½œæˆä¸­...\")\n\n# ãƒ¢ãƒ‡ãƒ«ä½œæˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹\nwith tqdm(total=4, desc=\"ğŸ—ï¸ ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰\", unit=\"step\") as model_pbar:\n    \n    # Step 1: ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ\n    model_pbar.set_description(\"ğŸ§  ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–\")\n    model = SwinUNETR3D(\n        img_size=CONFIG['img_size'],\n        patch_size=CONFIG['patch_size'],\n        in_chans=CONFIG['in_channels'],\n        out_chans=CONFIG['out_channels'],\n        embed_dim=CONFIG['embed_dim'],\n        depths=CONFIG['depths'],\n        num_heads=CONFIG['num_heads'],\n        window_size=CONFIG['window_size'],\n        mlp_ratio=CONFIG['mlp_ratio'],\n        drop_rate=CONFIG['drop_rate'],\n        drop_path_rate=CONFIG['drop_path_rate']\n    ).to(CONFIG['device'])\n    model_pbar.update(1)\n    \n    # Step 2: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°è¨ˆç®—\n    model_pbar.set_description(\"ğŸ“Š ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨ˆç®—\")\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    model_pbar.update(1)\n    \n    # Step 3: æå¤±é–¢æ•°å®šç¾©\n    model_pbar.set_description(\"âš–ï¸ æå¤±é–¢æ•°ä½œæˆ\")\n    # æå¤±é–¢æ•°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹\n    class CombinedLoss(nn.Module):\n        \"\"\"Dice + CrossEntropy Loss\"\"\"\n        \n        def __init__(self, dice_weight=0.5, ce_weight=0.5):\n            super().__init__()\n            self.dice_weight = dice_weight\n            self.ce_weight = ce_weight\n            self.ce_loss = nn.CrossEntropyLoss()\n        \n        def dice_loss(self, pred, target, smooth=1e-5):\n            pred_soft = torch.softmax(pred, dim=1)[:, 1]\n            target_flat = target.float()\n            \n            pred_flat = pred_soft.view(-1)\n            target_flat = target_flat.view(-1)\n            \n            intersection = (pred_flat * target_flat).sum()\n            dice = (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n            \n            return 1 - dice\n        \n        def forward(self, pred, target):\n            ce = self.ce_loss(pred, target)\n            dice = self.dice_loss(pred, target)\n            return self.ce_weight * ce + self.dice_weight * dice\n\n    def calculate_dice_score(pred, target, smooth=1e-5):\n        \"\"\"Dice Scoreè¨ˆç®—\"\"\"\n        pred_class = torch.argmax(pred, dim=1).float()\n        target_flat = target.float()\n        \n        pred_flat = pred_class.view(-1)\n        target_flat = target_flat.view(-1)\n        \n        intersection = (pred_flat * target_flat).sum()\n        dice = (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n        \n        return dice.item()\n    model_pbar.update(1)\n    \n    # Step 4: æœ€é©åŒ–å™¨è¨­å®š\n    model_pbar.set_description(\"âš™ï¸ æœ€é©åŒ–å™¨è¨­å®š\")\n    # æœ€é©åŒ–å™¨è¨­å®š\n    criterion = CombinedLoss(\n        dice_weight=CONFIG['dice_weight'],\n        ce_weight=CONFIG['ce_weight']\n    )\n\n    optimizer = optim.AdamW(\n        model.parameters(),\n        lr=CONFIG['learning_rate'],\n        weight_decay=CONFIG['weight_decay']\n    )\n\n    scheduler = optim.lr_scheduler.CosineAnnealingLR(\n        optimizer,\n        T_max=CONFIG['epochs'],\n        eta_min=1e-6\n    )\n\n    # Mixed Precision\n    scaler = GradScaler() if CONFIG['use_amp'] else None\n    model_pbar.update(1)\n\nprint(f\"ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©³ç´°:\")\nprint(f\"   ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}\")\nprint(f\"   å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}\")\nprint(f\"   ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: {total_params*4/1024/1024:.1f}MB\")\nprint(f\"   æ··åˆç²¾åº¦: {'âœ… æœ‰åŠ¹' if CONFIG['use_amp'] else 'âŒ ç„¡åŠ¹'}\")\nprint(f\"   ãƒ‡ãƒã‚¤ã‚¹: {CONFIG['device']}\")\n\nprint(\"âœ… å­¦ç¿’è¨­å®šå®Œäº†\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Step 8: å­¦ç¿’å®Ÿè¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# å­¦ç¿’é–¢æ•°ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\ndef train_epoch(model, dataloader, optimizer, criterion, scaler, device, epoch):\n    \"\"\"1ã‚¨ãƒãƒƒã‚¯å­¦ç¿’ï¼ˆè©³ç´°ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\"\"\"\n    model.train()\n    total_loss = 0.0\n    batch_count = 0\n    \n    # ã‚¨ãƒãƒƒã‚¯å†…ã®è©³ç´°ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼\n    epoch_pbar = tqdm(\n        dataloader, \n        desc=f\"ğŸš€ Epoch {epoch+1:2d}/{CONFIG['epochs']} Train\",\n        unit=\"batch\",\n        leave=False,\n        colour='green'\n    )\n    \n    for batch_idx, (data, target) in enumerate(epoch_pbar):\n        data, target = data.to(device), target.to(device)\n        \n        optimizer.zero_grad()\n        \n        if scaler is not None:\n            with autocast():\n                output = model(data)\n                loss = criterion(output, target)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n        \n        batch_loss = loss.item()\n        total_loss += batch_loss\n        batch_count += 1\n        \n        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°\n        avg_loss = total_loss / batch_count\n        epoch_pbar.set_postfix({\n            'Loss': f'{batch_loss:.4f}',\n            'Avg': f'{avg_loss:.4f}',\n            'GPU': f'{torch.cuda.memory_reserved(0)//1024//1024}MB' if torch.cuda.is_available() else 'CPU'\n        })\n    \n    return total_loss / len(dataloader)\n\ndef validate_epoch(model, dataloader, criterion, device, epoch):\n    \"\"\"1ã‚¨ãƒãƒƒã‚¯æ¤œè¨¼ï¼ˆè©³ç´°ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\"\"\"\n    model.eval()\n    total_loss = 0.0\n    total_dice = 0.0\n    batch_count = 0\n    \n    with torch.no_grad():\n        # æ¤œè¨¼ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼\n        val_pbar = tqdm(\n            dataloader, \n            desc=f\"ğŸ” Epoch {epoch+1:2d}/{CONFIG['epochs']} Valid\",\n            unit=\"batch\",\n            leave=False,\n            colour='blue'\n        )\n        \n        for batch_idx, (data, target) in enumerate(val_pbar):\n            data, target = data.to(device), target.to(device)\n            \n            output = model(data)\n            loss = criterion(output, target)\n            dice = calculate_dice_score(output, target)\n            \n            batch_loss = loss.item()\n            total_loss += batch_loss\n            total_dice += dice\n            batch_count += 1\n            \n            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°\n            avg_loss = total_loss / batch_count\n            avg_dice = total_dice / batch_count\n            val_pbar.set_postfix({\n                'Loss': f'{batch_loss:.4f}',\n                'Dice': f'{dice:.4f}',\n                'AvgDice': f'{avg_dice:.4f}'\n            })\n    \n    return total_loss / len(dataloader), total_dice / len(dataloader)\n\nprint(\"âœ… å­¦ç¿’é–¢æ•°ï¼ˆãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰æº–å‚™å®Œäº†\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ãƒ¡ã‚¤ãƒ³å­¦ç¿’ãƒ«ãƒ¼ãƒ—ï¼ˆè©³ç´°ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ä»˜ãï¼‰\nprint(\"=\"*70)\nprint(\"ğŸš€ SwinUNETR3D Vesuvius Challenge å­¦ç¿’é–‹å§‹!\")\nprint(\"=\"*70)\nprint(f\"   ã‚¨ãƒãƒƒã‚¯æ•°: {CONFIG['epochs']}\")\nprint(f\"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {CONFIG['batch_size']}\")\nprint(f\"   ãƒ‡ãƒã‚¤ã‚¹: {CONFIG['device']}\")\nprint(f\"   Mixed Precision: {CONFIG['use_amp']}\")\nprint(\"=\"*70)\n\n# TensorBoardè¨­å®š\nlog_dir = Path('./swinunetr_logs')\nlog_dir.mkdir(exist_ok=True)\nwriter = SummaryWriter(log_dir=str(log_dir))\n\n# å­¦ç¿’å±¥æ­´\nhistory = {\n    'train_loss': [],\n    'val_loss': [],\n    'val_dice': [],\n    'lr': []\n}\n\nbest_dice = 0.0\nstart_time = datetime.now()\n\n# ãƒ¡ã‚¤ãƒ³å­¦ç¿’ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼\nmain_pbar = tqdm(\n    total=CONFIG['epochs'],\n    desc=\"ğŸ¯ ç·åˆé€²æ—\",\n    unit=\"epoch\",\n    position=0,\n    colour='red'\n)\n\ntry:\n    for epoch in range(CONFIG['epochs']):\n        epoch_start = datetime.now()\n        \n        # ã‚¨ãƒãƒƒã‚¯é€²æ—æ›´æ–°\n        main_pbar.set_description(f\"ğŸ¯ ã‚¨ãƒãƒƒã‚¯ {epoch+1}/{CONFIG['epochs']}\")\n        \n        # å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º\n        train_loss = train_epoch(\n            model, train_loader, optimizer, criterion, scaler, CONFIG['device'], epoch\n        )\n        \n        # æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º\n        val_loss, val_dice = validate_epoch(\n            model, val_loader, criterion, CONFIG['device'], epoch\n        )\n        \n        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼æ›´æ–°\n        scheduler.step()\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        # å±¥æ­´è¨˜éŒ²\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['val_dice'].append(val_dice)\n        history['lr'].append(current_lr)\n        \n        # TensorBoardè¨˜éŒ²\n        writer.add_scalar('Loss/Train', train_loss, epoch)\n        writer.add_scalar('Loss/Validation', val_loss, epoch)\n        writer.add_scalar('Dice/Validation', val_dice, epoch)\n        writer.add_scalar('Learning_Rate', current_lr, epoch)\n        \n        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜\n        is_best = val_dice > best_dice\n        if is_best:\n            best_dice = val_dice\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'best_dice': best_dice,\n                'config': CONFIG\n            }, 'best_swinunetr_vesuvius.pth')\n        \n        epoch_time = datetime.now() - epoch_start\n        elapsed_total = datetime.now() - start_time\n        \n        # ãƒ¡ã‚¤ãƒ³ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°\n        main_pbar.update(1)\n        main_pbar.set_postfix({\n            'Dice': f'{val_dice:.4f}',\n            'Best': f'{best_dice:.4f}',\n            'Loss': f'{val_loss:.4f}',\n            'Time': f'{epoch_time.total_seconds():.0f}s'\n        })\n        \n        # è©³ç´°çµæœè¡¨ç¤ºï¼ˆtqdm.writeä½¿ç”¨ï¼‰\n        status_icon = \"ğŸ†\" if is_best else \"ğŸ“Š\"\n        tqdm.write(f\"\\n{status_icon} Epoch {epoch+1:2d}/{CONFIG['epochs']} å®Œäº†:\")\n        tqdm.write(f\"  â”œâ”€ Train Loss: {train_loss:.4f}\")\n        tqdm.write(f\"  â”œâ”€ Val Loss:   {val_loss:.4f}\")\n        tqdm.write(f\"  â”œâ”€ Val Dice:   {val_dice:.4f} {'ğŸ†• NEW BEST!' if is_best else ''}\")\n        tqdm.write(f\"  â”œâ”€ Best Dice:  {best_dice:.4f}\")\n        tqdm.write(f\"  â”œâ”€ LR:         {current_lr:.2e}\")\n        tqdm.write(f\"  â”œâ”€ Epochæ™‚é–“:  {epoch_time}\")\n        tqdm.write(f\"  â””â”€ ç·çµŒéæ™‚é–“: {elapsed_total}\")\n        \n        # æ—©æœŸçµ‚äº†åˆ¤å®š\n        if val_dice > 0.85:\n            tqdm.write(f\"\\nğŸ‰ ç›®æ¨™é”æˆ! Dice={val_dice:.4f} > 0.85\")\n            main_pbar.close()\n            break\n    \n    main_pbar.close()\n    total_time = datetime.now() - start_time\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"ğŸ‰ SwinUNETRå­¦ç¿’å®Œäº†!\")\n    print(\"=\"*70)\n    print(f\"   å­¦ç¿’æ™‚é–“: {total_time}\")\n    print(f\"   ãƒ™ã‚¹ãƒˆDice: {best_dice:.4f}\")\n    print(f\"   æœ€çµ‚ã‚¨ãƒãƒƒã‚¯: {len(history['train_loss'])}\")\n    \n    TRAINING_SUCCESS = True\n    \nexcept KeyboardInterrupt:\n    main_pbar.close()\n    tqdm.write(\"\\nâ¹ï¸ å­¦ç¿’ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ\")\n    TRAINING_SUCCESS = False\n    \nexcept Exception as e:\n    main_pbar.close()\n    tqdm.write(f\"\\nâŒ å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}\")\n    import traceback\n    traceback.print_exc()\n    TRAINING_SUCCESS = False\n\nfinally:\n    writer.close()\n    if 'main_pbar' in locals():\n        main_pbar.close()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Step 9: çµæœå¯è¦–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’çµæœå¯è¦–åŒ–\n",
    "if TRAINING_SUCCESS and len(history['train_loss']) > 0:\n",
    "    print(\"ğŸ“Š å­¦ç¿’çµæœå¯è¦–åŒ–ä¸­...\")\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('SwinUNETR Vesuvius Challenge - Training Results', fontsize=16, weight='bold')\n",
    "    \n",
    "    epochs_range = range(len(history['train_loss']))\n",
    "    \n",
    "    # Lossæ›²ç·š\n",
    "    axes[0, 0].plot(epochs_range, history['train_loss'], 'b-', label='Train Loss', linewidth=2.5)\n",
    "    axes[0, 0].plot(epochs_range, history['val_loss'], 'r-', label='Val Loss', linewidth=2.5)\n",
    "    axes[0, 0].set_title('Training & Validation Loss', fontsize=14, weight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend(fontsize=12)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Dice Score\n",
    "    axes[0, 1].plot(epochs_range, history['val_dice'], 'g-', label='Val Dice', linewidth=2.5)\n",
    "    axes[0, 1].axhline(y=best_dice, color='orange', linestyle='--', label=f'Best: {best_dice:.4f}')\n",
    "    axes[0, 1].set_title('Validation Dice Score', fontsize=14, weight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Dice Score')\n",
    "    axes[0, 1].legend(fontsize=12)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[1, 0].plot(epochs_range, history['lr'], 'purple', linewidth=2.5)\n",
    "    axes[1, 0].set_title('Learning Rate Schedule', fontsize=14, weight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].set_yscale('log')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training Summary\n",
    "    best_epoch = history['val_dice'].index(best_dice)\n",
    "    final_dice = history['val_dice'][-1]\n",
    "    data_type = 'Real Data' if full_dataset.data_path else 'Demo Data'\n",
    "    \n",
    "    summary_text = f\"\"\"SwinUNETR Vesuvius Results Summary:\n",
    "\n",
    "ğŸ† Performance Metrics:\n",
    "â€¢ Best Dice Score: {best_dice:.4f} (Epoch {best_epoch+1})\n",
    "â€¢ Final Dice Score: {final_dice:.4f}\n",
    "â€¢ Final Train Loss: {history['train_loss'][-1]:.4f}\n",
    "â€¢ Final Val Loss: {history['val_loss'][-1]:.4f}\n",
    "\n",
    "âš™ï¸ Model Configuration:\n",
    "â€¢ Architecture: 3D SwinUNETR\n",
    "â€¢ Parameters: {total_params:,}\n",
    "â€¢ Embed Dim: {CONFIG['embed_dim']}\n",
    "â€¢ Batch Size: {CONFIG['batch_size']}\n",
    "â€¢ Device: {CONFIG['device']}\n",
    "\n",
    "ğŸ“Š Training Details:\n",
    "â€¢ Data Type: {data_type}\n",
    "â€¢ Total Epochs: {len(history['train_loss'])}\n",
    "â€¢ Mixed Precision: {CONFIG['use_amp']}\n",
    "â€¢ Input Size: {CONFIG['input_shape']}\n",
    "\n",
    "ğŸ¯ Status: {'SUCCESS âœ…' if best_dice > 0.5 else 'NEEDS IMPROVEMENT âš ï¸'}\"\"\"\n",
    "    \n",
    "    axes[1, 1].text(0.05, 0.95, summary_text, transform=axes[1, 1].transAxes,\n",
    "                    fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                    bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))\n",
    "    axes[1, 1].set_xlim(0, 1)\n",
    "    axes[1, 1].set_ylim(0, 1)\n",
    "    axes[1, 1].axis('off')\n",
    "    axes[1, 1].set_title('Training Summary', fontsize=14, weight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('swinunetr_vesuvius_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… çµæœå¯è¦–åŒ–å®Œäº†: swinunetr_vesuvius_results.png\")\n",
    "    \n",
    "    # å±¥æ­´ã‚’JSONã§ä¿å­˜\n",
    "    import json\n",
    "    with open('swinunetr_training_history.json', 'w') as f:\n",
    "        json.dump(history, f, indent=2, default=str)\n",
    "    print(\"âœ… å­¦ç¿’å±¥æ­´ä¿å­˜: swinunetr_training_history.json\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ å­¦ç¿’å±¥æ­´ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Step 10: äºˆæ¸¬ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# äºˆæ¸¬ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª\n",
    "if TRAINING_SUCCESS:\n",
    "    print(\"ğŸ” äºˆæ¸¬ã‚µãƒ³ãƒ—ãƒ«ç¢ºèªä¸­...\")\n",
    "    \n",
    "    model.eval()\n",
    "    sample_batch = next(iter(val_loader))\n",
    "    data, target = sample_batch[0].to(CONFIG['device']), sample_batch[1].to(CONFIG['device'])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1)\n",
    "    \n",
    "    # CPUç§»å‹•\n",
    "    data_cpu = data.cpu().numpy()\n",
    "    target_cpu = target.cpu().numpy()\n",
    "    pred_cpu = pred.cpu().numpy()\n",
    "    \n",
    "    # 3ã¤ã®ã‚¹ãƒ©ã‚¤ã‚¹ã§ç¢ºèª\n",
    "    sample_idx = 0\n",
    "    depth_slices = [data_cpu.shape[-1]//4, data_cpu.shape[-1]//2, 3*data_cpu.shape[-1]//4]\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    fig.suptitle('SwinUNETR Prediction Results - 3D Slices', fontsize=16, weight='bold')\n",
    "    \n",
    "    for i, slice_idx in enumerate(depth_slices):\n",
    "        # Input\n",
    "        axes[i, 0].imshow(data_cpu[sample_idx, 0, :, :, slice_idx], cmap='gray')\n",
    "        axes[i, 0].set_title(f'Input (Slice {slice_idx})', fontsize=12)\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # Ground Truth\n",
    "        axes[i, 1].imshow(target_cpu[sample_idx, :, :, slice_idx], cmap='coolwarm')\n",
    "        axes[i, 1].set_title(f'Ground Truth', fontsize=12)\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Prediction\n",
    "        axes[i, 2].imshow(pred_cpu[sample_idx, :, :, slice_idx], cmap='coolwarm')\n",
    "        axes[i, 2].set_title(f'SwinUNETR Prediction', fontsize=12)\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('swinunetr_predictions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Diceä¿‚æ•°è¨ˆç®—\n",
    "    dice_sample = calculate_dice_score(output, target)\n",
    "    print(f\"\\nğŸ“Š ã‚µãƒ³ãƒ—ãƒ«Diceä¿‚æ•°: {dice_sample:.4f}\")\n",
    "    print(f\"   å‰æ™¯ãƒ”ã‚¯ã‚»ãƒ«ç‡ (GT): {(target_cpu == 1).mean():.3f}\")\n",
    "    print(f\"   å‰æ™¯ãƒ”ã‚¯ã‚»ãƒ«ç‡ (Pred): {(pred_cpu == 1).mean():.3f}\")\n",
    "    \n",
    "    print(\"âœ… äºˆæ¸¬ç¢ºèªå®Œäº†: swinunetr_predictions.png\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ å­¦ç¿’ãŒå®Œäº†ã—ã¦ã„ãªã„ãŸã‚ã€äºˆæ¸¬ç¢ºèªã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ Step 11: ãƒ¢ãƒ‡ãƒ«ä¿å­˜ã¨å®Œäº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
    "if TRAINING_SUCCESS:\n",
    "    print(\"ğŸ’¾ æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ä¿å­˜ä¸­...\")\n",
    "    \n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'training_history': history,\n",
    "        'config': CONFIG,\n",
    "        'final_metrics': {\n",
    "            'best_dice': best_dice,\n",
    "            'final_dice': history['val_dice'][-1] if history['val_dice'] else 0.0,\n",
    "            'total_epochs': len(history['train_loss'])\n",
    "        }\n",
    "    }, 'final_swinunetr_vesuvius.pth')\n",
    "    \n",
    "    print(\"âœ… ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†\")\n",
    "    print(\"   - best_swinunetr_vesuvius.pth (ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«)\")\n",
    "    print(\"   - final_swinunetr_vesuvius.pth (æœ€çµ‚ãƒ¢ãƒ‡ãƒ«)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ‰ SwinUNETR Vesuvius Challenge å®Œäº†!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if TRAINING_SUCCESS:\n",
    "    data_type = 'å®Ÿãƒ‡ãƒ¼ã‚¿' if full_dataset.data_path else 'ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿'\n",
    "    performance = 'å„ªç§€' if best_dice > 0.7 else 'è‰¯å¥½' if best_dice > 0.5 else 'æ”¹å–„è¦'\n",
    "    \n",
    "    print(f\"ğŸ“Š æœ€çµ‚çµæœ:\")\n",
    "    print(f\"   ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—: {data_type}\")\n",
    "    print(f\"   ãƒ™ã‚¹ãƒˆDice: {best_dice:.4f} ({performance})\")\n",
    "    print(f\"   ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {total_params:,}\")\n",
    "    print(f\"   å­¦ç¿’æ™‚é–“: {datetime.now() - start_time}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:\")\n",
    "    print(f\"   - best_swinunetr_vesuvius.pth\")\n",
    "    print(f\"   - final_swinunetr_vesuvius.pth\")\n",
    "    print(f\"   - swinunetr_vesuvius_results.png\")\n",
    "    print(f\"   - swinunetr_predictions.png\")\n",
    "    print(f\"   - swinunetr_training_history.json\")\n",
    "    print(f\"   - swinunetr_logs/ (TensorBoard)\")\n",
    "    \n",
    "    if best_dice > 0.6:\n",
    "        print(f\"\\nğŸ† Kaggleæå‡ºå¯èƒ½ãƒ¬ãƒ™ãƒ«é”æˆ! (Dice > 0.6)\")\n",
    "    else:\n",
    "        print(f\"\\nğŸ’ª ã•ã‚‰ãªã‚‹æ”¹å–„ã§é«˜ã‚¹ã‚³ã‚¢ç‹™ã„å¯èƒ½!\")\n",
    "        print(f\"   - ã‚¨ãƒãƒƒã‚¯æ•°ã‚’å¢—åŠ  (50-100)\")\n",
    "        print(f\"   - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µè¿½åŠ \")\n",
    "        print(f\"   - ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ å­¦ç¿’ãŒå®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "    print(\"   è¨­å®šã‚’èª¿æ•´ã—ã¦å†å®Ÿè¡Œã—ã¦ãã ã•ã„\")\n",
    "\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ ä½¿ç”¨æ–¹æ³•ã¨å®Œäº†\n",
    "\n",
    "### âœ… **ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ç‰¹å¾´**:\n",
    "- **å®Œå…¨ç‹¬ç«‹** - å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ä¾å­˜ãªã—\n",
    "- **å®Ÿãƒ‡ãƒ¼ã‚¿å¯¾å¿œ** - Kaggleè‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ»å‡¦ç†\n",
    "- **SwinUNETR** - æœ€æ–°Transformer + U-Net\n",
    "- **Runpodsæœ€é©åŒ–** - GPUåˆ¥è‡ªå‹•è¨­å®š\n",
    "- **å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³** - ãƒ‡ãƒ¼ã‚¿â†’å­¦ç¿’â†’è©•ä¾¡â†’ä¿å­˜\n",
    "\n",
    "### ğŸš€ **Runpodså®Ÿè¡Œæ‰‹é †**:\n",
    "1. **JupyterLabã§ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’é–‹ã**\n",
    "2. **èªè¨¼è¨­å®š**: `setup_kaggle_auth_runpods(username=\"...\", key=\"...\")`\n",
    "3. **\"Run All\"å®Ÿè¡Œ** - å…¨è‡ªå‹•ã§å®Œäº†\n",
    "4. **çµæœç¢ºèª**: ã‚°ãƒ©ãƒ•ã¨ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª\n",
    "\n",
    "### ğŸ¯ **æœŸå¾…æ€§èƒ½**:\n",
    "- **å®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨**: Dice Score 0.6-0.8+\n",
    "- **Kaggleæå‡ºå¯èƒ½**: LB 0.552+é”æˆå¯èƒ½\n",
    "- **é«˜é€Ÿå­¦ç¿’**: A6000ã§ç´„30-60åˆ†\n",
    "\n",
    "### ğŸ“ **å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«**:\n",
    "- `best_swinunetr_vesuvius.pth` - ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«\n",
    "- `swinunetr_vesuvius_results.png` - å­¦ç¿’çµæœ\n",
    "- `swinunetr_predictions.png` - äºˆæ¸¬çµæœ\n",
    "- `swinunetr_logs/` - TensorBoardãƒ­ã‚°"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}