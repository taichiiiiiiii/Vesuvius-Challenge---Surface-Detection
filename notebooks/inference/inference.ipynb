{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":117682,"databundleVersionId":15062069,"sourceType":"competition"},{"sourceId":290917305,"sourceType":"kernelVersion"},{"sourceId":655294,"sourceType":"modelInstanceVersion","modelInstanceId":495238,"modelId":510647},{"sourceId":660383,"sourceType":"modelInstanceVersion","modelInstanceId":499479,"modelId":510647},{"sourceId":665924,"sourceType":"modelInstanceVersion","modelInstanceId":504051,"modelId":510647},{"sourceId":672178,"sourceType":"modelInstanceVersion","modelInstanceId":495238,"modelId":510647},{"sourceId":673516,"sourceType":"modelInstanceVersion","modelInstanceId":499479,"modelId":510647},{"sourceId":674747,"sourceType":"modelInstanceVersion","modelInstanceId":503784,"modelId":510647},{"sourceId":681152,"sourceType":"modelInstanceVersion","modelInstanceId":516822,"modelId":510647},{"sourceId":732880,"sourceType":"modelInstanceVersion","modelInstanceId":516822,"modelId":510647}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Training Notebooks\n\n- [Vesuvius Surface 3D Detection in Keras-JAX](https://www.kaggle.com/code/ipythonx/vesuvius-surface-3d-detection-in-jax)\n- [Vesuvius Surface 3D Detection in PyTorch](https://www.kaggle.com/code/ipythonx/vesuvius-surface-3d-detection-in-pytorch)\n- [Vesuvius Surface 3D Detection in PyTorch Lightning](https://www.kaggle.com/code/ipythonx/train-vesuvius-surface-3d-detection-in-lightning)\n- [[WIP] Vesuvius Surface 2.5D Detection](https://www.kaggle.com/code/ipythonx/wip-vesuvius-surface-2-5d-detection)\n\n**Note**\n1. The inference code below is adapted from the **Keras-JAX** version. The PyTorch and Lightning implementations follow the same workflow. Training was performed on a single Tesla T4 (16 GB VRAM) with extended epochs.\n2. Both the training and inference pipelines are implemented using [`medicai`](https://github.com/innat/medic-ai), a **Keras 3** based multi-backend medical ML library designed for 2D and 3D classification and segmentation tasks. However, please note, `medicai` project is still new and actively evolving.","metadata":{}},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"from IPython.display import clear_output\n\nvar=\"/kaggle/input/vsdetection-packages-offline-installer-only/whls\"\n!pip install \\\n  \"$var\"/keras_nightly-*.whl \\\n  \"$var\"/tifffile-*.whl \\\n  \"$var\"/imagecodecs-*.whl \\\n  \"$var\"/medicai-*.whl \\\n  --no-index \\\n  --find-links \"$var\"\n\nclear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:24:40.698302Z","iopub.execute_input":"2026-01-29T06:24:40.698708Z","iopub.status.idle":"2026-01-29T06:24:48.291306Z","shell.execute_reply.started":"2026-01-29T06:24:40.698674Z","shell.execute_reply":"2026-01-29T06:24:48.290536Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nos.environ[\"KERAS_BACKEND\"] = \"jax\"\n\nimport keras\nfrom keras import ops\nfrom medicai.transforms import (\n    Compose,\n    ScaleIntensityRange,\n    NormalizeIntensity\n)\nfrom medicai.models import SegFormer, TransUNet\nfrom medicai.utils.inference import SlidingWindowInference\n\nimport numpy as np\nimport pandas as pd\nimport zipfile\nimport tifffile\nimport scipy.ndimage as ndi\nfrom skimage.morphology import remove_small_objects\nfrom matplotlib import pyplot as plt\n\nkeras.config.backend(), keras.version()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:30:56.47316Z","iopub.execute_input":"2026-01-29T06:30:56.47354Z","iopub.status.idle":"2026-01-29T06:30:56.480392Z","shell.execute_reply.started":"2026-01-29T06:30:56.473521Z","shell.execute_reply":"2026-01-29T06:30:56.479463Z"},"_kg_hide-output":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Dataset**","metadata":{}},{"cell_type":"code","source":"root_dir = \"/kaggle/input/vesuvius-challenge-surface-detection\"\ntest_dir = f\"{root_dir}/test_images\"\noutput_dir = \"/kaggle/working/submission_masks\"\nzip_path = \"/kaggle/working/submission.zip\"\nos.makedirs(output_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:02.398974Z","iopub.execute_input":"2026-01-29T06:25:02.399529Z","iopub.status.idle":"2026-01-29T06:25:02.403914Z","shell.execute_reply.started":"2026-01-29T06:25:02.399507Z","shell.execute_reply":"2026-01-29T06:25:02.402868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = pd.read_csv(f\"{root_dir}/test.csv\")\ntest_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:02.404744Z","iopub.execute_input":"2026-01-29T06:25:02.405665Z","iopub.status.idle":"2026-01-29T06:25:02.460022Z","shell.execute_reply.started":"2026-01-29T06:25:02.405635Z","shell.execute_reply":"2026-01-29T06:25:02.459246Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Transformation**","metadata":{}},{"cell_type":"code","source":"def val_transformation(image):\n    data = {\"image\": image}\n    pipeline = Compose([\n        NormalizeIntensity(\n            keys=[\"image\"], \n            nonzero=True,\n            channel_wise=False\n        ),\n    ])\n    result = pipeline(data)\n    return result[\"image\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:02.461907Z","iopub.execute_input":"2026-01-29T06:25:02.46228Z","iopub.status.idle":"2026-01-29T06:25:02.466843Z","shell.execute_reply.started":"2026-01-29T06:25:02.462261Z","shell.execute_reply":"2026-01-29T06:25:02.465894Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Model**","metadata":{}},{"cell_type":"code","source":"tta=1\nnum_classes=3\ninput_shape=(160, 160, 160)\nkaggle_model_path = \"/kaggle/input/vsd-model/keras/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:02.467795Z","iopub.execute_input":"2026-01-29T06:25:02.468138Z","iopub.status.idle":"2026-01-29T06:25:02.479757Z","shell.execute_reply.started":"2026-01-29T06:25:02.468119Z","shell.execute_reply":"2026-01-29T06:25:02.479102Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def get_model():\n    ## LB: 0.486\n    # model = SegFormer(\n    #     input_shape=(128, 128, 128, 1),\n    #     encoder_name='mit_b2',\n    #     classifier_activation='softmax',\n    #     num_classes=2,\n    # )\n    # model.load_weights(\n    #     \"/kaggle/input/vsd-model/keras/segformer.mit.b2/2/segformer.mit.b2.weights.h5\"\n    # )\n\n    ## LB: 0.5 \n    # model = TransUNet(\n    #     input_shape=(128, 128, 128, 1),\n    #     encoder_name='seresnext50',\n    #     classifier_activation='softmax',\n    #     num_classes=2,\n    # )\n    # model.load_weights(\n    #     f\"{kaggle_model_path}/transunet/2/transunet.seresnext50.128px.weights.h5\"\n    # )\n\n    # ## LB: 505\n    # model = TransUNet(\n    #     input_shape=(160, 160, 160, 1),\n    #     encoder_name='seresnext50',\n    #     classifier_activation='softmax',\n    #     num_classes=3,\n    # )\n    # model.load_weights(\n    #     f\"{kaggle_model_path}/transunet/2/transunet.seresnext50.160px.weights.h5\"\n    # )\n\n    # 0.545 (tta+pp)\n    model = TransUNet(\n        input_shape=(160, 160, 160, 1),\n        encoder_name='seresnext50',\n        classifier_activation=None, # For tta, do softmax later.\n        num_classes=3,\n    )\n    model.load_weights(\n        f\"{kaggle_model_path}/transunet/3/transunet.seresnext50.160px.comboloss.weights.h5\"\n    )\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:02.480537Z","iopub.execute_input":"2026-01-29T06:25:02.480802Z","iopub.status.idle":"2026-01-29T06:25:02.491928Z","shell.execute_reply.started":"2026-01-29T06:25:02.480778Z","shell.execute_reply":"2026-01-29T06:25:02.491234Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = get_model()\nmodel.count_params() / 1e6","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:02.49279Z","iopub.execute_input":"2026-01-29T06:25:02.493071Z","iopub.status.idle":"2026-01-29T06:25:23.026604Z","shell.execute_reply.started":"2026-01-29T06:25:02.493054Z","shell.execute_reply":"2026-01-29T06:25:23.025766Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.instance_describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:23.02746Z","iopub.execute_input":"2026-01-29T06:25:23.027771Z","iopub.status.idle":"2026-01-29T06:25:23.102092Z","shell.execute_reply.started":"2026-01-29T06:25:23.02775Z","shell.execute_reply":"2026-01-29T06:25:23.101275Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Sliding Window Inference**","metadata":{}},{"cell_type":"code","source":"swi = SlidingWindowInference(\n    model,\n    num_classes=3,\n    roi_size=input_shape,\n    sw_batch_size=1,\n    mode='gaussian',\n    overlap=0.5,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:23.105566Z","iopub.execute_input":"2026-01-29T06:25:23.106079Z","iopub.status.idle":"2026-01-29T06:25:23.111287Z","shell.execute_reply.started":"2026-01-29T06:25:23.10606Z","shell.execute_reply":"2026-01-29T06:25:23.110442Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_volume(path):\n    vol = tifffile.imread(path)\n    vol = vol.astype(np.float32)\n    vol = vol[None, ..., None]\n    return vol","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:23.112476Z","iopub.execute_input":"2026-01-29T06:25:23.112784Z","iopub.status.idle":"2026-01-29T06:25:23.124367Z","shell.execute_reply.started":"2026-01-29T06:25:23.112756Z","shell.execute_reply":"2026-01-29T06:25:23.123223Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Test Time Augmentation (TTA)**","metadata":{}},{"cell_type":"code","source":"def predict_with_tta(inputs, swi):\n    logits = []\n\n    # Original\n    logits.append(swi(inputs))\n\n    # Flips (spatial only)\n    for axis in [1, 2, 3]:\n        img_f = np.flip(inputs, axis=axis)\n        p = swi(img_f)\n        p = np.flip(p, axis=axis)\n        logits.append(p)\n\n    # Axial rotations (H, W)\n    for k in [1, 2, 3]:\n        img_r = np.rot90(inputs, k=k, axes=(2, 3))\n        p = swi(img_r)\n        p = np.rot90(p, k=-k, axes=(2, 3))\n        logits.append(p)\n\n    mean_logits = np.mean(logits, axis=0)\n    mean_prob = ops.softmax(mean_logits, axis=-1)\n    return mean_prob.argmax(-1).astype(np.uint8).squeeze()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:23.125462Z","iopub.execute_input":"2026-01-29T06:25:23.125914Z","iopub.status.idle":"2026-01-29T06:25:23.138101Z","shell.execute_reply.started":"2026-01-29T06:25:23.125895Z","shell.execute_reply":"2026-01-29T06:25:23.13725Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Post Processing**","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/choudharymanas/inference-baseline-transunet-lb-0-537\ndef build_anisotropic_struct(z_radius: int, xy_radius: int):\n    z, r = z_radius, xy_radius\n    if z == 0 and r == 0:\n        return None\n    if z == 0 and r > 0:\n        size = 2 * r + 1\n        struct = np.zeros((1, size, size), dtype=bool)\n        cy, cx = r, r\n        for dy in range(-r, r + 1):\n            for dx in range(-r, r + 1):\n                if dy * dy + dx * dx <= r * r:\n                    struct[0, cy + dy, cx + dx] = True\n        return struct\n    if z > 0 and r == 0:\n        struct = np.zeros((2 * z + 1, 1, 1), dtype=bool)\n        struct[:, 0, 0] = True\n        return struct\n    depth = 2 * z + 1\n    size = 2 * r + 1\n    struct = np.zeros((depth, size, size), dtype=bool)\n    cz, cy, cx = z, r, r\n    for dz in range(-z, z + 1):\n        for dy in range(-r, r + 1):\n            for dx in range(-r, r + 1):\n                if dy * dy + dx * dx <= r * r:\n                    struct[cz + dz, cy + dy, cx + dx] = True\n    return struct\n\ndef topo_postprocess(\n    probs,\n    T_low=0.90,\n    T_high=0.90,\n    z_radius=1,\n    xy_radius=0,\n    dust_min_size=100,\n):\n    # Step 1: 3D Hysteresis\n    strong = probs >= T_high\n    weak   = probs >= T_low\n\n    if not strong.any():\n        return np.zeros_like(probs, dtype=np.uint8)\n\n    struct_hyst = ndi.generate_binary_structure(3, 3)\n    mask = ndi.binary_propagation(\n        strong, mask=weak, structure=struct_hyst\n    )\n\n    if not mask.any():\n        return np.zeros_like(probs, dtype=np.uint8)\n\n    # Step 2: 3D Anisotropic Closing\n    if z_radius > 0 or xy_radius > 0:\n        struct_close = build_anisotropic_struct(z_radius, xy_radius)\n        if struct_close is not None:\n            mask = ndi.binary_closing(mask, structure=struct_close)\n\n    # Step 3: Dust Removal\n    if dust_min_size > 0:\n        mask = remove_small_objects(\n            mask.astype(bool), min_size=dust_min_size\n        )\n\n    return mask.astype(np.uint8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:23.140788Z","iopub.execute_input":"2026-01-29T06:25:23.141068Z","iopub.status.idle":"2026-01-29T06:25:23.162827Z","shell.execute_reply.started":"2026-01-29T06:25:23.141051Z","shell.execute_reply":"2026-01-29T06:25:23.161121Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Prediction and Zip Submission**","metadata":{}},{"cell_type":"code","source":"def inference_pipelines(\n    volume,\n    T_low=0.50,\n    T_high=0.90,\n    z_radius=1,\n    xy_radius=0,\n    dust_min_size=100,\n):\n    probs = predict_with_tta(volume, swi)\n    final = topo_postprocess(\n        probs,\n        T_low=T_low,\n        T_high=T_high,\n        z_radius=z_radius,\n        xy_radius=xy_radius,\n        dust_min_size=dust_min_size,\n    )\n    return final","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:25:23.16595Z","iopub.execute_input":"2026-01-29T06:25:23.166389Z","iopub.status.idle":"2026-01-29T06:25:23.177779Z","shell.execute_reply.started":"2026-01-29T06:25:23.166364Z","shell.execute_reply":"2026-01-29T06:25:23.177117Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with zipfile.ZipFile(\n    zip_path, \"w\", compression=zipfile.ZIP_DEFLATED\n) as z:\n    for image_id in test_df[\"id\"]:\n        tif_path = f\"{test_dir}/{image_id}.tif\"\n        \n        volume = load_volume(tif_path)\n        volume = val_transformation(volume)\n        output = inference_pipelines(volume) \n        \n        out_path = f\"{output_dir}/{image_id}.tif\"\n        tifffile.imwrite(out_path, output.astype(np.uint8))\n\n        z.write(out_path, arcname=f\"{image_id}.tif\")\n        os.remove(out_path)\n\nprint(\"Submission ZIP:\", zip_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:28:32.213798Z","iopub.execute_input":"2026-01-29T06:28:32.214667Z","iopub.status.idle":"2026-01-29T06:30:56.471895Z","shell.execute_reply.started":"2026-01-29T06:28:32.21464Z","shell.execute_reply":"2026-01-29T06:30:56.470935Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Sample View**","metadata":{}},{"cell_type":"code","source":"def plot_sample(x, y, sample_idx=0, max_slices=16):\n    img = np.squeeze(x[sample_idx])  # make (D, H, W)\n    mask = np.squeeze(y[sample_idx])  # make (D, H, W)\n    D = img.shape[0]\n\n    # Decide which slices to plot\n    step = max(1, D // max_slices)\n    slices = range(0, D, step)\n\n    n_slices = len(slices)\n    fig, axes = plt.subplots(2, n_slices, figsize=(3*n_slices, 6))\n\n    for i, s in enumerate(slices):\n        axes[0, i].imshow(img[s], cmap='gray')\n        axes[0, i].set_title(f\"Slice {s}\")\n        axes[0, i].axis('off')\n\n        axes[1, i].imshow(mask[s], cmap='gray')\n        axes[1, i].set_title(f\"Mask {s}\")\n        axes[1, i].axis('off')\n\n    plt.suptitle(f\"Sample {sample_idx}\")\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:28:14.221527Z","iopub.execute_input":"2026-01-29T06:28:14.221898Z","iopub.status.idle":"2026-01-29T06:28:14.228955Z","shell.execute_reply.started":"2026-01-29T06:28:14.221872Z","shell.execute_reply":"2026-01-29T06:28:14.22795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_sample(\n    volume.numpy(), output[None], sample_idx=0, max_slices=5\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-29T06:28:14.22986Z","iopub.execute_input":"2026-01-29T06:28:14.230278Z","iopub.status.idle":"2026-01-29T06:28:15.219135Z","shell.execute_reply.started":"2026-01-29T06:28:14.230251Z","shell.execute_reply":"2026-01-29T06:28:15.218108Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}