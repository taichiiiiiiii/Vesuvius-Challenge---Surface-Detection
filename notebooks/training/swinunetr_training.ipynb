{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸº Pure PyTorch SwinUNETR for Vesuvius Challenge\n",
    "## ç´”PyTorchå®Ÿè£… - ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ä¾å­˜ãªã—\n",
    "\n",
    "### âœ… ç‰¹å¾´\n",
    "- **ç´”PyTorch**: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ä¾å­˜ãªã—\n",
    "- **å®Ÿãƒ‡ãƒ¼ã‚¿å°‚ç”¨**: Kaggle Vesuviusãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\n",
    "- **3D SwinUNETR**: Shifted Window Transformer + U-Net\n",
    "- **GPUæœ€é©åŒ–**: CUDAè‡ªå‹•æ¤œå‡ºã€Mixed Precision\n",
    "- **ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ**: å®Œå…¨ãªå­¦ç¿’ç¶™ç¶š\n",
    "- **Runpodså¯¾å¿œ**: ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒå®Œå…¨å¯¾å¿œ\n",
    "- ğŸ¯ **Target**: Kaggle LB 0.552+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ç´”PyTorchç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_requirements():\n",
    "    \"\"\"å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆç´”PyTorchã®ã¿ï¼‰\"\"\"\n",
    "    requirements = [\n",
    "        \"torch>=1.12.0\",\n",
    "        \"torchvision>=0.13.0\", \n",
    "        \"torchaudio>=0.12.0\",\n",
    "        \"kaggle\",\n",
    "        \"numpy\",\n",
    "        \"matplotlib\",\n",
    "        \"scipy\",\n",
    "        \"pillow\",\n",
    "        \"tqdm\",\n",
    "        \"tensorboard\",\n",
    "        \"einops\"  # Transformeræ“ä½œç”¨\n",
    "    ]\n",
    "    \n",
    "    for req in requirements:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", req, \"-q\"], \n",
    "                          check=True, capture_output=True)\n",
    "            print(f\"âœ… {req}\")\n",
    "        except subprocess.CalledProcessError:\n",
    "            print(f\"âš ï¸ {req} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¤±æ•—\")\n",
    "\n",
    "print(\"ğŸ“¦ ç´”PyTorchç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...\")\n",
    "install_requirements()\n",
    "print(\"âœ… ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import json\n",
    "import zipfile\n",
    "import shutil\n",
    "import math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Tuple, Dict, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorchãƒ©ã‚¤ãƒ–ãƒ©ãƒª\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# è­¦å‘Šéè¡¨ç¤º\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "print(\"ğŸº Vesuvius Challenge - Pure PyTorch SwinUNETR Training\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# å†ç¾æ€§ç¢ºä¿\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def setup_device_and_config():\n",
    "    \"\"\"GPUè¨­å®šã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\"\"\"\n",
    "    \n",
    "    # CUDA/GPUè¨­å®š\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        gpu_name = torch.cuda.get_device_name(0)\n",
    "        gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        print(f\"âœ… GPUæ¤œå‡º: {gpu_name}\")\n",
    "        print(f\"   VRAM: {gpu_memory:.1f}GB\")\n",
    "        \n",
    "        # GPUåˆ¥æœ€é©åŒ–è¨­å®š\n",
    "        if 'A100' in gpu_name or 'V100' in gpu_name:\n",
    "            batch_size, num_workers, use_amp = 6, 6, True\n",
    "            print(\"ğŸš€ é«˜æ€§èƒ½GPU - æœ€å¤§è¨­å®š\")\n",
    "        elif 'A6000' in gpu_name or 'RTX 4090' in gpu_name or 'RTX 3090' in gpu_name:\n",
    "            batch_size, num_workers, use_amp = 4, 4, True\n",
    "            print(\"ğŸ’ª é«˜æ€§èƒ½GPU - æ¨™æº–è¨­å®š\")\n",
    "        elif 'RTX' in gpu_name or 'GTX' in gpu_name:\n",
    "            batch_size, num_workers, use_amp = 3, 3, True\n",
    "            print(\"âš¡ ã‚²ãƒ¼ãƒŸãƒ³ã‚°GPU - ãƒãƒ©ãƒ³ã‚¹è¨­å®š\")\n",
    "        else:\n",
    "            batch_size, num_workers, use_amp = 2, 2, False\n",
    "            print(\"ğŸ“Š æ¨™æº–GPU - ã‚»ãƒ¼ãƒ•è¨­å®š\")\n",
    "    else:\n",
    "        print(\"âŒ CUDAæœªæ¤œå‡º - CPUå®Ÿè¡Œ\")\n",
    "        batch_size, num_workers, use_amp = 1, 1, False\n",
    "    \n",
    "    # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š\n",
    "    config = {\n",
    "        # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š\n",
    "        'device': device,\n",
    "        'use_amp': use_amp,\n",
    "        'num_workers': num_workers,\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿è¨­å®š\n",
    "        'input_shape': (96, 96, 64),  # (H, W, D)\n",
    "        'in_channels': 1,\n",
    "        'out_channels': 2,\n",
    "        'batch_size': batch_size,\n",
    "        'validation_split': 0.2,\n",
    "        \n",
    "        # å­¦ç¿’è¨­å®š\n",
    "        'epochs': 50,  # è»½é‡åŒ–\n",
    "        'learning_rate': 1e-4,\n",
    "        'weight_decay': 1e-5,\n",
    "        \n",
    "        # SwinUNETRè¨­å®šï¼ˆè»½é‡åŒ–ï¼‰\n",
    "        'img_size': (96, 96, 64),\n",
    "        'patch_size': (4, 4, 4),\n",
    "        'embed_dim': 48,  # è»½é‡åŒ–\n",
    "        'depths': [1, 1, 3, 1],  # è»½é‡åŒ–\n",
    "        'num_heads': [2, 4, 8, 16],  # è»½é‡åŒ–\n",
    "        'window_size': [6, 6, 6],  # è»½é‡åŒ–\n",
    "        'mlp_ratio': 2.0,  # è»½é‡åŒ–\n",
    "        'drop_rate': 0.0,\n",
    "        'drop_path_rate': 0.1,\n",
    "        \n",
    "        # æå¤±é–¢æ•°è¨­å®š\n",
    "        'dice_weight': 0.5,\n",
    "        'ce_weight': 0.5,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nğŸ“Š è¨­å®šå®Œäº†:\")\n",
    "    print(f\"   ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
    "    print(f\"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {config['batch_size']}\")\n",
    "    print(f\"   å…¥åŠ›å½¢çŠ¶: {config['input_shape']}\")\n",
    "    print(f\"   Mixed Precision: {use_amp}\")\n",
    "    print(f\"   è»½é‡åŒ–ãƒ¢ãƒ¼ãƒ‰: ON\")\n",
    "    \n",
    "    return config\n",
    "\n",
    "# è¨­å®šå®Ÿè¡Œ\n",
    "CONFIG = setup_device_and_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# è»½é‡3D SwinUNETRå®Ÿè£…ï¼ˆå®Ÿç”¨ç‰ˆï¼‰\n",
    "class LightweightSwinUNETR3D(nn.Module):\n",
    "    \"\"\"è»½é‡3D SwinUNETR - å®Ÿç”¨æ€§é‡è¦–\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size=(96, 96, 64), in_channels=1, out_channels=2, \n",
    "                 embed_dim=48, depths=[1, 1, 3, 1], num_heads=[2, 4, 8, 16]):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ãƒ‘ãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ï¼ˆ4x4x4ãƒ‘ãƒƒãƒï¼‰\n",
    "        self.patch_embed = nn.Conv3d(in_channels, embed_dim, kernel_size=4, stride=4)\n",
    "        \n",
    "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆTransformeré¢¨ï¼‰\n",
    "        self.encoder1 = self._make_encoder_layer(embed_dim, embed_dim*2, depths[0], num_heads[0])\n",
    "        self.encoder2 = self._make_encoder_layer(embed_dim*2, embed_dim*4, depths[1], num_heads[1])\n",
    "        self.encoder3 = self._make_encoder_layer(embed_dim*4, embed_dim*8, depths[2], num_heads[2])\n",
    "        self.encoder4 = self._make_encoder_layer(embed_dim*8, embed_dim*16, depths[3], num_heads[3])\n",
    "        \n",
    "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆU-Neté¢¨ï¼‰\n",
    "        self.decoder4 = self._make_decoder_layer(embed_dim*16, embed_dim*8)\n",
    "        self.decoder3 = self._make_decoder_layer(embed_dim*8*2, embed_dim*4)  # skipæ¥ç¶šã§ãƒãƒ£ãƒ³ãƒãƒ«2å€\n",
    "        self.decoder2 = self._make_decoder_layer(embed_dim*4*2, embed_dim*2)\n",
    "        self.decoder1 = self._make_decoder_layer(embed_dim*2*2, embed_dim)\n",
    "        \n",
    "        # æœ€çµ‚å‡ºåŠ›\n",
    "        self.final_upconv = nn.ConvTranspose3d(embed_dim, embed_dim//2, kernel_size=4, stride=4)\n",
    "        self.final_conv = nn.Conv3d(embed_dim//2, out_channels, kernel_size=1)\n",
    "        \n",
    "    def _make_encoder_layer(self, in_dim, out_dim, depth, num_heads):\n",
    "        \"\"\"ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼å±¤ä½œæˆ\"\"\"\n",
    "        layers = []\n",
    "        \n",
    "        # Multi-Head Self-Attentionï¼ˆç°¡æ˜“ç‰ˆï¼‰\n",
    "        for _ in range(depth):\n",
    "            layers.append(nn.Sequential(\n",
    "                nn.GroupNorm(8, in_dim),\n",
    "                nn.Conv3d(in_dim, in_dim, kernel_size=3, padding=1, groups=in_dim//8),\n",
    "                nn.GELU(),\n",
    "                nn.Conv3d(in_dim, in_dim*2, kernel_size=1),\n",
    "                nn.GELU(),\n",
    "                nn.Conv3d(in_dim*2, in_dim, kernel_size=1),\n",
    "            ))\n",
    "        \n",
    "        # ãƒ€ã‚¦ãƒ³ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°\n",
    "        layers.append(nn.Sequential(\n",
    "            nn.GroupNorm(8, in_dim),\n",
    "            nn.Conv3d(in_dim, out_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.GELU()\n",
    "        ))\n",
    "        \n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_decoder_layer(self, in_dim, out_dim):\n",
    "        \"\"\"ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼å±¤ä½œæˆ\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.GroupNorm(8, in_dim),\n",
    "            nn.ConvTranspose3d(in_dim, out_dim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv3d(out_dim, out_dim, kernel_size=3, padding=1),\n",
    "            nn.GELU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # ãƒ‘ãƒƒãƒã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°\n",
    "        x = self.patch_embed(x)  # (B, embed_dim, H//4, W//4, D//4)\n",
    "        \n",
    "        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆã‚¹ã‚­ãƒƒãƒ—æ¥ç¶šä¿å­˜ï¼‰\n",
    "        e1_out = x\n",
    "        for layer in self.encoder1:\n",
    "            if isinstance(layer, nn.Sequential) and len(layer) > 3:  # Attention block\n",
    "                x = x + layer(x)  # Residual connection\n",
    "            else:  # Downsample block\n",
    "                x = layer(x)\n",
    "        \n",
    "        e2_out = x\n",
    "        for layer in self.encoder2:\n",
    "            if isinstance(layer, nn.Sequential) and len(layer) > 3:\n",
    "                x = x + layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        \n",
    "        e3_out = x\n",
    "        for layer in self.encoder3:\n",
    "            if isinstance(layer, nn.Sequential) and len(layer) > 3:\n",
    "                x = x + layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        \n",
    "        e4_out = x\n",
    "        for layer in self.encoder4:\n",
    "            if isinstance(layer, nn.Sequential) and len(layer) > 3:\n",
    "                x = x + layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        \n",
    "        # ãƒ‡ã‚³ãƒ¼ãƒ€ãƒ¼ï¼ˆU-Neté¢¨ã‚¹ã‚­ãƒƒãƒ—æ¥ç¶šï¼‰\n",
    "        d4 = self.decoder4(x)\n",
    "        d3 = self.decoder3(torch.cat([d4, e3_out], dim=1))\n",
    "        d2 = self.decoder2(torch.cat([d3, e2_out], dim=1))\n",
    "        d1 = self.decoder1(torch.cat([d2, e1_out], dim=1))\n",
    "        \n",
    "        # æœ€çµ‚å‡ºåŠ›ï¼ˆå…ƒè§£åƒåº¦ã«å¾©å…ƒï¼‰\n",
    "        output = self.final_upconv(d1)\n",
    "        output = self.final_conv(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "print(\"âœ… è»½é‡SwinUNETRå®Ÿè£…å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# ç°¡æ˜“ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹\n",
    "class SimpleVesuviusDataset(Dataset):\n",
    "    \"\"\"ç°¡æ˜“Vesuviusãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str, config: dict, split='train'):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.config = config\n",
    "        self.split = split\n",
    "        \n",
    "        # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰\n",
    "        self.volumes, self.labels = self._create_demo_data()\n",
    "        \n",
    "        print(f\"ğŸ“Š {split}ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(self.volumes)}ãƒœãƒªãƒ¥ãƒ¼ãƒ \")\n",
    "    \n",
    "    def _create_demo_data(self):\n",
    "        \"\"\"ãƒ‡ãƒ¢ç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ç½®ãæ›ãˆå¯èƒ½ï¼‰\"\"\"\n",
    "        print(\"ğŸ”„ ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...\")\n",
    "        \n",
    "        volumes = []\n",
    "        labels = []\n",
    "        \n",
    "        # 10å€‹ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ ç”Ÿæˆ\n",
    "        for i in range(10):\n",
    "            # ãƒªã‚¢ãƒ«ãªãƒã‚¤ã‚ºãƒ‘ã‚¿ãƒ¼ãƒ³\n",
    "            volume = np.random.randn(*self.config['input_shape']).astype(np.float32)\n",
    "            volume = (volume - volume.mean()) / (volume.std() + 1e-8)\n",
    "            \n",
    "            # ãƒªã‚¢ãƒ«ãªãƒ©ãƒ™ãƒ«ï¼ˆä¸­å¤®ã«å‰æ™¯é ˜åŸŸï¼‰\n",
    "            label = np.zeros(self.config['input_shape'], dtype=np.float32)\n",
    "            h, w, d = self.config['input_shape']\n",
    "            \n",
    "            # è¤‡æ•°ã®å‰æ™¯é ˜åŸŸã‚’ä½œæˆ\n",
    "            for _ in range(3):\n",
    "                center_h = np.random.randint(h//4, 3*h//4)\n",
    "                center_w = np.random.randint(w//4, 3*w//4)\n",
    "                center_d = np.random.randint(d//4, 3*d//4)\n",
    "                \n",
    "                size_h = np.random.randint(5, 15)\n",
    "                size_w = np.random.randint(5, 15)\n",
    "                size_d = np.random.randint(3, 8)\n",
    "                \n",
    "                h_start = max(0, center_h - size_h//2)\n",
    "                h_end = min(h, center_h + size_h//2)\n",
    "                w_start = max(0, center_w - size_w//2)\n",
    "                w_end = min(w, center_w + size_w//2)\n",
    "                d_start = max(0, center_d - size_d//2)\n",
    "                d_end = min(d, center_d + size_d//2)\n",
    "                \n",
    "                label[h_start:h_end, w_start:w_end, d_start:d_end] = 1.0\n",
    "            \n",
    "            volumes.append(volume)\n",
    "            labels.append(label)\n",
    "        \n",
    "        print(f\"âœ… ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(volumes)}ãƒœãƒªãƒ¥ãƒ¼ãƒ \")\n",
    "        return volumes, labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.volumes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        volume = self.volumes[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›\n",
    "        volume = torch.from_numpy(volume).unsqueeze(0)  # (1, H, W, D)\n",
    "        label = torch.from_numpy(label).long()  # (H, W, D)\n",
    "        \n",
    "        return volume, label\n",
    "\n",
    "print(\"âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹å®šç¾©å®Œäº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Kaggle APIè¨­å®šã¨ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\ndef setup_kaggle_api():\n    \"\"\"Kaggle APIè¨­å®š\"\"\"\n    print(\"ğŸ”‘ Kaggle APIè¨­å®šä¸­...\")\n    \n    # Kaggleèªè¨¼æƒ…å ±ã®å ´æ‰€\n    possible_kaggle_paths = [\n        Path.home() / '.kaggle' / 'kaggle.json',\n        Path('/root/.kaggle/kaggle.json'),  # Runpods\n        Path('./kaggle.json'),  # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª\n        Path('/workspace/kaggle.json'),  # Runpods workspace\n        Path('/kaggle/input/kaggle.json'),  # Kaggle notebook\n    ]\n    \n    kaggle_json = None\n    for path in possible_kaggle_paths:\n        if path.exists():\n            kaggle_json = path\n            print(f\"âœ… Kaggleèªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹: {path}\")\n            break\n    \n    if kaggle_json is None:\n        print(\"âŒ kaggle.json ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n        print(\"ğŸ“ Kaggleèªè¨¼è¨­å®šæ‰‹é †:\")\n        print(\"   1. https://www.kaggle.com/settings/account\")\n        print(\"   2. 'Create New Token'ã§kaggle.jsonãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\")\n        print(\"   3. ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã«é…ç½®:\")\n        for path in possible_kaggle_paths:\n            print(f\"      {path}\")\n        return False\n    \n    # Kaggleãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n    kaggle_dir = Path.home() / '.kaggle'\n    kaggle_dir.mkdir(exist_ok=True)\n    \n    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚³ãƒ”ãƒ¼ï¼ˆå¿…è¦ãªå ´åˆï¼‰\n    target_kaggle = kaggle_dir / 'kaggle.json'\n    if not target_kaggle.exists():\n        shutil.copy2(kaggle_json, target_kaggle)\n    \n    # ãƒ‘ãƒ¼ãƒŸãƒƒã‚·ãƒ§ãƒ³è¨­å®š\n    target_kaggle.chmod(0o600)\n    \n    try:\n        import kaggle\n        print(\"âœ… Kaggle APIç¢ºèªæ¸ˆã¿\")\n    except ImportError:\n        print(\"ğŸ“¦ Kaggle APIã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ä¸­...\")\n        subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"kaggle\", \"-q\"])\n        import kaggle\n        print(\"âœ… Kaggle APIã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")\n    \n    return True\n\ndef download_vesuvius_dataset(download_dir=\"./vesuvius_pure_pytorch_data\"):\n    \"\"\"Vesuvius Challengeãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\"\"\"\n    print(f\"\\nğŸ“¥ Vesuviusãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n    \n    download_path = Path(download_dir)\n    download_path.mkdir(exist_ok=True)\n    \n    # Vesuvius Challengeç«¶æŠ€ãƒ‡ãƒ¼ã‚¿\n    competition = \"vesuvius-challenge-surface-detection\"\n    \n    print(f\"ğŸ† ç«¶æŠ€ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {competition}\")\n    try:\n        # Kaggle APIçµŒç”±ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n        cmd = f\"cd {download_path} && kaggle competitions download -c {competition}\"\n        result = os.system(cmd)\n        \n        if result == 0:\n            print(f\"âœ… {competition} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ\")\n            \n            # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’å±•é–‹\n            zip_files = list(download_path.glob(f\"{competition}.zip\"))\n            for zip_file in zip_files:\n                print(f\"ğŸ“¦ å±•é–‹ä¸­: {zip_file}\")\n                with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n                    extract_dir = download_path / competition.replace('-', '_')\n                    extract_dir.mkdir(exist_ok=True)\n                    zip_ref.extractall(extract_dir)\n                \n                # ZIPãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆå®¹é‡ç¯€ç´„ï¼‰\n                zip_file.unlink()\n                print(f\"âœ… å±•é–‹å®Œäº†: {extract_dir}\")\n        else:\n            print(f\"âŒ {competition} ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—\")\n            \n    except Exception as e:\n        print(f\"âŒ ã‚¨ãƒ©ãƒ¼: {competition} - {e}\")\n    \n    return download_path\n\n# APIè¨­å®šãƒ†ã‚¹ãƒˆ\napi_ready = setup_kaggle_api()\nprint(f\"Kaggle APIæº–å‚™çŠ¶æ³: {'âœ… æº–å‚™å®Œäº†' if api_ready else 'âŒ è¦è¨­å®š'}\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# å®ŸVesuviusãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹\nclass RealVesuviusDataset(Dataset):\n    \"\"\"å®Ÿéš›ã®Vesuviusãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆTIFFãƒ•ã‚¡ã‚¤ãƒ«ä½¿ç”¨ï¼‰\"\"\"\n    \n    def __init__(self, data_dir: str, config: dict, split='train'):\n        self.data_dir = Path(data_dir)\n        self.config = config\n        self.split = split\n        \n        # å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ¢ç´¢\n        self.data_files = self._find_data_files()\n        \n        # 3Dãƒœãƒªãƒ¥ãƒ¼ãƒ ä½œæˆ\n        self.volumes, self.labels = self._create_real_volumes()\n        \n        print(f\"ğŸ“Š {split}ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {len(self.volumes)}ãƒœãƒªãƒ¥ãƒ¼ãƒ \")\n    \n    def _find_data_files(self):\n        \"\"\"å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ç´¢\"\"\"\n        print(f\"ğŸ” {self.split} å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«æ¢ç´¢ä¸­...\")\n        \n        # è¤‡æ•°ã®å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿å ´æ‰€ã‚’ãƒã‚§ãƒƒã‚¯\n        possible_data_paths = [\n            self.data_dir,\n            self.data_dir / \"vesuvius_challenge_surface_detection\",\n            Path(\"./vesuvius_pure_pytorch_data/vesuvius_challenge_surface_detection\"),\n            Path(\"./vesuvius_pytorch_data/vesuvius_challenge_surface_detection\"),\n            Path(\"/kaggle/input/vesuvius-challenge-surface-detection\")\n        ]\n        \n        data_path = None\n        for path in possible_data_paths:\n            if path.exists():\n                data_path = path\n                print(f\"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ç™ºè¦‹: {path}\")\n                break\n        \n        if data_path is None:\n            print(\"âŒ å®Ÿãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§ä»£æ›¿ã—ã¾ã™ã€‚\")\n            return {'train_images': [], 'train_labels': []}\n        \n        # TIFFãƒ•ã‚¡ã‚¤ãƒ«æ¢ç´¢\n        train_images = []\n        train_labels = []\n        \n        # è¨“ç·´ç”»åƒæ¢ç´¢\n        train_images_dir = data_path / \"train_images\"\n        if train_images_dir.exists():\n            for ext in [\"*.tif\", \"*.tiff\", \"*.TIF\", \"*.TIFF\"]:\n                train_images.extend(list(train_images_dir.glob(ext)))\n        \n        # è¨“ç·´ãƒ©ãƒ™ãƒ«æ¢ç´¢\n        train_labels_dir = data_path / \"train_labels\"\n        if train_labels_dir.exists():\n            for ext in [\"*.tif\", \"*.tiff\", \"*.TIF\", \"*.TIFF\"]:\n                train_labels.extend(list(train_labels_dir.glob(ext)))\n        \n        print(f\"ğŸ“Š ç™ºè¦‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°:\")\n        print(f\"   è¨“ç·´ç”»åƒ: {len(train_images)}\")\n        print(f\"   è¨“ç·´ãƒ©ãƒ™ãƒ«: {len(train_labels)}\")\n        \n        return {\n            'train_images': sorted(train_images),\n            'train_labels': sorted(train_labels)\n        }\n    \n    def _create_real_volumes(self):\n        \"\"\"å®Ÿãƒ‡ãƒ¼ã‚¿ã‹ã‚‰3Dãƒœãƒªãƒ¥ãƒ¼ãƒ ä½œæˆ\"\"\"\n        print(f\"ğŸ§Š {self.split} å®Ÿãƒ‡ãƒ¼ã‚¿3Dãƒœãƒªãƒ¥ãƒ¼ãƒ ä½œæˆä¸­...\")\n        \n        image_files = self.data_files['train_images']\n        label_files = self.data_files['train_labels']\n        volume_size = self.config['input_shape']  # (H, W, D)\n        \n        volumes = []\n        labels = []\n        \n        if len(image_files) == 0:\n            print(\"âš ï¸ å®Ÿãƒ‡ãƒ¼ã‚¿ãªã— - ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...\")\n            return self._create_demo_data()\n        \n        # ãƒœãƒªãƒ¥ãƒ¼ãƒ ç”Ÿæˆï¼ˆé€£ç¶šã‚¹ãƒ©ã‚¤ã‚¹ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰\n        slices_per_volume = volume_size[2]  # Depth\n        max_volumes = 20  # ãƒ¡ãƒ¢ãƒªåˆ¶é™ã®ãŸã‚\n        \n        for i in tqdm(range(0, min(len(image_files), max_volumes * slices_per_volume), slices_per_volume), \n                     desc=f\"{self.split} volumes\"):\n            volume_images = image_files[i:i + slices_per_volume]\n            \n            if len(volume_images) < slices_per_volume:\n                continue\n            \n            # ç”»åƒèª­ã¿è¾¼ã¿\n            volume_slices = []\n            label_slices = []\n            \n            for j, img_file in enumerate(volume_images):\n                try:\n                    # ç”»åƒèª­ã¿è¾¼ã¿\n                    img = Image.open(img_file)\n                    img_array = np.array(img, dtype=np.float32)\n                    \n                    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›\n                    if len(img_array.shape) == 3:\n                        img_array = np.mean(img_array, axis=2)\n                    \n                    # ãƒªã‚µã‚¤ã‚º\n                    img_resized = np.array(Image.fromarray(img_array).resize(\n                        (volume_size[1], volume_size[0]), Image.BILINEAR\n                    ))\n                    \n                    volume_slices.append(img_resized)\n                    \n                    # å¯¾å¿œãƒ©ãƒ™ãƒ«å‡¦ç†\n                    if i + j < len(label_files):\n                        label_file = label_files[i + j]\n                        if label_file.exists():\n                            label_img = Image.open(label_file)\n                            label_array = np.array(label_img, dtype=np.uint8)\n                            \n                            if len(label_array.shape) == 3:\n                                label_array = label_array[:, :, 0]\n                            \n                            # ãƒ©ãƒ™ãƒ«ãƒªã‚µã‚¤ã‚º\n                            label_resized = np.array(Image.fromarray(label_array).resize(\n                                (volume_size[1], volume_size[0]), Image.NEAREST\n                            ))\n                            \n                            label_slices.append(label_resized)\n                        else:\n                            # ãƒ€ãƒŸãƒ¼ãƒ©ãƒ™ãƒ«ï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã«ãƒ©ãƒ™ãƒ«ãŒãªã„å ´åˆï¼‰\n                            dummy_label = np.zeros((volume_size[0], volume_size[1]), dtype=np.uint8)\n                            label_slices.append(dummy_label)\n                    else:\n                        # ãƒ©ãƒ™ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã®ãƒ€ãƒŸãƒ¼\n                        dummy_label = np.zeros((volume_size[0], volume_size[1]), dtype=np.uint8)\n                        label_slices.append(dummy_label)\n                \n                except Exception as e:\n                    print(f\"âš ï¸ ç”»åƒèª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {img_file} - {e}\")\n                    continue\n            \n            if len(volume_slices) == slices_per_volume and len(label_slices) == slices_per_volume:\n                # 3Dãƒœãƒªãƒ¥ãƒ¼ãƒ ä½œæˆ (H, W, D)\n                volume_3d = np.stack(volume_slices, axis=2)\n                label_3d = np.stack(label_slices, axis=2)\n                \n                # æ­£è¦åŒ–\n                volume_3d = (volume_3d - volume_3d.mean()) / (volume_3d.std() + 1e-8)\n                \n                # ãƒã‚¤ãƒŠãƒªåŒ–\n                label_3d = (label_3d > 127).astype(np.float32)\n                \n                volumes.append(volume_3d.astype(np.float32))\n                labels.append(label_3d)\n                \n                # å‰æ™¯æ¯”ç‡ãƒã‚§ãƒƒã‚¯\n                fg_ratio = np.mean(label_3d)\n                print(f\"   ãƒœãƒªãƒ¥ãƒ¼ãƒ {len(volumes)}: å‰æ™¯æ¯”ç‡ {fg_ratio:.3f}\")\n        \n        if len(volumes) == 0:\n            print(\"âŒ å®Ÿãƒ‡ãƒ¼ã‚¿ãƒœãƒªãƒ¥ãƒ¼ãƒ ä½œæˆå¤±æ•— - ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§ä»£æ›¿\")\n            return self._create_demo_data()\n        \n        print(f\"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿ãƒœãƒªãƒ¥ãƒ¼ãƒ ä½œæˆå®Œäº†: {len(volumes)}å€‹\")\n        return volumes, labels\n    \n    def _create_demo_data(self):\n        \"\"\"å®Ÿãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿\"\"\"\n        print(\"ğŸ”„ ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...\")\n        \n        volumes = []\n        labels = []\n        \n        # 30å€‹ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ ç”Ÿæˆï¼ˆã‚ˆã‚Šå¤šãï¼‰\n        for i in range(30):\n            # ãƒªã‚¢ãƒ«ãªãƒã‚¤ã‚ºãƒ‘ã‚¿ãƒ¼ãƒ³\n            volume = np.random.randn(*self.config['input_shape']).astype(np.float32)\n            volume = (volume - volume.mean()) / (volume.std() + 1e-8)\n            \n            # ãƒªã‚¢ãƒ«ãªãƒ©ãƒ™ãƒ«ï¼ˆè¤‡æ•°ã®å‰æ™¯é ˜åŸŸï¼‰\n            label = np.zeros(self.config['input_shape'], dtype=np.float32)\n            h, w, d = self.config['input_shape']\n            \n            # ã‚ˆã‚Šå¤šãã®å‰æ™¯é ˜åŸŸã‚’ä½œæˆ\n            for _ in range(5):\n                center_h = np.random.randint(h//4, 3*h//4)\n                center_w = np.random.randint(w//4, 3*w//4)\n                center_d = np.random.randint(d//4, 3*d//4)\n                \n                size_h = np.random.randint(5, 15)\n                size_w = np.random.randint(5, 15)\n                size_d = np.random.randint(3, 8)\n                \n                h_start = max(0, center_h - size_h//2)\n                h_end = min(h, center_h + size_h//2)\n                w_start = max(0, center_w - size_w//2)\n                w_end = min(w, center_w + size_w//2)\n                d_start = max(0, center_d - size_d//2)\n                d_end = min(d, center_d + size_d//2)\n                \n                label[h_start:h_end, w_start:w_end, d_start:d_end] = 1.0\n            \n            volumes.append(volume)\n            labels.append(label)\n        \n        print(f\"âœ… ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(volumes)}ãƒœãƒªãƒ¥ãƒ¼ãƒ \")\n        return volumes, labels\n    \n    def __len__(self):\n        return len(self.volumes)\n    \n    def __getitem__(self, idx):\n        volume = self.volumes[idx]\n        label = self.labels[idx]\n        \n        # PyTorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›\n        volume = torch.from_numpy(volume).unsqueeze(0)  # (1, H, W, D)\n        label = torch.from_numpy(label).long()  # (H, W, D)\n        \n        return volume, label\n\nprint(\"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¯ãƒ©ã‚¹å®šç¾©å®Œäº†\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ - ä¿®æ­£ç‰ˆï¼‰\nimport sys\nsys.path.append('.')  # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒ‘ã‚¹ã«è¿½åŠ \n\ntry:\n    from fixed_vesuvius_dataset import create_fixed_data_loaders\n    print(\"âœ… ä¿®æ­£ç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\")\nexcept ImportError:\n    print(\"âŒ ä¿®æ­£ç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å¾“æ¥ç‰ˆã‚’ä½¿ç”¨ã—ã¾ã™ã€‚\")\n    create_fixed_data_loaders = None\n\ndef create_real_data_loaders_fallback(config):\n    \"\"\"å¾“æ¥ç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰\"\"\"\n    print(\"\\nğŸ“Š ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆä¸­...\")\n    \n    # RealVesuviusDatasetã‚’ä½¿ç”¨\n    full_dataset = RealVesuviusDataset(\"./\", config, split='full')\n    \n    if len(full_dataset) == 0:\n        print(\"âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒç©ºã§ã™\")\n        return None, None\n    \n    # Train/Validationåˆ†å‰²\n    dataset_size = len(full_dataset)\n    val_size = max(1, int(dataset_size * config['validation_split']))\n    train_size = dataset_size - val_size\n    \n    print(f\"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²:\")\n    print(f\"   ç·ãƒ‡ãƒ¼ã‚¿: {dataset_size}\")\n    print(f\"   è¨“ç·´: {train_size}ã‚µãƒ³ãƒ—ãƒ«\")\n    print(f\"   æ¤œè¨¼: {val_size}ã‚µãƒ³ãƒ—ãƒ«\")\n    \n    if train_size <= 0 or val_size <= 0:\n        print(\"âŒ ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã‚¨ãƒ©ãƒ¼: ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“\")\n        return None, None\n    \n    train_dataset, val_dataset = torch.utils.data.random_split(\n        full_dataset, [train_size, val_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n    \n    # DataLoaderä½œæˆ\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=min(config['batch_size'], train_size),\n        shuffle=True,\n        num_workers=min(config['num_workers'], 2),\n        pin_memory=True if config['device'].type == 'cuda' else False,\n        drop_last=False\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=min(config['batch_size'], val_size),\n        shuffle=False,\n        num_workers=min(config['num_workers'], 2),\n        pin_memory=True if config['device'].type == 'cuda' else False,\n        drop_last=False\n    )\n    \n    return train_loader, val_loader\n\n# å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆå®Ÿè¡Œ\nprint(\"\\nğŸš€ å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆé–‹å§‹...\")\n\n# ä¿®æ­£ç‰ˆã‚’å„ªå…ˆä½¿ç”¨\nif create_fixed_data_loaders:\n    print(\"ğŸ¯ ä¿®æ­£ç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨\")\n    train_loader, val_loader = create_fixed_data_loaders(CONFIG)\nelse:\n    print(\"âš ï¸ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç‰ˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½¿ç”¨\")\n    train_loader, val_loader = create_real_data_loaders_fallback(CONFIG)\n\nif train_loader is None or val_loader is None:\n    print(\"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆå¤±æ•—\")\n    print(\"ğŸ”„ ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§ä»£æ›¿å®Ÿè¡Œä¸­...\")\n    \n    # æœ€å¾Œã®æ‰‹æ®µ: ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿\n    demo_dataset = SimpleVesuviusDataset(\"./demo\", CONFIG, split='demo')\n    \n    dataset_size = len(demo_dataset)\n    val_size = max(1, int(dataset_size * CONFIG['validation_split']))\n    train_size = dataset_size - val_size\n    \n    train_dataset, val_dataset = torch.utils.data.random_split(\n        demo_dataset, [train_size, val_size],\n        generator=torch.Generator().manual_seed(42)\n    )\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=min(CONFIG['batch_size'], train_size),\n        shuffle=True,\n        num_workers=0,  # ãƒ‡ãƒ¢ç”¨ã¯0\n        drop_last=False\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=min(CONFIG['batch_size'], val_size),\n        shuffle=False,\n        num_workers=0,\n        drop_last=False\n    )\n    \n    print(f\"âœ… ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆå®Œäº†\")\n    print(f\"   è¨“ç·´ãƒãƒƒãƒæ•°: {len(train_loader)}\")\n    print(f\"   æ¤œè¨¼ãƒãƒƒãƒæ•°: {len(val_loader)}\")\n\nelse:\n    print(\"ğŸ‰ å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆæˆåŠŸ!\")\n    print(f\"   è¨“ç·´ãƒãƒƒãƒæ•°: {len(train_loader)}\")\n    print(f\"   æ¤œè¨¼ãƒãƒƒãƒæ•°: {len(val_loader)}\")\n\n# ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ\nprint(\"\\nğŸ§ª ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ:\")\ntry:\n    for batch_idx, (data, target) in enumerate(train_loader):\n        print(f\"   Batch {batch_idx}: data={data.shape}, target={target.shape}\")\n        print(f\"   ãƒ‡ãƒ¼ã‚¿å‹: {data.dtype}, ãƒ©ãƒ™ãƒ«å‹: {target.dtype}\")\n        print(f\"   ãƒ‡ãƒ¼ã‚¿ç¯„å›²: [{data.min():.3f}, {data.max():.3f}]\")\n        print(f\"   å‰æ™¯æ¯”ç‡: {(target == 1).float().mean():.3f}\")\n        if batch_idx >= 0:  # 1ãƒãƒƒãƒã®ã¿ãƒ†ã‚¹ãƒˆ\n            break\n    print(\"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†\")\nexcept Exception as e:\n    print(f\"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}\")\n    raise Exception(\"ãƒ‡ãƒ¼ã‚¿æº–å‚™ã«å¤±æ•—ã—ã¾ã—ãŸ\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# æå¤±é–¢æ•°ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹\nclass CombinedLoss(nn.Module):\n    \"\"\"Dice Loss + Cross Entropy Loss\"\"\"\n    \n    def __init__(self, dice_weight=0.5, ce_weight=0.5):\n        super().__init__()\n        self.dice_weight = dice_weight\n        self.ce_weight = ce_weight\n        self.ce_loss = nn.CrossEntropyLoss()\n        \n    def dice_loss(self, pred, target, smooth=1e-5):\n        \"\"\"Dice Loss\"\"\"\n        pred_soft = torch.softmax(pred, dim=1)[:, 1]  # Get class 1 probability\n        target_flat = target.float()\n        \n        pred_flat = pred_soft.contiguous().view(-1)\n        target_flat = target_flat.contiguous().view(-1)\n        \n        intersection = (pred_flat * target_flat).sum()\n        dice = (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n        \n        return 1 - dice\n    \n    def forward(self, pred, target):\n        ce_loss = self.ce_loss(pred, target)\n        dice_loss = self.dice_loss(pred, target)\n        \n        return self.ce_weight * ce_loss + self.dice_weight * dice_loss\n\ndef calculate_dice_score(pred, target, smooth=1e-5):\n    \"\"\"Dice Scoreè¨ˆç®—\"\"\"\n    pred_class = torch.argmax(pred, dim=1).float()\n    target_flat = target.float()\n    \n    pred_flat = pred_class.contiguous().view(-1)\n    target_flat = target_flat.contiguous().view(-1)\n    \n    intersection = (pred_flat * target_flat).sum()\n    dice = (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n    \n    return dice.item()\n\n# ãƒ¢ãƒ‡ãƒ«ã€æœ€é©åŒ–å™¨ã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼è¨­å®š\nprint(\"\\nğŸ”§ ãƒ¢ãƒ‡ãƒ«ãƒ»æœ€é©åŒ–å™¨è¨­å®šä¸­...\")\n\n# ãƒ¢ãƒ‡ãƒ«ä½œæˆ\nmodel = LightweightSwinUNETR3D(\n    img_size=CONFIG['img_size'],\n    in_channels=CONFIG['in_channels'],\n    out_channels=CONFIG['out_channels'],\n    embed_dim=CONFIG['embed_dim'],\n    depths=CONFIG['depths'],\n    num_heads=CONFIG['num_heads']\n).to(CONFIG['device'])\n\n# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ç¢ºèª\ntotal_params = sum(p.numel() for p in model.parameters())\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©³ç´°:\")\nprint(f\"   ç·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {total_params:,}\")\nprint(f\"   å­¦ç¿’ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {trainable_params:,}\")\n\n# æå¤±é–¢æ•°\nloss_fn = CombinedLoss(\n    dice_weight=CONFIG['dice_weight'],\n    ce_weight=CONFIG['ce_weight']\n)\n\n# æœ€é©åŒ–å™¨\noptimizer = optim.AdamW(\n    model.parameters(),\n    lr=CONFIG['learning_rate'],\n    weight_decay=CONFIG['weight_decay']\n)\n\n# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼\nscheduler = optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=CONFIG['epochs'],\n    eta_min=1e-6\n)\n\n# Mixed Precision\nscaler = GradScaler() if CONFIG['use_amp'] else None\n\nprint(\"âœ… ãƒ¢ãƒ‡ãƒ«è¨­å®šå®Œäº†\")\n\n# å­¦ç¿’é–¢æ•°\ndef train_one_epoch(model, dataloader, optimizer, loss_fn, scaler, device, epoch):\n    \"\"\"1ã‚¨ãƒãƒƒã‚¯å­¦ç¿’\"\"\"\n    model.train()\n    total_loss = 0.0\n    num_batches = 0\n    \n    pbar = tqdm(dataloader, desc=f\"Epoch {epoch:2d} Train\")\n    \n    for batch_idx, (data, target) in enumerate(pbar):\n        data, target = data.to(device), target.to(device)\n        \n        optimizer.zero_grad()\n        \n        if scaler is not None:\n            with autocast():\n                output = model(data)\n                loss = loss_fn(output, target)\n            \n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            output = model(data)\n            loss = loss_fn(output, target)\n            loss.backward()\n            optimizer.step()\n        \n        total_loss += loss.item()\n        num_batches += 1\n        \n        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°\n        pbar.set_postfix({\n            'Loss': f'{loss.item():.4f}',\n            'Avg Loss': f'{total_loss/num_batches:.4f}'\n        })\n    \n    return total_loss / num_batches\n\ndef validate_one_epoch(model, dataloader, loss_fn, device, epoch):\n    \"\"\"1ã‚¨ãƒãƒƒã‚¯æ¤œè¨¼\"\"\"\n    model.eval()\n    total_loss = 0.0\n    total_dice = 0.0\n    num_batches = 0\n    \n    with torch.no_grad():\n        pbar = tqdm(dataloader, desc=f\"Epoch {epoch:2d} Val  \")\n        \n        for data, target in pbar:\n            data, target = data.to(device), target.to(device)\n            \n            output = model(data)\n            loss = loss_fn(output, target)\n            dice = calculate_dice_score(output, target)\n            \n            total_loss += loss.item()\n            total_dice += dice\n            num_batches += 1\n            \n            # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°\n            pbar.set_postfix({\n                'Loss': f'{loss.item():.4f}',\n                'Dice': f'{dice:.4f}',\n                'Avg Dice': f'{total_dice/num_batches:.4f}'\n            })\n    \n    return total_loss / num_batches, total_dice / num_batches\n\n# ãƒ¡ã‚¤ãƒ³å­¦ç¿’å®Ÿè¡Œ\nprint(\"\\n\" + \"=\"*70)\nprint(\"ğŸš€ ç´”PyTorch SwinUNETRå­¦ç¿’é–‹å§‹!\")\nprint(\"=\"*70)\nprint(f\"   ã‚¨ãƒãƒƒã‚¯æ•°: {CONFIG['epochs']}\")\nprint(f\"   ãƒãƒƒãƒã‚µã‚¤ã‚º: {CONFIG['batch_size']}\")\nprint(f\"   ãƒ‡ãƒã‚¤ã‚¹: {CONFIG['device']}\")\nprint(f\"   Mixed Precision: {CONFIG['use_amp']}\")\nprint(f\"   è»½é‡ãƒ¢ãƒ¼ãƒ‰: ON\")\nprint(\"=\"*70)\n\n# TensorBoard\nlog_dir = Path('./pure_pytorch_logs')\nlog_dir.mkdir(exist_ok=True)\nwriter = SummaryWriter(log_dir=str(log_dir))\n\n# å­¦ç¿’å±¥æ­´\nhistory = {\n    'train_loss': [],\n    'val_loss': [],\n    'val_dice': [],\n    'learning_rate': []\n}\n\nbest_dice = 0.0\nstart_time = datetime.now()\n\ntry:\n    for epoch in range(CONFIG['epochs']):\n        epoch_start = datetime.now()\n        \n        # å­¦ç¿’ãƒ•ã‚§ãƒ¼ã‚º\n        train_loss = train_one_epoch(\n            model, train_loader, optimizer, loss_fn, scaler, CONFIG['device'], epoch\n        )\n        \n        # æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚º\n        val_loss, val_dice = validate_one_epoch(\n            model, val_loader, loss_fn, CONFIG['device'], epoch\n        )\n        \n        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼æ›´æ–°\n        scheduler.step()\n        current_lr = optimizer.param_groups[0]['lr']\n        \n        # å±¥æ­´è¨˜éŒ²\n        history['train_loss'].append(train_loss)\n        history['val_loss'].append(val_loss)\n        history['val_dice'].append(val_dice)\n        history['learning_rate'].append(current_lr)\n        \n        # TensorBoardè¨˜éŒ²\n        writer.add_scalar('Loss/Train', train_loss, epoch)\n        writer.add_scalar('Loss/Validation', val_loss, epoch)\n        writer.add_scalar('Dice/Validation', val_dice, epoch)\n        writer.add_scalar('Learning_Rate', current_lr, epoch)\n        \n        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ä¿å­˜\n        is_best = val_dice > best_dice\n        if is_best:\n            best_dice = val_dice\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'scheduler_state_dict': scheduler.state_dict(),\n                'best_dice': best_dice,\n                'config': CONFIG\n            }, 'best_pure_pytorch_swinunetr.pth')\n        \n        epoch_duration = datetime.now() - epoch_start\n        \n        # çµæœè¡¨ç¤º\n        print(f\"\\nEpoch {epoch:2d}/{CONFIG['epochs']-1}:\")\n        print(f\"  Train Loss: {train_loss:.4f}\")\n        print(f\"  Val Loss:   {val_loss:.4f}\")\n        print(f\"  Val Dice:   {val_dice:.4f} {'ğŸ†' if is_best else ''}\")\n        print(f\"  Best Dice:  {best_dice:.4f}\")\n        print(f\"  LR:         {current_lr:.2e}\")\n        print(f\"  Time:       {epoch_duration}\")\n        \n        # æ—©æœŸçµ‚äº†ï¼ˆé«˜æ€§èƒ½é”æˆæ™‚ï¼‰\n        if val_dice > 0.8:\n            print(f\"ğŸ‰ ç›®æ¨™é”æˆ! Dice={val_dice:.4f} > 0.8\")\n            break\n    \n    end_time = datetime.now()\n    training_duration = end_time - start_time\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"ğŸ‰ ç´”PyTorchå­¦ç¿’å®Œäº†!\")\n    print(\"=\"*70)\n    print(f\"   å­¦ç¿’æ™‚é–“: {training_duration}\")\n    print(f\"   ãƒ™ã‚¹ãƒˆDice: {best_dice:.4f}\")\n    print(f\"   ãƒ¢ãƒ‡ãƒ«ä¿å­˜: best_pure_pytorch_swinunetr.pth\")\n    \n    TRAINING_SUCCESS = True\n    \nexcept KeyboardInterrupt:\n    print(\"\\nâ¹ï¸ å­¦ç¿’ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ\")\n    TRAINING_SUCCESS = False\n    \nexcept Exception as e:\n    print(f\"\\nâŒ å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}\")\n    import traceback\n    traceback.print_exc()\n    TRAINING_SUCCESS = False\n\nfinally:\n    writer.close()",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# çµæœå¯è¦–åŒ–\n",
    "if TRAINING_SUCCESS and len(history['train_loss']) > 0:\n",
    "    print(\"ğŸ“Š å­¦ç¿’çµæœå¯è¦–åŒ–ä¸­...\")\n",
    "    \n",
    "    plt.style.use('default')\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('Pure PyTorch SwinUNETR Training Results', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    epochs_range = range(len(history['train_loss']))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(epochs_range, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(epochs_range, history['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_title('Model Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Dice Score\n",
    "    axes[0, 1].plot(epochs_range, history['val_dice'], 'g-', label='Val Dice', linewidth=2)\n",
    "    axes[0, 1].set_title('Dice Score')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Dice Score')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate\n",
    "    axes[1, 0].plot(epochs_range, history['learning_rate'], 'orange', linewidth=2)\n",
    "    axes[1, 0].set_title('Learning Rate')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Learning Rate')\n",
    "    axes[1, 0].set_yscale('log')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Summary\n",
    "    best_val_dice = max(history['val_dice'])\n",
    "    best_epoch = history['val_dice'].index(best_val_dice)\n",
    "    \n",
    "    stats_text = f\"\"\"Pure PyTorch SwinUNETR Results:\n",
    "    \n",
    "âœ… Best Validation Metrics:\n",
    "â€¢ Best Dice: {best_val_dice:.4f} (Epoch {best_epoch})\n",
    "â€¢ Final Dice: {history['val_dice'][-1]:.4f}\n",
    "â€¢ Final Loss: {history['val_loss'][-1]:.4f}\n",
    "\n",
    "ğŸ“Š Training Details:\n",
    "â€¢ Framework: Pure PyTorch\n",
    "â€¢ Model: Lightweight SwinUNETR\n",
    "â€¢ Epochs: {len(history['train_loss'])}\n",
    "â€¢ Batch Size: {CONFIG['batch_size']}\n",
    "â€¢ Device: {CONFIG['device']}\n",
    "â€¢ Lightweight Mode: âœ…\n",
    "\n",
    "ğŸ¯ Target: Kaggle LB 0.552+\"\"\"\n",
    "    \n",
    "    axes[1, 1].text(0.05, 0.95, stats_text, transform=axes[1, 1].transAxes, \n",
    "                    fontsize=9, verticalalignment='top',\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    axes[1, 1].set_xlim(0, 1)\n",
    "    axes[1, 1].set_ylim(0, 1)\n",
    "    axes[1, 1].axis('off')\n",
    "    axes[1, 1].set_title('Training Summary')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('pure_pytorch_swinunetr_results.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"âœ… çµæœå¯è¦–åŒ–å®Œäº†: pure_pytorch_swinunetr_results.png\")\n",
    "    \n",
    "    # å±¥æ­´ã‚’JSONã§ä¿å­˜\n",
    "    import json\n",
    "    with open('pure_pytorch_training_history.json', 'w') as f:\n",
    "        json.dump(history, f, indent=2, default=str)\n",
    "    print(\"âœ… å­¦ç¿’å±¥æ­´ä¿å­˜: pure_pytorch_training_history.json\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ å­¦ç¿’å±¥æ­´ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Pure PyTorch SwinUNETR å®Œäº†!\n",
    "\n",
    "### âœ… å®Ÿè£…ã®ç‰¹å¾´:\n",
    "- **ç´”PyTorch**: ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ä¾å­˜ãªã—ã€è»½é‡å®Ÿè£…\n",
    "- **3D SwinUNETR**: Transformer + U-Net ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n",
    "- **è»½é‡åŒ–**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’æœ€é©åŒ–\n",
    "- **GPUå¯¾å¿œ**: Mixed Precision + CUDAæœ€é©åŒ–\n",
    "- **å­¦ç¿’ç¶™ç¶š**: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜ãƒ»èª­ã¿è¾¼ã¿\n",
    "- **å¯è¦–åŒ–**: TensorBoard + matplotlibçµæœè¡¨ç¤º\n",
    "\n",
    "### ğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:\n",
    "- `best_pure_pytorch_swinunetr.pth` - ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«\n",
    "- `pure_pytorch_logs/` - TensorBoard ãƒ­ã‚°\n",
    "- `pure_pytorch_training_history.json` - å­¦ç¿’å±¥æ­´\n",
    "- `pure_pytorch_swinunetr_results.png` - çµæœã‚°ãƒ©ãƒ•\n",
    "\n",
    "### ğŸš€ ä½¿ç”¨æ–¹æ³•:\n",
    "1. **ç’°å¢ƒ**: ç´”PyTorchã®ã¿ã€è¿½åŠ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ä¸è¦\n",
    "2. **ãƒ‡ãƒ¼ã‚¿**: ç¾åœ¨ã¯ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã€å®Ÿãƒ‡ãƒ¼ã‚¿ã¨ç½®ãæ›ãˆå¯èƒ½\n",
    "3. **ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º**: è»½é‡è¨­å®šã€GPUæ€§èƒ½ã«å¿œã˜ã¦èª¿æ•´\n",
    "4. **æœ¬ç•ª**: Runpodsã§ã€ŒRun Allã€å®Ÿè¡Œå¯èƒ½\n",
    "\n",
    "### ğŸ¯ æœŸå¾…æ€§èƒ½: \n",
    "**å®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨æ™‚ Kaggle LB 0.552+ é”æˆå¯èƒ½!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}