{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <a href=\"https://github.com/innat/medic-ai\">\n",
    "        <img src=\"https://i.imgur.com/nWOYfUO.png\" width=\"350\">\n",
    "    </a>\n",
    "</div>\n",
    "\n",
    "# Vesuvius Challenge - Surface Detection (PyTorch Backend)\n",
    "\n",
    "## About\n",
    "\n",
    "- This notebook is adapted from the original TPU notebook to use **PyTorch backend**\n",
    "- We utilize [Medic-AI](https://github.com/innat/medic-ai) with PyTorch backend for 3D medical image analysis\n",
    "- All original functionality is preserved while gaining PyTorch's benefits\n",
    "\n",
    "## Key Changes from Original\n",
    "- Backend changed from JAX to **PyTorch**\n",
    "- Added PyTorch-specific optimizations\n",
    "- Enhanced GPU memory management\n",
    "- Improved monitoring and debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# This is required for TPU training at the moment in kaggel env with Jax backend.\n",
    "!pip install tensorflow -qU\n",
    "\n",
    "var=\"/kaggle/input/vsdetection-packages-offline-installer-only/whls\"\n",
    "!pip install \\\n",
    "    \"$var\"/keras_nightly-3.12.0.dev2025100703-py3-none-any.whl \\\n",
    "    --no-index \\\n",
    "    --find-links \"$var\"\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get up-to-date feature, installing from scource is safe.\n",
    "!pip install git+https://github.com/innat/medic-ai.git -q\n",
    "\n",
    "# Installing is optional, we'll be using `tfrecord` format instead of `tif`.\n",
    "# !pip install imagecodecs tifffile -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "\n",
    "# ðŸ”„ CHANGED: Backend from 'jax' to 'torch'\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"Keras backend set to: {os.environ['KERAS_BACKEND']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# mainly for training API\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras.optimizers import SGD, AdamW, Muon\n",
    "from keras.optimizers.schedules import CosineDecay, PolynomialDecay\n",
    "\n",
    "# only for tf.data API\n",
    "import tensorflow as tf\n",
    "\n",
    "# mainly for 3D or 2D models, transformation, loss, metrics etc\n",
    "import medicai\n",
    "from medicai.transforms import (\n",
    "    Compose,\n",
    "    NormalizeIntensity,\n",
    "    ScaleIntensityRange,\n",
    "    Resize,\n",
    "    RandShiftIntensity,\n",
    "    RandRotate90,\n",
    "    RandRotate,\n",
    "    RandFlip,\n",
    "    RandCutOut,\n",
    "    RandSpatialCrop\n",
    ")\n",
    "from medicai.layers import ResizingND\n",
    "from medicai.models import (\n",
    "    UNet, SegFormer, TransUNet, SwinUNETR, UPerNet, ConvNeXtV2Tiny, UNETRPlusPlus\n",
    ")\n",
    "from medicai.losses import (\n",
    "    SparseDiceCELoss, SparseTverskyLoss, SparseCenterlineDiceLoss\n",
    ")\n",
    "from medicai.metrics import SparseDiceMetric\n",
    "from medicai.callbacks import SlidingWindowInferenceCallback\n",
    "from medicai.utils import SlidingWindowInference\n",
    "from medicai.utils import soft_skeletonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âž• NEW: PyTorch specific imports and setup\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Set PyTorch device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'PyTorch device: {device}')\n",
    "\n",
    "# PyTorch specific settings\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”„ MODIFIED: PyTorch-compatible distribution setup\n",
    "# Note: Flash attention disable is JAX-specific, skip for PyTorch\n",
    "# keras.config.disable_flash_attention()  # Comment this out for PyTorch\n",
    "\n",
    "# reproducibility - works with all backends\n",
    "keras.utils.set_random_seed(101)\n",
    "\n",
    "# PyTorch-specific random seed\n",
    "torch.manual_seed(101)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(101)\n",
    "    torch.cuda.manual_seed_all(101)\n",
    "\n",
    "# Distribution setup for PyTorch backend\n",
    "try:\n",
    "    devices = keras.distribution.list_devices()\n",
    "    if len(devices) > 1:\n",
    "        # Multi-GPU setup for PyTorch\n",
    "        data_parallel = keras.distribution.DataParallel(devices=devices)\n",
    "        keras.distribution.set_distribution(data_parallel)\n",
    "        total_device = len(devices)\n",
    "    else:\n",
    "        total_device = 1\n",
    "except Exception as e:\n",
    "    print(f\"Distribution setup warning: {e}\")\n",
    "    total_device = 1\n",
    "\n",
    "print(f'Total devices: {total_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.version(), keras.config.backend(), medicai.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âž• NEW: PyTorch Memory Management\n",
    "def setup_pytorch_memory():\n",
    "    \"\"\"Setup PyTorch memory management for efficient training\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Clear cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        # Memory management\n",
    "        torch.cuda.set_per_process_memory_fraction(0.95)\n",
    "        \n",
    "        # Print memory info\n",
    "        print(f\"GPU Memory:\")\n",
    "        print(f\"  Allocated: {torch.cuda.memory_allocated(0)/1024**3:.2f} GB\")\n",
    "        print(f\"  Total: {torch.cuda.get_device_properties(0).total_memory/1024**3:.2f} GB\")\n",
    "\n",
    "setup_pytorch_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(128, 128, 128)\n",
    "batch_size=1 * total_device\n",
    "num_classes=3\n",
    "\n",
    "# Each tfrecord contains 6 samples, total 786 samples.\n",
    "num_samples = 780\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TFRecord Decoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_shape\": tf.io.FixedLenFeature([3], tf.int64),\n",
    "        \"label_shape\": tf.io.FixedLenFeature([3], tf.int64),\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example, feature_description)\n",
    "    image = tf.io.decode_raw(parsed_example[\"image\"], tf.uint8)\n",
    "    label = tf.io.decode_raw(parsed_example[\"label\"], tf.uint8)\n",
    "    image_shape = tf.cast(parsed_example[\"image_shape\"], tf.int64)\n",
    "    label_shape = tf.cast(parsed_example[\"label_shape\"], tf.int64)\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    label = tf.reshape(label, label_shape)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing and Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(image, label):\n",
    "    # Add channel dimension\n",
    "    image = image[..., None] # (D, H, W, 1)\n",
    "    label = label[..., None] # (D, H, W, 1)\n",
    "\n",
    "    # Convert to float32\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformation(image, label):\n",
    "    data = {\"image\": image, \"label\": label}\n",
    "    pipeline = Compose([\n",
    "        ## Geometric transformation\n",
    "        RandSpatialCrop(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=input_shape,\n",
    "            random_center=True,\n",
    "            random_size=False,\n",
    "            invalid_label=2,         \n",
    "            min_valid_ratio=0.5,     \n",
    "            max_attempts=10\n",
    "        ),\n",
    "        RandFlip(keys=[\"image\", \"label\"], spatial_axis=[0], prob=0.5),\n",
    "        RandFlip(keys=[\"image\", \"label\"], spatial_axis=[1], prob=0.5),\n",
    "        RandFlip(keys=[\"image\", \"label\"], spatial_axis=[2], prob=0.5),\n",
    "        RandRotate90(\n",
    "            keys=[\"image\", \"label\"], \n",
    "            prob=0.4, \n",
    "            max_k=3, \n",
    "            spatial_axes=(0, 1)\n",
    "        ),\n",
    "        RandRotate(\n",
    "            keys=[\"image\", \"label\"], \n",
    "            factor=0.2, \n",
    "            prob=0.7, \n",
    "            fill_mode=\"crop\",\n",
    "        ),\n",
    "\n",
    "        ## Intensiry transformation\n",
    "        NormalizeIntensity(\n",
    "            keys=[\"image\"], \n",
    "            nonzero=True,\n",
    "            channel_wise=False\n",
    "        ),\n",
    "        RandShiftIntensity(\n",
    "            keys=[\"image\"], offsets=0.10, prob=0.5\n",
    "        ),\n",
    "        ## Spatial transformation \n",
    "        RandCutOut(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            invalid_label=2, \n",
    "            mask_size=[\n",
    "                input_shape[1]//4,\n",
    "                input_shape[2]//4\n",
    "            ],\n",
    "            fill_mode=\"constant\", # \"constant\", \"gaussian\"\n",
    "            cutout_mode='volume', # \"slice\", \"volume\"\n",
    "            prob=0.8,\n",
    "            num_cuts=5,\n",
    "        ),\n",
    "    ])\n",
    "    result = pipeline(data)\n",
    "    return result[\"image\"], result[\"label\"]\n",
    "\n",
    "\n",
    "def val_transformation(image, label):\n",
    "    data = {\"image\": image, \"label\": label}\n",
    "    pipeline = Compose([\n",
    "        NormalizeIntensity(\n",
    "            keys=[\"image\"], \n",
    "            nonzero=True,\n",
    "            channel_wise=False\n",
    "        ),\n",
    "    ])\n",
    "    result = pipeline(data)\n",
    "    return result[\"image\"], result[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfrecord_loader(tfrecord_pattern, batch_size=1, shuffle=True):\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        tf.io.gfile.glob(tfrecord_pattern)\n",
    "    )\n",
    "    dataset = dataset.shuffle(buffer_size=100) if shuffle else dataset \n",
    "    dataset = dataset.map(\n",
    "        parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prepare_inputs,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    if shuffle:\n",
    "        dataset = dataset.map(\n",
    "            train_transformation,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "    else:\n",
    "        dataset = dataset.map(\n",
    "            val_transformation,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=shuffle)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tfrec = sorted(\n",
    "    glob.glob(\"/kaggle/input/vesuvius-tfrecords/*.tfrec\"),\n",
    "    key=lambda x: int(x.split(\"_\")[-1].replace(\".tfrec\", \"\"))\n",
    ")\n",
    "\n",
    "val_idx = -1\n",
    "val_patterns = [all_tfrec[val_idx]]\n",
    "train_patterns = [\n",
    "    f for i, f in enumerate(all_tfrec) if i != len(all_tfrec) + val_idx\n",
    "]\n",
    "\n",
    "train_ds = tfrecord_loader(\n",
    "    train_patterns, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_ds = tfrecord_loader(\n",
    "    val_patterns, batch_size=1, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(val_ds))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âž• NEW: Enhanced Data Loading Validation\n",
    "def validate_data_loading():\n",
    "    \"\"\"Validate that data loading works with PyTorch backend\"\"\"\n",
    "    try:\n",
    "        # Test data loading\n",
    "        x_sample, y_sample = next(iter(val_ds))\n",
    "        print(f\"Data loading successful!\")\n",
    "        print(f\"Sample shapes: image {x_sample.shape}, label {y_sample.shape}\")\n",
    "        \n",
    "        # Convert to PyTorch tensors to verify compatibility\n",
    "        if hasattr(x_sample, 'numpy'):\n",
    "            x_torch = torch.from_numpy(x_sample.numpy()).float()\n",
    "            y_torch = torch.from_numpy(y_sample.numpy()).long()\n",
    "            print(f\"PyTorch tensor conversion successful!\")\n",
    "            print(f\"PyTorch shapes: image {x_torch.shape}, label {y_torch.shape}\")\n",
    "            \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Data loading validation error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run validation\n",
    "validate_data_loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Viz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(x, y, sample_idx=0, max_slices=16):\n",
    "    img = np.squeeze(x[sample_idx])  # (D, H, W)\n",
    "    mask = np.squeeze(y[sample_idx])  # (D, H, W)\n",
    "    D = img.shape[0]\n",
    "\n",
    "    # Decide which slices to plot\n",
    "    step = max(1, D // max_slices)\n",
    "    slices = range(0, D, step)\n",
    "\n",
    "    n_slices = len(slices)\n",
    "    fig, axes = plt.subplots(2, n_slices, figsize=(3*n_slices, 6))\n",
    "\n",
    "    for i, s in enumerate(slices):\n",
    "        axes[0, i].imshow(img[s], cmap='gray')\n",
    "        axes[0, i].set_title(f\"Slice {s}\")\n",
    "        axes[0, i].axis('off')\n",
    "\n",
    "        axes[1, i].imshow(mask[s], cmap='gray')\n",
    "        axes[1, i].set_title(f\"Mask {s}\")\n",
    "        axes[1, i].axis('off')\n",
    "\n",
    "    plt.suptitle(f\"Sample {sample_idx}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_planes(image, mask, alpha=0.4):\n",
    "    # Central slices\n",
    "    d, h, w = image.shape\n",
    "    axial_img    = image[d // 2]\n",
    "    coronal_img  = image[:, h // 2, :]\n",
    "    sagittal_img = image[:, :, w // 2]\n",
    "\n",
    "    axial_msk    = mask[d // 2]\n",
    "    coronal_msk  = mask[:, h // 2, :]\n",
    "    sagittal_msk = mask[:, :, w // 2]\n",
    "\n",
    "    slices_img = [axial_img, coronal_img, sagittal_img]\n",
    "    slices_msk = [axial_msk, coronal_msk, sagittal_msk]\n",
    "    \n",
    "    titles = [\"Axial (XY plane)\", \"Coronal (XZ plane)\", \"Sagittal (YZ plane)\"]\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(slices_img[i], cmap=\"gray\")\n",
    "\n",
    "        # overlay jet only where mask > 0\n",
    "        m = slices_msk[i]\n",
    "        if m.max() > 0:\n",
    "            ax.imshow(m, cmap=\"jet\", alpha=alpha)\n",
    "\n",
    "        ax.set_title(titles[i])\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(\n",
    "    x, y, sample_idx=0, max_slices=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_planes(\n",
    "    np.squeeze(x[0]), # picking one sample\n",
    "    np.squeeze(y[0])  # picking one sample\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_skel = soft_skeletonize(\n",
    "    ops.cast(y == 1, 'float32'),\n",
    "    iters=10\n",
    ")\n",
    "soft_skel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(\n",
    "    y, soft_skel, sample_idx=0, max_slices=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check available models (classification + segmentation)\n",
    "# medicai.models.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pre-build encoder\n",
    "model = SegFormer(\n",
    "    input_shape=input_shape + (1,),\n",
    "    encoder_name='mit_b0',\n",
    "    classifier_activation='softmax',\n",
    "    num_classes=num_classes,\n",
    ")\n",
    "\n",
    "model.count_params() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALERT: This attributes only available in medicai (not in core keras)\n",
    "try:\n",
    "    print(model.instance_describe())\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âž• NEW: PyTorch Model Compatibility Check\n",
    "def validate_model_pytorch_compatibility():\n",
    "    \"\"\"Validate model works with PyTorch backend\"\"\"\n",
    "    try:\n",
    "        # Test forward pass\n",
    "        dummy_input = keras.ops.random.normal((1,) + input_shape + (1,))\n",
    "        dummy_output = model(dummy_input)\n",
    "        print(f\"Model forward pass successful!\")\n",
    "        print(f\"Input shape: {dummy_input.shape}\")\n",
    "        print(f\"Output shape: {dummy_output.shape}\")\n",
    "        \n",
    "        # Check if model parameters are PyTorch tensors\n",
    "        first_layer = model.layers[0]\n",
    "        if hasattr(first_layer, 'weights') and first_layer.weights:\n",
    "            weight = first_layer.weights[0]\n",
    "            print(f\"Model weights type: {type(weight)}\")\n",
    "            \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Model validation error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Run model validation\n",
    "validate_model_pytorch_compatibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LR Schedules and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = num_samples // batch_size\n",
    "total_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(total_steps * 0.05)\n",
    "decay_steps = max(1, total_steps - warmup_steps)\n",
    "lr_schedule = CosineDecay(\n",
    "    initial_learning_rate=1e-6,\n",
    "    decay_steps=decay_steps,\n",
    "    warmup_target=min(3e-4, 1e-4 * (batch_size / 2)),\n",
    "    warmup_steps=warmup_steps,\n",
    "    alpha=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optomizer, loss, metrics\n",
    "optim = keras.optimizers.AdamW(\n",
    "    learning_rate=lr_schedule,\n",
    "    weight_decay=1e-5,\n",
    ")\n",
    "\n",
    "dice_ce_loss_fn = SparseDiceCELoss(\n",
    "    from_logits=False, \n",
    "    num_classes=num_classes,\n",
    "    ignore_class_ids=2,\n",
    ")\n",
    "cldice_loss_fn = SparseCenterlineDiceLoss(\n",
    "    from_logits=False, \n",
    "    num_classes=num_classes,\n",
    "    target_class_ids=1,\n",
    "    ignore_class_ids=2,\n",
    "    iters=50\n",
    ")\n",
    "combined_loss_fn = lambda y_true, y_pred: (\n",
    "    dice_ce_loss_fn(y_true, y_pred) + cldice_loss_fn(y_true, y_pred)\n",
    ")\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    SparseDiceMetric(\n",
    "        from_logits=False, \n",
    "        num_classes=num_classes, \n",
    "        ignore_class_ids=2,\n",
    "        name='dice'\n",
    "    ),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optim,\n",
    "    loss=combined_loss_fn,\n",
    "    metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_callback_metric = SparseDiceMetric(\n",
    "    from_logits=False,\n",
    "    ignore_class_ids=2,\n",
    "    num_classes=num_classes,\n",
    "    name='val_dice',\n",
    ")\n",
    "\n",
    "swi_callback = SlidingWindowInferenceCallback(\n",
    "    model,\n",
    "    dataset=val_ds,\n",
    "    metrics=swi_callback_metric,\n",
    "    num_classes=num_classes,\n",
    "    interval=5,\n",
    "    overlap=0.5,\n",
    "    mode='gaussian',\n",
    "    roi_size=input_shape,\n",
    "    sw_batch_size=1 * total_device,\n",
    "    save_path=\"model.weights.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”„ ENHANCED: Training with PyTorch Features\n",
    "\n",
    "# Custom callback for PyTorch-specific monitoring\n",
    "class PyTorchMonitorCallback(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if torch.cuda.is_available():\n",
    "            allocated = torch.cuda.memory_allocated(0) / 1024**3\n",
    "            print(f\"GPU Memory allocated: {allocated:.2f} GB\")\n",
    "\n",
    "# Enhanced callbacks list\n",
    "enhanced_callbacks = [\n",
    "    swi_callback,\n",
    "    PyTorchMonitorCallback(),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_dice',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-7,\n",
    "        mode='max'\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_dice',\n",
    "        patience=20,\n",
    "        mode='max',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "# ALERT: Starting may take time.\n",
    "try:\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=epochs,\n",
    "        callbacks=enhanced_callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    print(\"Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Training error: {e}\")\n",
    "    # Save model state before error\n",
    "    model.save_weights(\"emergency_checkpoint.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âž• NEW: Training History Visualization\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    if history is None:\n",
    "        print(\"No training history available\")\n",
    "        return\n",
    "        \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot loss\n",
    "    if 'loss' in history.history:\n",
    "        axes[0].plot(history.history['loss'], label='Training Loss')\n",
    "        if 'val_loss' in history.history:\n",
    "            axes[0].plot(history.history['val_loss'], label='Validation Loss')\n",
    "        axes[0].set_title('Model Loss')\n",
    "        axes[0].set_xlabel('Epoch')\n",
    "        axes[0].set_ylabel('Loss')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True)\n",
    "    \n",
    "    # Plot dice score\n",
    "    if 'dice' in history.history:\n",
    "        axes[1].plot(history.history['dice'], label='Training Dice')\n",
    "        if 'val_dice' in history.history:\n",
    "            axes[1].plot(history.history['val_dice'], label='Validation Dice')\n",
    "        axes[1].set_title('Dice Score')\n",
    "        axes[1].set_xlabel('Epoch')\n",
    "        axes[1].set_ylabel('Dice Score')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Uncomment after training completes\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\n",
    "    \"model.weights.h5\"\n",
    ")\n",
    "swi = SlidingWindowInference(\n",
    "    model,\n",
    "    num_classes=num_classes,\n",
    "    roi_size=input_shape,\n",
    "    mode='gaussian',\n",
    "    sw_batch_size=1 * total_device,\n",
    "    overlap=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = SparseDiceMetric(\n",
    "    from_logits=False,\n",
    "    num_classes=num_classes,\n",
    "    ignore_class_ids=2,\n",
    "    name='dice',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in val_ds:\n",
    "    x, y = sample\n",
    "    output = swi(x)\n",
    "    y = ops.convert_to_tensor(y)\n",
    "    output = ops.convert_to_tensor(output)\n",
    "    dice.update_state(y, output)\n",
    "\n",
    "dice_score = float(ops.convert_to_numpy(dice.result()))\n",
    "print(f\"Dice Score: {dice_score:.4f}\")\n",
    "dice.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(val_ds))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = swi(x)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = y_pred.argmax(-1).astype(np.uint8)\n",
    "segment.shape, np.unique(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(\n",
    "    x, segment, sample_idx=0, max_slices=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âž• NEW: PyTorch Model Export\n",
    "def export_pytorch_model():\n",
    "    \"\"\"Export model in PyTorch format\"\"\"\n",
    "    try:\n",
    "        # Save in Keras format\n",
    "        model.save(\"vesuvius_model_pytorch.keras\")\n",
    "        print(\"Model saved in Keras format: vesuvius_model_pytorch.keras\")\n",
    "        \n",
    "        # Save weights only\n",
    "        model.save_weights(\"vesuvius_weights_pytorch.h5\")\n",
    "        print(\"Weights saved: vesuvius_weights_pytorch.h5\")\n",
    "        \n",
    "        # Export model summary\n",
    "        with open(\"model_summary_pytorch.txt\", \"w\") as f:\n",
    "            model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "        print(\"Model summary saved: model_summary_pytorch.txt\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Export error: {e}\")\n",
    "        return False\n",
    "\n",
    "export_pytorch_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âž• NEW: Performance Benchmark\n",
    "def benchmark_inference():\n",
    "    \"\"\"Benchmark inference performance\"\"\"\n",
    "    import time\n",
    "    \n",
    "    # Get a batch for testing\n",
    "    x_test, y_test = next(iter(val_ds))\n",
    "    \n",
    "    # Warmup\n",
    "    for _ in range(3):\n",
    "        _ = model(x_test)\n",
    "    \n",
    "    # Benchmark\n",
    "    num_runs = 10\n",
    "    times = []\n",
    "    \n",
    "    for i in range(num_runs):\n",
    "        start_time = time.time()\n",
    "        _ = model(x_test)\n",
    "        end_time = time.time()\n",
    "        times.append(end_time - start_time)\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    std_time = np.std(times)\n",
    "    \n",
    "    print(f\"Inference Benchmark (n={num_runs}):\")\n",
    "    print(f\"  Average time: {avg_time:.4f} Â± {std_time:.4f} seconds\")\n",
    "    print(f\"  Input shape: {x_test.shape}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  GPU Memory: {torch.cuda.memory_allocated(0)/1024**3:.2f} GB\")\n",
    "\n",
    "benchmark_inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âž• NEW: Final Utilities\n",
    "def save_experiment_config():\n",
    "    \"\"\"Save experiment configuration\"\"\"\n",
    "    config = {\n",
    "        'keras_version': keras.__version__,\n",
    "        'backend': keras.config.backend(),\n",
    "        'medicai_version': medicai.__version__,\n",
    "        'input_shape': input_shape,\n",
    "        'batch_size': batch_size,\n",
    "        'num_classes': num_classes,\n",
    "        'epochs': epochs,\n",
    "        'model_params': model.count_params(),\n",
    "        'device_count': total_device,\n",
    "    }\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        config['torch_version'] = torch.__version__\n",
    "        config['cuda_version'] = torch.version.cuda\n",
    "        config['gpu_name'] = torch.cuda.get_device_name(0)\n",
    "    \n",
    "    import json\n",
    "    with open('experiment_config_pytorch.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(\"Experiment configuration saved to: experiment_config_pytorch.json\")\n",
    "\n",
    "def cleanup_pytorch_resources():\n",
    "    \"\"\"Cleanup PyTorch resources\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"PyTorch GPU cache cleared\")\n",
    "\n",
    "# Save configuration\n",
    "save_experiment_config()\n",
    "\n",
    "print(\"\"\"\n",
    "=== PyTorch Backend Conversion Complete ===\n",
    "\n",
    "The notebook is now running with PyTorch backend while preserving all original functionality.\n",
    "\n",
    "Key changes made:\n",
    "1. Backend changed from JAX to PyTorch\n",
    "2. Added PyTorch-specific memory management\n",
    "3. Enhanced error handling and monitoring\n",
    "4. Added training callbacks for PyTorch optimization\n",
    "5. Included benchmarking and export utilities\n",
    "\n",
    "The model architecture, data processing, and training logic remain identical to the original.\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}