{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vesuvius Challenge - Pure PyTorch Implementation\n",
    "完全なPyTorch実装（TensorFlow依存なし）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    # Data\n",
    "    input_shape = (64, 64, 64)  # (D, H, W) - adjust based on GPU memory\n",
    "    num_classes = 3\n",
    "    \n",
    "    # Training\n",
    "    batch_size = 2\n",
    "    epochs = 100\n",
    "    learning_rate = 3e-4\n",
    "    weight_decay = 1e-5\n",
    "    \n",
    "    # Paths\n",
    "    data_path = \"./data\"  # Change to your data path\n",
    "    checkpoint_path = \"best_model_pytorch.pth\"\n",
    "    \n",
    "    # Augmentation\n",
    "    use_augmentation = True\n",
    "    \n",
    "    # Mixed precision\n",
    "    use_amp = True\n",
    "    \n",
    "    # Sliding window inference\n",
    "    sw_batch_size = 4\n",
    "    overlap = 0.5\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentation3D:\n",
    "    \"\"\"3D augmentation for volumetric data\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_flip(image, label, axis):\n",
    "        if np.random.rand() > 0.5:\n",
    "            image = np.flip(image, axis=axis).copy()\n",
    "            label = np.flip(label, axis=axis).copy()\n",
    "        return image, label\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_rotate90(image, label):\n",
    "        if np.random.rand() > 0.5:\n",
    "            k = np.random.randint(1, 4)\n",
    "            axes = (1, 2)  # Rotate in H-W plane\n",
    "            image = np.rot90(image, k, axes).copy()\n",
    "            label = np.rot90(label, k, axes).copy()\n",
    "        return image, label\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_intensity_shift(image, shift_range=0.1):\n",
    "        if np.random.rand() > 0.5:\n",
    "            shift = np.random.uniform(-shift_range, shift_range)\n",
    "            image = image + shift\n",
    "            image = np.clip(image, 0, 1)\n",
    "        return image\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_crop(image, label, crop_size):\n",
    "        \"\"\"Random crop to specified size\"\"\"\n",
    "        d, h, w = image.shape\n",
    "        cd, ch, cw = crop_size\n",
    "        \n",
    "        # Random crop positions\n",
    "        d_start = np.random.randint(0, max(1, d - cd + 1))\n",
    "        h_start = np.random.randint(0, max(1, h - ch + 1))\n",
    "        w_start = np.random.randint(0, max(1, w - cw + 1))\n",
    "        \n",
    "        image_crop = image[d_start:d_start+cd, h_start:h_start+ch, w_start:w_start+cw]\n",
    "        label_crop = label[d_start:d_start+cd, h_start:h_start+ch, w_start:w_start+cw]\n",
    "        \n",
    "        return image_crop, label_crop\n",
    "    \n",
    "    @staticmethod\n",
    "    def apply(image, label, crop_size):\n",
    "        \"\"\"Apply augmentation pipeline\"\"\"\n",
    "        # Random crop\n",
    "        image, label = Augmentation3D.random_crop(image, label, crop_size)\n",
    "        \n",
    "        # Geometric augmentations\n",
    "        image, label = Augmentation3D.random_flip(image, label, axis=0)\n",
    "        image, label = Augmentation3D.random_flip(image, label, axis=1)\n",
    "        image, label = Augmentation3D.random_flip(image, label, axis=2)\n",
    "        image, label = Augmentation3D.random_rotate90(image, label)\n",
    "        \n",
    "        # Intensity augmentation\n",
    "        image = Augmentation3D.random_intensity_shift(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VesuviusDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for Vesuvius Challenge\"\"\"\n",
    "    \n",
    "    def __init__(self, data_files, config, is_train=True):\n",
    "        self.data_files = data_files\n",
    "        self.config = config\n",
    "        self.is_train = is_train\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Assuming each file contains multiple samples\n",
    "        return len(self.data_files) * 6  # Adjust based on your data\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # This is a placeholder - replace with actual data loading\n",
    "        # For demonstration, generating random data\n",
    "        \n",
    "        # In real implementation, load from your data files:\n",
    "        # file_idx = idx // 6\n",
    "        # sample_idx = idx % 6\n",
    "        # image, label = self.load_sample(self.data_files[file_idx], sample_idx)\n",
    "        \n",
    "        # Generate dummy data (replace with actual loading)\n",
    "        if self.is_train:\n",
    "            # Larger volume for cropping\n",
    "            image = np.random.randn(128, 128, 128).astype(np.float32)\n",
    "            label = np.random.randint(0, self.config.num_classes, (128, 128, 128))\n",
    "        else:\n",
    "            # Fixed size for validation\n",
    "            image = np.random.randn(*self.config.input_shape).astype(np.float32)\n",
    "            label = np.random.randint(0, self.config.num_classes, self.config.input_shape)\n",
    "        \n",
    "        # Normalize image\n",
    "        image = (image - image.mean()) / (image.std() + 1e-8)\n",
    "        \n",
    "        # Apply augmentation if training\n",
    "        if self.is_train and self.config.use_augmentation:\n",
    "            image, label = Augmentation3D.apply(image, label, self.config.input_shape)\n",
    "        \n",
    "        # Ensure correct shape\n",
    "        if image.shape != self.config.input_shape:\n",
    "            # Center crop or pad if needed\n",
    "            image = self._resize_volume(image, self.config.input_shape)\n",
    "            label = self._resize_volume(label, self.config.input_shape)\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        image = torch.from_numpy(image).unsqueeze(0)  # Add channel dimension\n",
    "        label = torch.from_numpy(label).long()\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def _resize_volume(self, volume, target_shape):\n",
    "        \"\"\"Resize volume to target shape by cropping or padding\"\"\"\n",
    "        current_shape = volume.shape\n",
    "        \n",
    "        # Calculate padding or cropping for each dimension\n",
    "        pad_or_crop = []\n",
    "        for cur, tar in zip(current_shape, target_shape):\n",
    "            diff = tar - cur\n",
    "            if diff > 0:\n",
    "                # Padding needed\n",
    "                pad_before = diff // 2\n",
    "                pad_after = diff - pad_before\n",
    "                pad_or_crop.append((pad_before, pad_after))\n",
    "            else:\n",
    "                # Cropping needed\n",
    "                crop_before = (-diff) // 2\n",
    "                crop_after = cur - (-diff) - crop_before\n",
    "                pad_or_crop.append((crop_before, crop_after))\n",
    "        \n",
    "        # Apply padding or cropping\n",
    "        if any(p[0] > 0 or p[1] > 0 for p in pad_or_crop):\n",
    "            # Padding\n",
    "            volume = np.pad(volume, pad_or_crop, mode='constant', constant_values=0)\n",
    "        \n",
    "        # Cropping\n",
    "        slices = []\n",
    "        for i, (crop_start, crop_end) in enumerate(pad_or_crop):\n",
    "            if crop_start < 0 or crop_end < 0:\n",
    "                slices.append(slice(abs(min(crop_start, 0)), \n",
    "                                   volume.shape[i] - abs(min(crop_end, 0))))\n",
    "            else:\n",
    "                slices.append(slice(None))\n",
    "        \n",
    "        return volume[tuple(slices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock3D(nn.Module):\n",
    "    \"\"\"Basic 3D convolutional block\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn1 = nn.BatchNorm3d(out_channels)\n",
    "        self.conv2 = nn.Conv3d(out_channels, out_channels, kernel_size, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm3d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "        return x\n",
    "\n",
    "class UNet3D(nn.Module):\n",
    "    \"\"\"3D U-Net for volumetric segmentation\"\"\"\n",
    "    def __init__(self, in_channels=1, num_classes=3, features=[32, 64, 128, 256]):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='trilinear', align_corners=False)\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder1 = ConvBlock3D(in_channels, features[0])\n",
    "        self.encoder2 = ConvBlock3D(features[0], features[1])\n",
    "        self.encoder3 = ConvBlock3D(features[1], features[2])\n",
    "        self.encoder4 = ConvBlock3D(features[2], features[3])\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = ConvBlock3D(features[3], features[3] * 2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder4 = ConvBlock3D(features[3] * 2 + features[3], features[3])\n",
    "        self.decoder3 = ConvBlock3D(features[3] + features[2], features[2])\n",
    "        self.decoder2 = ConvBlock3D(features[2] + features[1], features[1])\n",
    "        self.decoder1 = ConvBlock3D(features[1] + features[0], features[0])\n",
    "        \n",
    "        # Final layer\n",
    "        self.final = nn.Conv3d(features[0], num_classes, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.encoder1(x)\n",
    "        p1 = self.pool(e1)\n",
    "        \n",
    "        e2 = self.encoder2(p1)\n",
    "        p2 = self.pool(e2)\n",
    "        \n",
    "        e3 = self.encoder3(p2)\n",
    "        p3 = self.pool(e3)\n",
    "        \n",
    "        e4 = self.encoder4(p3)\n",
    "        p4 = self.pool(e4)\n",
    "        \n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(p4)\n",
    "        \n",
    "        # Decoder\n",
    "        d4 = self.up(b)\n",
    "        d4 = torch.cat([d4, e4], dim=1)\n",
    "        d4 = self.decoder4(d4)\n",
    "        \n",
    "        d3 = self.up(d4)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.decoder3(d3)\n",
    "        \n",
    "        d2 = self.up(d3)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.decoder2(d2)\n",
    "        \n",
    "        d1 = self.up(d2)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.decoder1(d1)\n",
    "        \n",
    "        return self.final(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    \"\"\"Dice loss for segmentation\"\"\"\n",
    "    def __init__(self, num_classes=3, smooth=1e-5, ignore_index=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.smooth = smooth\n",
    "        self.ignore_index = ignore_index\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        pred = torch.softmax(pred, dim=1)\n",
    "        \n",
    "        # Create one-hot encoding\n",
    "        target_one_hot = F.one_hot(target, self.num_classes)\n",
    "        target_one_hot = target_one_hot.permute(0, 4, 1, 2, 3).float()\n",
    "        \n",
    "        # Calculate dice for each class\n",
    "        dice_scores = []\n",
    "        for i in range(self.num_classes):\n",
    "            if i == self.ignore_index:\n",
    "                continue\n",
    "                \n",
    "            pred_i = pred[:, i]\n",
    "            target_i = target_one_hot[:, i]\n",
    "            \n",
    "            intersection = (pred_i * target_i).sum(dim=(1, 2, 3))\n",
    "            union = pred_i.sum(dim=(1, 2, 3)) + target_i.sum(dim=(1, 2, 3))\n",
    "            \n",
    "            dice = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "            dice_scores.append(dice)\n",
    "        \n",
    "        dice_scores = torch.stack(dice_scores, dim=1)\n",
    "        return 1 - dice_scores.mean()\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined Dice + CrossEntropy loss\"\"\"\n",
    "    def __init__(self, num_classes=3, dice_weight=0.5, ce_weight=0.5, ignore_index=2):\n",
    "        super().__init__()\n",
    "        self.dice_loss = DiceLoss(num_classes, ignore_index=ignore_index)\n",
    "        self.ce_loss = nn.CrossEntropyLoss(ignore_index=ignore_index)\n",
    "        self.dice_weight = dice_weight\n",
    "        self.ce_weight = ce_weight\n",
    "        \n",
    "    def forward(self, pred, target):\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        ce = self.ce_loss(pred, target)\n",
    "        return self.dice_weight * dice + self.ce_weight * ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceMetric:\n",
    "    \"\"\"Calculate Dice score for evaluation\"\"\"\n",
    "    def __init__(self, num_classes=3, ignore_index=2):\n",
    "        self.num_classes = num_classes\n",
    "        self.ignore_index = ignore_index\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.intersection = np.zeros(self.num_classes)\n",
    "        self.union = np.zeros(self.num_classes)\n",
    "        \n",
    "    def update(self, pred, target):\n",
    "        pred = torch.argmax(pred, dim=1).cpu().numpy()\n",
    "        target = target.cpu().numpy()\n",
    "        \n",
    "        for i in range(self.num_classes):\n",
    "            if i == self.ignore_index:\n",
    "                continue\n",
    "                \n",
    "            pred_i = (pred == i).astype(np.float32)\n",
    "            target_i = (target == i).astype(np.float32)\n",
    "            \n",
    "            self.intersection[i] += np.sum(pred_i * target_i)\n",
    "            self.union[i] += np.sum(pred_i) + np.sum(target_i)\n",
    "    \n",
    "    def compute(self):\n",
    "        dice_scores = []\n",
    "        for i in range(self.num_classes):\n",
    "            if i == self.ignore_index:\n",
    "                continue\n",
    "            if self.union[i] == 0:\n",
    "                dice_scores.append(1.0)\n",
    "            else:\n",
    "                dice = (2 * self.intersection[i]) / self.union[i]\n",
    "                dice_scores.append(dice)\n",
    "        return np.mean(dice_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowInference:\n",
    "    \"\"\"Sliding window inference for large volumes\"\"\"\n",
    "    \n",
    "    def __init__(self, roi_size, sw_batch_size=4, overlap=0.5, mode='gaussian'):\n",
    "        self.roi_size = roi_size\n",
    "        self.sw_batch_size = sw_batch_size\n",
    "        self.overlap = overlap\n",
    "        self.mode = mode\n",
    "        \n",
    "    def __call__(self, model, image):\n",
    "        \"\"\"Run sliding window inference\"\"\"\n",
    "        device = next(model.parameters()).device\n",
    "        \n",
    "        # Get image dimensions\n",
    "        batch_size, channels, d, h, w = image.shape\n",
    "        \n",
    "        # Calculate stride\n",
    "        stride = [int(r * (1 - self.overlap)) for r in self.roi_size]\n",
    "        \n",
    "        # Calculate number of windows\n",
    "        num_windows_d = max(1, int(np.ceil((d - self.roi_size[0]) / stride[0] + 1)))\n",
    "        num_windows_h = max(1, int(np.ceil((h - self.roi_size[1]) / stride[1] + 1)))\n",
    "        num_windows_w = max(1, int(np.ceil((w - self.roi_size[2]) / stride[2] + 1)))\n",
    "        \n",
    "        # Initialize output\n",
    "        num_classes = config.num_classes\n",
    "        output = torch.zeros(batch_size, num_classes, d, h, w).to(device)\n",
    "        count_map = torch.zeros(batch_size, 1, d, h, w).to(device)\n",
    "        \n",
    "        # Generate gaussian importance map if needed\n",
    "        if self.mode == 'gaussian':\n",
    "            importance_map = self._get_gaussian_map(self.roi_size).to(device)\n",
    "        else:\n",
    "            importance_map = torch.ones(1, 1, *self.roi_size).to(device)\n",
    "        \n",
    "        # Sliding window\n",
    "        for d_idx in range(num_windows_d):\n",
    "            for h_idx in range(num_windows_h):\n",
    "                for w_idx in range(num_windows_w):\n",
    "                    # Calculate window position\n",
    "                    d_start = min(d_idx * stride[0], d - self.roi_size[0])\n",
    "                    h_start = min(h_idx * stride[1], h - self.roi_size[1])\n",
    "                    w_start = min(w_idx * stride[2], w - self.roi_size[2])\n",
    "                    \n",
    "                    d_end = d_start + self.roi_size[0]\n",
    "                    h_end = h_start + self.roi_size[1]\n",
    "                    w_end = w_start + self.roi_size[2]\n",
    "                    \n",
    "                    # Extract window\n",
    "                    window = image[:, :, d_start:d_end, h_start:h_end, w_start:w_end]\n",
    "                    \n",
    "                    # Run inference\n",
    "                    with torch.no_grad():\n",
    "                        window_output = model(window)\n",
    "                        window_output = torch.softmax(window_output, dim=1)\n",
    "                    \n",
    "                    # Add to output with importance weighting\n",
    "                    output[:, :, d_start:d_end, h_start:h_end, w_start:w_end] += \\\n",
    "                        window_output * importance_map\n",
    "                    count_map[:, :, d_start:d_end, h_start:h_end, w_start:w_end] += \\\n",
    "                        importance_map\n",
    "        \n",
    "        # Normalize by count map\n",
    "        output = output / count_map.clamp(min=1e-5)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _get_gaussian_map(self, size):\n",
    "        \"\"\"Generate gaussian importance map\"\"\"\n",
    "        gaussians = []\n",
    "        for s in size:\n",
    "            gaussian_1d = torch.exp(-4 * torch.linspace(-1, 1, s) ** 2)\n",
    "            gaussians.append(gaussian_1d)\n",
    "        \n",
    "        gaussian_3d = gaussians[0].unsqueeze(-1).unsqueeze(-1) * \\\n",
    "                      gaussians[1].unsqueeze(0).unsqueeze(-1) * \\\n",
    "                      gaussians[2].unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        return gaussian_3d.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device, scaler=None):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(loader, desc='Training')\n",
    "    for batch_idx, (images, labels) in enumerate(progress_bar):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if scaler is not None:\n",
    "            # Mixed precision training\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            # Normal training\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    return total_loss / len(loader)\n",
    "\n",
    "def validate_epoch(model, loader, criterion, metric, device):\n",
    "    \"\"\"Validate for one epoch\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    metric.reset()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(loader, desc='Validation')\n",
    "        for images, labels in progress_bar:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            metric.update(outputs, labels)\n",
    "            \n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    dice_score = metric.compute()\n",
    "    \n",
    "    return avg_loss, dice_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"Main training function\"\"\"\n",
    "    \n",
    "    # Create dummy data files (replace with actual data)\n",
    "    train_files = [f\"train_{i}\" for i in range(10)]  # Replace with actual file paths\n",
    "    val_files = [f\"val_{i}\" for i in range(2)]  # Replace with actual file paths\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = VesuviusDataset(train_files, config, is_train=True)\n",
    "    val_dataset = VesuviusDataset(val_files, config, is_train=False)\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=config.batch_size, \n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Create model\n",
    "    model = UNet3D(in_channels=1, num_classes=config.num_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total parameters: {total_params/1e6:.2f}M\")\n",
    "    \n",
    "    # Create loss and optimizer\n",
    "    criterion = CombinedLoss(num_classes=config.num_classes)\n",
    "    optimizer = optim.AdamW(model.parameters(), \n",
    "                           lr=config.learning_rate, \n",
    "                           weight_decay=config.weight_decay)\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.epochs)\n",
    "    \n",
    "    # Mixed precision scaler\n",
    "    scaler = GradScaler() if config.use_amp else None\n",
    "    \n",
    "    # Metric\n",
    "    metric = DiceMetric(num_classes=config.num_classes)\n",
    "    \n",
    "    # Training history\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'val_loss': [],\n",
    "        'val_dice': []\n",
    "    }\n",
    "    \n",
    "    best_dice = 0\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(config.epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{config.epochs}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Train\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, scaler)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_dice = validate_epoch(model, val_loader, criterion, metric, device)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_dice'].append(val_dice)\n",
    "        \n",
    "        # Print metrics\n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        print(f\"Val Dice: {val_dice:.4f}\")\n",
    "        print(f\"LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "        \n",
    "        # Save best model\n",
    "        if val_dice > best_dice:\n",
    "            best_dice = val_dice\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_dice': best_dice,\n",
    "            }, config.checkpoint_path)\n",
    "            print(f\"Saved best model with Dice: {best_dice:.4f}\")\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "model, history = train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Dice plot\n",
    "axes[1].plot(history['val_dice'], label='Val Dice', color='green')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Dice Score')\n",
    "axes[1].set_title('Validation Dice Score')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_with_sliding_window(model, image_volume):\n",
    "    \"\"\"Run inference with sliding window on a large volume\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Create sliding window inference\n",
    "    swi = SlidingWindowInference(\n",
    "        roi_size=config.input_shape,\n",
    "        sw_batch_size=config.sw_batch_size,\n",
    "        overlap=config.overlap\n",
    "    )\n",
    "    \n",
    "    # Prepare input\n",
    "    if isinstance(image_volume, np.ndarray):\n",
    "        image_volume = torch.from_numpy(image_volume).float()\n",
    "    \n",
    "    # Add batch and channel dimensions if needed\n",
    "    if image_volume.ndim == 3:\n",
    "        image_volume = image_volume.unsqueeze(0).unsqueeze(0)\n",
    "    elif image_volume.ndim == 4:\n",
    "        image_volume = image_volume.unsqueeze(0)\n",
    "    \n",
    "    image_volume = image_volume.to(device)\n",
    "    \n",
    "    # Run inference\n",
    "    with torch.no_grad():\n",
    "        output = swi(model, image_volume)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = torch.argmax(output, dim=1)\n",
    "    \n",
    "    return predictions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inference on a test volume\n",
    "test_volume = np.random.randn(128, 128, 128)  # Replace with actual test data\n",
    "predictions = inference_with_sliding_window(model, test_volume)\n",
    "print(f\"Predictions shape: {predictions.shape}\")\n",
    "print(f\"Unique classes: {np.unique(predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_slice(volume, prediction, slice_idx=None):\n",
    "    \"\"\"Visualize a slice from the volume and prediction\"\"\"\n",
    "    if slice_idx is None:\n",
    "        slice_idx = volume.shape[0] // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    axes[0].imshow(volume[slice_idx], cmap='gray')\n",
    "    axes[0].set_title(f'Input (Slice {slice_idx})')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(prediction[0, slice_idx], cmap='jet', vmin=0, vmax=2)\n",
    "    axes[1].set_title(f'Prediction (Slice {slice_idx})')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize result\n",
    "visualize_slice(test_volume, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model\n",
    "torch.save(model.state_dict(), 'final_model_pytorch.pth')\n",
    "print(\"Model saved to final_model_pytorch.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}