"""
çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ - å®Ÿãƒ‡ãƒ¼ã‚¿ã¨ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã®ä¸¡æ–¹ã«å¯¾å¿œ
"""

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import numpy as np
from pathlib import Path
from typing import Optional, Tuple, List, Dict
import os

class VesuviusDataset(Dataset):
    """Vesuvius Challengeç”¨ã®çµ±åˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    
    def __init__(self, 
                 split='train',
                 volume_size=(96, 96, 64),
                 num_samples=30,
                 data_path: Optional[str] = None):
        """
        Args:
            split: 'train' or 'val'
            volume_size: (H, W, D) ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚µã‚¤ã‚º
            num_samples: ç”Ÿæˆã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
            data_path: å®Ÿãƒ‡ãƒ¼ã‚¿ã®ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        """
        self.split = split
        self.volume_size = volume_size
        self.num_samples = num_samples
        self.data_path = data_path
        
        # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        self.volumes, self.labels = self._create_data()
        
    def _create_data(self) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆå®Ÿãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ï¼‰"""
        
        # å®Ÿãƒ‡ãƒ¼ã‚¿ç¢ºèª
        if self._check_real_data():
            print(f"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨: {self.data_path}")
            return self._load_real_data()
        else:
            print(f"ğŸ­ ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­ ({self.split})")
            return self._generate_demo_data()
    
    def _check_real_data(self) -> bool:
        """å®Ÿãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ç¢ºèªï¼ˆRunpodsç’°å¢ƒå¯¾å¿œï¼‰"""
        if not self.data_path:
            # MCPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è©¦è¡Œ
            try:
                print("ğŸ“¥ Kaggleãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è©¦è¡Œä¸­...")
                # ã“ã®é–¢æ•°ãŒæ—¢ã«å‘¼ã°ã‚Œã¦ã„ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                if not hasattr(self, '_download_attempted'):
                    self._download_attempted = True
                    import subprocess
                    result = subprocess.run(
                        ["python", "-c", 
                         "from mcp__kaggle__prepare_kaggle_dataset import prepare_kaggle_dataset; "
                         "prepare_kaggle_dataset('vesuvius-challenge-surface-detection')"],
                        capture_output=True, text=True, timeout=10
                    )
            except:
                pass
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹ã‚’ç¢ºèª
            default_paths = [
                "/workspace/vesuvius-challenge-surface-detection",
                "/content/vesuvius-challenge-surface-detection",
                "./data/vesuvius-challenge-surface-detection",
                "./vesuvius-challenge-surface-detection",
                "../input/vesuvius-challenge-surface-detection"
            ]
            
            for default_path in default_paths:
                path = Path(default_path)
                if path.exists():
                    train_images = path / "train_images"
                    if train_images.exists():
                        tiff_files = list(train_images.glob("*.tif*"))
                        if len(tiff_files) > 0:
                            self.data_path = default_path
                            print(f"âœ… å®Ÿãƒ‡ãƒ¼ã‚¿è‡ªå‹•æ¤œå‡º: {default_path}")
                            return True
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
            print("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’æ‰‹å‹•ã§å®Ÿè¡Œã—ã¦ãã ã•ã„:")
            print("   kaggle competitions download -c vesuvius-challenge-surface-detection -p ./data")
            return False
        
        path = Path(self.data_path)
        if path.exists():
            # train_imagesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ãƒã‚§ãƒƒã‚¯
            train_images = path / "train_images"
            if train_images.exists():
                tiff_files = list(train_images.glob("*.tif*"))
                return len(tiff_files) > 0
        return False
    
    def _load_real_data(self) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """å®Ÿãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰"""
        try:
            from PIL import Image
            import cv2
        except ImportError:
            print("âš ï¸ PIL/cv2ãŒåˆ©ç”¨ä¸å¯ - ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            return self._generate_demo_data()
        
        volumes = []
        labels = []
        
        data_path = Path(self.data_path)
        train_images_dir = data_path / "train_images"
        train_labels_dir = data_path / "train_labels"
        
        # TIFFãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—
        tiff_files = sorted(list(train_images_dir.glob("*.tif")))
        
        if len(tiff_files) == 0:
            print("âš ï¸ TIFFãƒ•ã‚¡ã‚¤ãƒ«ãªã— - ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨")
            return self._generate_demo_data()
        
        print(f"ğŸ“Š {len(tiff_files)}å€‹ã®TIFFãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹")
        
        H, W, D = self.volume_size
        num_volumes = min(self.num_samples, max(1, len(tiff_files) // D))
        
        for vol_idx in range(num_volumes):
            # ã‚¹ãƒ©ã‚¤ã‚¹é¸æŠ
            start_idx = (vol_idx * D) % max(1, len(tiff_files) - D)
            selected_files = tiff_files[start_idx:start_idx + D]
            
            if len(selected_files) < D:
                # ä¸è¶³åˆ†ã¯å¾ªç’°
                selected_files = selected_files + tiff_files[:D-len(selected_files)]
            
            volume_slices = []
            label_slices = []
            
            for tiff_file in selected_files:
                try:
                    # ç”»åƒèª­ã¿è¾¼ã¿
                    img = np.array(Image.open(tiff_file), dtype=np.float32)
                    
                    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
                    if len(img.shape) == 3:
                        img = img.mean(axis=2)
                    
                    # ãƒªã‚µã‚¤ã‚º
                    img = cv2.resize(img, (W, H))
                    
                    # æ­£è¦åŒ–
                    img = (img - img.mean()) / (img.std() + 1e-8)
                    
                    # ãƒ©ãƒ™ãƒ«å‡¦ç†
                    if train_labels_dir.exists():
                        label_file = train_labels_dir / tiff_file.name
                        if label_file.exists():
                            label = np.array(Image.open(label_file), dtype=np.uint8)
                            if len(label.shape) == 3:
                                label = label.mean(axis=2)
                            label = cv2.resize(label, (W, H), interpolation=cv2.INTER_NEAREST)
                            label = (label > 127).astype(np.int64)
                        else:
                            # ç°¡æ˜“ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
                            label = (img > np.percentile(img, 75)).astype(np.int64)
                    else:
                        # ç°¡æ˜“ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
                        label = (img > np.percentile(img, 75)).astype(np.int64)
                    
                    volume_slices.append(img)
                    label_slices.append(label)
                    
                except Exception as e:
                    print(f"âš ï¸ {tiff_file.name}èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                    # ãƒ€ãƒŸãƒ¼ã‚¹ãƒ©ã‚¤ã‚¹
                    volume_slices.append(np.random.randn(H, W).astype(np.float32))
                    label_slices.append(np.zeros((H, W), dtype=np.int64))
            
            # 3Dãƒœãƒªãƒ¥ãƒ¼ãƒ æ§‹ç¯‰
            volume = np.stack(volume_slices, axis=2)
            label = np.stack(label_slices, axis=2)
            
            volumes.append(volume)
            labels.append(label)
            
            print(f"  âœ… ãƒœãƒªãƒ¥ãƒ¼ãƒ {vol_idx+1}: {volume.shape}, å‰æ™¯{(label==1).mean():.2%}")
        
        print(f"âœ… {len(volumes)}å€‹ã®å®Ÿãƒ‡ãƒ¼ã‚¿ãƒœãƒªãƒ¥ãƒ¼ãƒ ä½œæˆå®Œäº†")
        return volumes, labels
    
    def _generate_demo_data(self) -> Tuple[List[np.ndarray], List[np.ndarray]]:
        """é«˜å“è³ªãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        volumes = []
        labels = []
        
        H, W, D = self.volume_size
        
        for i in range(self.num_samples):
            # ãƒªã‚¢ãƒ«ãªãƒœãƒªãƒ¥ãƒ¼ãƒ ç”Ÿæˆ
            volume = np.random.randn(H, W, D).astype(np.float32)
            
            # è¤‡é›‘ãªãƒ†ã‚¯ã‚¹ãƒãƒ£è¿½åŠ 
            for z in range(D):
                # ãƒã‚¤ã‚ºã¨ãƒ‘ã‚¿ãƒ¼ãƒ³
                x, y = np.meshgrid(np.linspace(0, 3*np.pi, H), 
                                  np.linspace(0, 3*np.pi, W))
                pattern = np.sin(x + i) * np.cos(y + z/10)
                volume[:, :, z] += pattern * 0.5
                
                # ãƒ©ãƒ³ãƒ€ãƒ ãƒã‚¤ã‚º
                volume[:, :, z] += np.random.randn(H, W) * 0.2
            
            # æ­£è¦åŒ– (-1, 1)
            volume = (volume - volume.mean()) / (volume.std() + 1e-8)
            volume = np.clip(volume, -3, 3)
            
            # ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ©ãƒ™ãƒ«ç”Ÿæˆ
            label = np.zeros((H, W, D), dtype=np.int64)
            
            # è¤‡æ•°ã®å‰æ™¯é ˜åŸŸã‚’ä½œæˆ
            num_regions = np.random.randint(3, 8)
            for _ in range(num_regions):
                # ãƒ©ãƒ³ãƒ€ãƒ ãªä¸­å¿ƒç‚¹
                cx = np.random.randint(H//4, 3*H//4)
                cy = np.random.randint(W//4, 3*W//4)
                cz = np.random.randint(D//4, 3*D//4)
                
                # ãƒ©ãƒ³ãƒ€ãƒ ãªã‚µã‚¤ã‚º
                size = np.random.randint(5, 15)
                
                # 3Dæ¥•å††ä½“ã‚’ä½œæˆ
                for x in range(max(0, cx-size), min(H, cx+size)):
                    for y in range(max(0, cy-size), min(W, cy+size)):
                        for z in range(max(0, cz-size//2), min(D, cz+size//2)):
                            dist = ((x-cx)**2 + (y-cy)**2 + (z-cz)**2*4) / size**2
                            if dist < 1:
                                label[x, y, z] = 1
            
            volumes.append(volume)
            labels.append(label)
        
        return volumes, labels
    
    def __len__(self):
        return len(self.volumes)
    
    def __getitem__(self, idx):
        volume = torch.FloatTensor(self.volumes[idx])
        label = torch.LongTensor(self.labels[idx])
        
        # (H, W, D) -> (C=1, H, W, D)
        volume = volume.unsqueeze(0)
        
        return {
            'data': volume,
            'target': label
        }


def create_data_loaders(volume_size=(96, 96, 64),
                       batch_size=4,
                       train_samples=24,
                       val_samples=6,
                       data_path: Optional[str] = None,
                       num_workers=0):
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆï¼ˆRunpodsç’°å¢ƒå¯¾å¿œï¼‰
    
    Args:
        volume_size: ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚µã‚¤ã‚º (H, W, D)
        batch_size: ãƒãƒƒãƒã‚µã‚¤ã‚º
        train_samples: è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°
        val_samples: æ¤œè¨¼ã‚µãƒ³ãƒ—ãƒ«æ•°
        data_path: å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¹ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ - è‡ªå‹•æ¤œå‡ºï¼‰
        num_workers: ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°
        
    Returns:
        train_loader, val_loader
    """
    
    print("ğŸš€ ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆé–‹å§‹ï¼ˆRunpodsç’°å¢ƒï¼‰...")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    train_dataset = VesuviusDataset(
        split='train',
        volume_size=volume_size,
        num_samples=train_samples,
        data_path=data_path
    )
    
    val_dataset = VesuviusDataset(
        split='val',
        volume_size=volume_size,
        num_samples=val_samples,
        data_path=data_path
    )
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=torch.cuda.is_available()
    )
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚µã‚¤ã‚º:")
    print(f"   è¨“ç·´: {len(train_dataset)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"   æ¤œè¨¼: {len(val_dataset)}ã‚µãƒ³ãƒ—ãƒ«")
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆå®Œäº†!")
    print(f"   è¨“ç·´ãƒãƒƒãƒæ•°: {len(train_loader)}")
    print(f"   æ¤œè¨¼ãƒãƒƒãƒæ•°: {len(val_loader)}")
    
    # ãƒ†ã‚¹ãƒˆ
    sample_batch = next(iter(train_loader))
    print(f"\nğŸ§ª ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ:")
    print(f"   ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {sample_batch['data'].shape}")
    print(f"   ãƒ©ãƒ™ãƒ«å½¢çŠ¶: {sample_batch['target'].shape}")
    print(f"   ãƒ‡ãƒ¼ã‚¿ç¯„å›²: [{sample_batch['data'].min():.3f}, {sample_batch['data'].max():.3f}]")
    
    fg_ratio = (sample_batch['target'] == 1).float().mean()
    print(f"   å‰æ™¯æ¯”ç‡: {fg_ratio:.3f}")
    
    return train_loader, val_loader


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("ğŸ§ª çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ†ã‚¹ãƒˆ")
    
    train_loader, val_loader = create_data_loaders(
        volume_size=(64, 64, 32),
        batch_size=2,
        train_samples=10,
        val_samples=2
    )
    
    print("\nâœ… ãƒ†ã‚¹ãƒˆå®Œäº†!")