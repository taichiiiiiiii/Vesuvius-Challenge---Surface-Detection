{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vesuvius Challenge - 元のコードと同じ（環境対応のみ変更）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"  # jax → torch のみ変更\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras.optimizers import SGD, AdamW, Muon\n",
    "from keras.optimizers.schedules import CosineDecay, PolynomialDecay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import medicai\n",
    "from medicai.transforms import (\n",
    "    Compose,\n",
    "    NormalizeIntensity,\n",
    "    ScaleIntensityRange,\n",
    "    Resize,\n",
    "    RandShiftIntensity,\n",
    "    RandRotate90,\n",
    "    RandRotate,\n",
    "    RandFlip,\n",
    "    RandCutOut,\n",
    "    RandSpatialCrop\n",
    ")\n",
    "from medicai.layers import ResizingND\n",
    "from medicai.models import (\n",
    "    UNet, SegFormer, TransUNet, SwinUNETR, UPerNet, ConvNeXtV2Tiny, UNETRPlusPlus\n",
    ")\n",
    "from medicai.losses import (\n",
    "    SparseDiceCELoss, SparseTverskyLoss, SparseCenterlineDiceLoss\n",
    ")\n",
    "from medicai.metrics import SparseDiceMetric\n",
    "from medicai.callbacks import SlidingWindowInferenceCallback\n",
    "from medicai.utils import SlidingWindowInference\n",
    "from medicai.utils import soft_skeletonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.utils.set_random_seed(101)\n",
    "\n",
    "# TPU設定を削除、単一デバイス用に\n",
    "total_device = 1\n",
    "print(f'total device: {total_device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.version(), keras.config.backend(), medicai.version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(128, 128, 128)\n",
    "batch_size=1 * total_device\n",
    "num_classes=3\n",
    "num_samples = 780\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_shape\": tf.io.FixedLenFeature([3], tf.int64),\n",
    "        \"label_shape\": tf.io.FixedLenFeature([3], tf.int64),\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example, feature_description)\n",
    "    image = tf.io.decode_raw(parsed_example[\"image\"], tf.uint8)\n",
    "    label = tf.io.decode_raw(parsed_example[\"label\"], tf.uint8)\n",
    "    image_shape = tf.cast(parsed_example[\"image_shape\"], tf.int64)\n",
    "    label_shape = tf.cast(parsed_example[\"label_shape\"], tf.int64)\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    label = tf.reshape(label, label_shape)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(image, label):\n",
    "    image = image[..., None]\n",
    "    label = label[..., None]\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformation(image, label):\n",
    "    data = {\"image\": image, \"label\": label}\n",
    "    pipeline = Compose([\n",
    "        ## Geometric transformation\n",
    "        RandSpatialCrop(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=input_shape,\n",
    "            random_center=True,\n",
    "            random_size=False,\n",
    "            invalid_label=2,         \n",
    "            min_valid_ratio=0.5,     \n",
    "            max_attempts=10\n",
    "        ),\n",
    "        RandFlip(keys=[\"image\", \"label\"], spatial_axis=[0], prob=0.5),\n",
    "        RandFlip(keys=[\"image\", \"label\"], spatial_axis=[1], prob=0.5),\n",
    "        RandFlip(keys=[\"image\", \"label\"], spatial_axis=[2], prob=0.5),\n",
    "        RandRotate90(\n",
    "            keys=[\"image\", \"label\"], \n",
    "            prob=0.4, \n",
    "            max_k=3, \n",
    "            spatial_axes=(0, 1)\n",
    "        ),\n",
    "        RandRotate(\n",
    "            keys=[\"image\", \"label\"], \n",
    "            factor=0.2, \n",
    "            prob=0.7, \n",
    "            fill_mode=\"crop\",\n",
    "        ),\n",
    "\n",
    "        ## Intensiry transformation\n",
    "        NormalizeIntensity(\n",
    "            keys=[\"image\"], \n",
    "            nonzero=True,\n",
    "            channel_wise=False\n",
    "        ),\n",
    "        RandShiftIntensity(\n",
    "            keys=[\"image\"], offsets=0.10, prob=0.5\n",
    "        ),\n",
    "        ## Spatial transformation \n",
    "        RandCutOut(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            invalid_label=2, \n",
    "            mask_size=[\n",
    "                input_shape[1]//4,\n",
    "                input_shape[2]//4\n",
    "            ],\n",
    "            fill_mode=\"constant\",\n",
    "            cutout_mode='volume',\n",
    "            prob=0.8,\n",
    "            num_cuts=5,\n",
    "        ),\n",
    "    ])\n",
    "    result = pipeline(data)\n",
    "    return result[\"image\"], result[\"label\"]\n",
    "\n",
    "\n",
    "def val_transformation(image, label):\n",
    "    data = {\"image\": image, \"label\": label}\n",
    "    pipeline = Compose([\n",
    "        NormalizeIntensity(\n",
    "            keys=[\"image\"], \n",
    "            nonzero=True,\n",
    "            channel_wise=False\n",
    "        ),\n",
    "    ])\n",
    "    result = pipeline(data)\n",
    "    return result[\"image\"], result[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfrecord_loader(tfrecord_pattern, batch_size=1, shuffle=True):\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        tf.io.gfile.glob(tfrecord_pattern)\n",
    "    )\n",
    "    dataset = dataset.shuffle(buffer_size=100) if shuffle else dataset \n",
    "    dataset = dataset.map(\n",
    "        parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prepare_inputs,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    if shuffle:\n",
    "        dataset = dataset.map(\n",
    "            train_transformation,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "    else:\n",
    "        dataset = dataset.map(\n",
    "            val_transformation,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=shuffle)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tfrec = sorted(\n",
    "    glob.glob(\"/kaggle/input/vesuvius-tfrecords/*.tfrec\"),\n",
    "    key=lambda x: int(x.split(\"_\")[-1].replace(\".tfrec\", \"\"))\n",
    ")\n",
    "\n",
    "val_idx = -1\n",
    "val_patterns = [all_tfrec[val_idx]]\n",
    "train_patterns = [\n",
    "    f for i, f in enumerate(all_tfrec) if i != len(all_tfrec) + val_idx\n",
    "]\n",
    "\n",
    "train_ds = tfrecord_loader(\n",
    "    train_patterns, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_ds = tfrecord_loader(\n",
    "    val_patterns, batch_size=1, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(val_ds))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegFormer(\n",
    "    input_shape=input_shape + (1,),\n",
    "    encoder_name='mit_b0',\n",
    "    classifier_activation='softmax',\n",
    "    num_classes=num_classes,\n",
    ")\n",
    "\n",
    "model.count_params() / 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Schedules and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = num_samples // batch_size\n",
    "total_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(total_steps * 0.05)\n",
    "decay_steps = max(1, total_steps - warmup_steps)\n",
    "lr_schedule = CosineDecay(\n",
    "    initial_learning_rate=1e-6,\n",
    "    decay_steps=decay_steps,\n",
    "    warmup_target=min(3e-4, 1e-4 * (batch_size / 2)),\n",
    "    warmup_steps=warmup_steps,\n",
    "    alpha=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = keras.optimizers.AdamW(\n",
    "    learning_rate=lr_schedule,\n",
    "    weight_decay=1e-5,\n",
    ")\n",
    "\n",
    "dice_ce_loss_fn = SparseDiceCELoss(\n",
    "    from_logits=False, \n",
    "    num_classes=num_classes,\n",
    "    ignore_class_ids=2,\n",
    ")\n",
    "cldice_loss_fn = SparseCenterlineDiceLoss(\n",
    "    from_logits=False, \n",
    "    num_classes=num_classes,\n",
    "    target_class_ids=1,\n",
    "    ignore_class_ids=2,\n",
    "    iters=50\n",
    ")\n",
    "combined_loss_fn = lambda y_true, y_pred: (\n",
    "    dice_ce_loss_fn(y_true, y_pred) + cldice_loss_fn(y_true, y_pred)\n",
    ")\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    SparseDiceMetric(\n",
    "        from_logits=False, \n",
    "        num_classes=num_classes, \n",
    "        ignore_class_ids=2,\n",
    "        name='dice'\n",
    "    ),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optim,\n",
    "    loss=combined_loss_fn,\n",
    "    metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swi_callback_metric = SparseDiceMetric(\n",
    "    from_logits=False,\n",
    "    ignore_class_ids=2,\n",
    "    num_classes=num_classes,\n",
    "    name='val_dice',\n",
    ")\n",
    "\n",
    "swi_callback = SlidingWindowInferenceCallback(\n",
    "    model,\n",
    "    dataset=val_ds,\n",
    "    metrics=swi_callback_metric,\n",
    "    num_classes=num_classes,\n",
    "    interval=5,\n",
    "    overlap=0.5,\n",
    "    mode='gaussian',\n",
    "    roi_size=input_shape,\n",
    "    sw_batch_size=1 * total_device,\n",
    "    save_path=\"model.weights.h5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=[\n",
    "        swi_callback\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\n",
    "    \"model.weights.h5\"\n",
    ")\n",
    "swi = SlidingWindowInference(\n",
    "    model,\n",
    "    num_classes=num_classes,\n",
    "    roi_size=input_shape,\n",
    "    mode='gaussian',\n",
    "    sw_batch_size=1 * total_device,\n",
    "    overlap=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice = SparseDiceMetric(\n",
    "    from_logits=False,\n",
    "    num_classes=num_classes,\n",
    "    ignore_class_ids=2,\n",
    "    name='dice',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in val_ds:\n",
    "    x, y = sample\n",
    "    output = swi(x)\n",
    "    y = ops.convert_to_tensor(y)\n",
    "    output = ops.convert_to_tensor(output)\n",
    "    dice.update_state(y, output)\n",
    "\n",
    "dice_score = float(ops.convert_to_numpy(dice.result()))\n",
    "print(f\"Dice Score: {dice_score:.4f}\")\n",
    "dice.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(val_ds))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = swi(x)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = y_pred.argmax(-1).astype(np.uint8)\n",
    "segment.shape, np.unique(segment)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}