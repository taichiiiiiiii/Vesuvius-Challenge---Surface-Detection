{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vesuvius Challenge - GPU/CPU Training with SWI\n",
    "元のコードから最小限の変更 + SlidingWindowInference保持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バックエンドをPyTorchに変更（GPU/CPU対応）\n",
    "import os\n",
    "import warnings\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"  # jax → torch\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import ops\n",
    "from keras.optimizers import AdamW\n",
    "from keras.optimizers.schedules import CosineDecay\n",
    "\n",
    "# tf.dataのみTensorFlow使用\n",
    "import tensorflow as tf\n",
    "\n",
    "import medicai\n",
    "from medicai.transforms import (\n",
    "    Compose,\n",
    "    NormalizeIntensity,\n",
    "    ScaleIntensityRange,\n",
    "    Resize,\n",
    "    RandShiftIntensity,\n",
    "    RandRotate90,\n",
    "    RandRotate,\n",
    "    RandFlip,\n",
    "    RandCutOut,\n",
    "    RandSpatialCrop\n",
    ")\n",
    "from medicai.models import SegFormer, TransUNet, UNETRPlusPlus\n",
    "from medicai.losses import SparseDiceCELoss, SparseCenterlineDiceLoss\n",
    "from medicai.metrics import SparseDiceMetric\n",
    "from medicai.callbacks import SlidingWindowInferenceCallback\n",
    "from medicai.utils import SlidingWindowInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定\n",
    "input_shape = (64, 64, 64)  # GPU/CPUメモリに合わせて調整可能\n",
    "batch_size = 2  # GPU/CPUに合わせて調整\n",
    "num_classes = 3\n",
    "num_samples = 780\n",
    "epochs = 100  # 元は200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_fn(example):\n",
    "    feature_description = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_shape\": tf.io.FixedLenFeature([3], tf.int64),\n",
    "        \"label_shape\": tf.io.FixedLenFeature([3], tf.int64),\n",
    "    }\n",
    "    parsed_example = tf.io.parse_single_example(example, feature_description)\n",
    "    image = tf.io.decode_raw(parsed_example[\"image\"], tf.uint8)\n",
    "    label = tf.io.decode_raw(parsed_example[\"label\"], tf.uint8)\n",
    "    image_shape = tf.cast(parsed_example[\"image_shape\"], tf.int64)\n",
    "    label_shape = tf.cast(parsed_example[\"label_shape\"], tf.int64)\n",
    "    image = tf.reshape(image, image_shape)\n",
    "    label = tf.reshape(label, label_shape)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(image, label):\n",
    "    # Add channel dimension\n",
    "    image = image[..., None] # (D, H, W, 1)\n",
    "    label = label[..., None] # (D, H, W, 1)\n",
    "    \n",
    "    # Convert to float32\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transformation(image, label):\n",
    "    data = {\"image\": image, \"label\": label}\n",
    "    pipeline = Compose([\n",
    "        ## Geometric transformation\n",
    "        RandSpatialCrop(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=input_shape,\n",
    "            random_center=True,\n",
    "            random_size=False,\n",
    "            invalid_label=2,         \n",
    "            min_valid_ratio=0.5,     \n",
    "            max_attempts=10\n",
    "        ),\n",
    "        RandFlip(keys=[\"image\", \"label\"], spatial_axis=[0], prob=0.5),\n",
    "        RandFlip(keys=[\"image\", \"label\"], spatial_axis=[1], prob=0.5),\n",
    "        RandFlip(keys=[\"image\", \"label\"], spatial_axis=[2], prob=0.5),\n",
    "        RandRotate90(\n",
    "            keys=[\"image\", \"label\"], \n",
    "            prob=0.4, \n",
    "            max_k=3, \n",
    "            spatial_axes=(0, 1)\n",
    "        ),\n",
    "        RandRotate(\n",
    "            keys=[\"image\", \"label\"], \n",
    "            factor=0.2, \n",
    "            prob=0.7, \n",
    "            fill_mode=\"crop\",\n",
    "        ),\n",
    "        \n",
    "        ## Intensity transformation\n",
    "        NormalizeIntensity(\n",
    "            keys=[\"image\"], \n",
    "            nonzero=True,\n",
    "            channel_wise=False\n",
    "        ),\n",
    "        RandShiftIntensity(\n",
    "            keys=[\"image\"], offsets=0.10, prob=0.5\n",
    "        ),\n",
    "        \n",
    "        ## Spatial transformation \n",
    "        RandCutOut(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            invalid_label=2, \n",
    "            mask_size=[\n",
    "                input_shape[1]//4,\n",
    "                input_shape[2]//4\n",
    "            ],\n",
    "            fill_mode=\"constant\",\n",
    "            cutout_mode='volume',\n",
    "            prob=0.8,\n",
    "            num_cuts=5,\n",
    "        ),\n",
    "    ])\n",
    "    result = pipeline(data)\n",
    "    return result[\"image\"], result[\"label\"]\n",
    "\n",
    "def val_transformation(image, label):\n",
    "    data = {\"image\": image, \"label\": label}\n",
    "    pipeline = Compose([\n",
    "        NormalizeIntensity(\n",
    "            keys=[\"image\"], \n",
    "            nonzero=True,\n",
    "            channel_wise=False\n",
    "        ),\n",
    "    ])\n",
    "    result = pipeline(data)\n",
    "    return result[\"image\"], result[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfrecord_loader(tfrecord_pattern, batch_size=1, shuffle=True):\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        tf.io.gfile.glob(tfrecord_pattern)\n",
    "    )\n",
    "    dataset = dataset.shuffle(buffer_size=100) if shuffle else dataset \n",
    "    dataset = dataset.map(\n",
    "        parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    dataset = dataset.map(\n",
    "        prepare_inputs,\n",
    "        num_parallel_calls=tf.data.AUTOTUNE\n",
    "    )\n",
    "    if shuffle:\n",
    "        dataset = dataset.map(\n",
    "            train_transformation,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "    else:\n",
    "        dataset = dataset.map(\n",
    "            val_transformation,\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        )\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=shuffle)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "all_tfrec = sorted(\n",
    "    glob.glob(\"/kaggle/input/vesuvius-tfrecords/*.tfrec\"),\n",
    "    key=lambda x: int(x.split(\"_\")[-1].replace(\".tfrec\", \"\"))\n",
    ")\n",
    "\n",
    "val_idx = -1\n",
    "val_patterns = [all_tfrec[val_idx]]\n",
    "train_patterns = [\n",
    "    f for i, f in enumerate(all_tfrec) if i != len(all_tfrec) + val_idx\n",
    "]\n",
    "\n",
    "train_ds = tfrecord_loader(\n",
    "    train_patterns, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_ds = tfrecord_loader(\n",
    "    val_patterns, batch_size=1, shuffle=False\n",
    ")\n",
    "\n",
    "print(f\"Train files: {len(train_patterns)}\")\n",
    "print(f\"Val files: {len(val_patterns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ確認\n",
    "x, y = next(iter(val_ds))\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Label shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(x, y, sample_idx=0, max_slices=4):\n",
    "    img = np.squeeze(x[sample_idx])  # (D, H, W)\n",
    "    mask = np.squeeze(y[sample_idx])  # (D, H, W)\n",
    "    D = img.shape[0]\n",
    "    \n",
    "    step = max(1, D // max_slices)\n",
    "    slices = range(0, D, step)[:max_slices]\n",
    "    \n",
    "    n_slices = len(slices)\n",
    "    fig, axes = plt.subplots(2, n_slices, figsize=(3*n_slices, 6))\n",
    "    \n",
    "    for i, s in enumerate(slices):\n",
    "        axes[0, i].imshow(img[s], cmap='gray')\n",
    "        axes[0, i].set_title(f\"Slice {s}\")\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        axes[1, i].imshow(mask[s], cmap='gray')\n",
    "        axes[1, i].set_title(f\"Mask {s}\")\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle(f\"Sample {sample_idx}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sample(x, y, sample_idx=0, max_slices=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義（3つから選択可能）\n",
    "MODEL_TYPE = \"segformer\"  # \"segformer\", \"transunet\", \"unetr++\"\n",
    "\n",
    "if MODEL_TYPE == \"segformer\":\n",
    "    model = SegFormer(\n",
    "        input_shape=input_shape + (1,),\n",
    "        encoder_name='mit_b0',\n",
    "        classifier_activation='softmax',\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "elif MODEL_TYPE == \"transunet\":\n",
    "    model = TransUNet(\n",
    "        encoder_name='seresnext50',\n",
    "        input_shape=input_shape + (1,),\n",
    "        num_classes=num_classes,\n",
    "        classifier_activation='softmax'\n",
    "    )\n",
    "elif MODEL_TYPE == \"unetr++\":\n",
    "    model = UNETRPlusPlus(\n",
    "        input_shape=input_shape + (1,),\n",
    "        encoder_name='unetr_plusplus_encoder',\n",
    "        classifier_activation='softmax',\n",
    "        num_classes=num_classes,\n",
    "    )\n",
    "\n",
    "print(f\"Model: {MODEL_TYPE}\")\n",
    "print(f\"Parameters: {model.count_params() / 1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRスケジュール\n",
    "steps_per_epoch = num_samples // batch_size\n",
    "total_steps = steps_per_epoch * epochs\n",
    "warmup_steps = int(total_steps * 0.05)\n",
    "decay_steps = max(1, total_steps - warmup_steps)\n",
    "\n",
    "lr_schedule = CosineDecay(\n",
    "    initial_learning_rate=1e-6,\n",
    "    decay_steps=decay_steps,\n",
    "    warmup_target=min(3e-4, 1e-4 * (batch_size / 2)),\n",
    "    warmup_steps=warmup_steps,\n",
    "    alpha=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オプティマイザ、損失関数、メトリクス\n",
    "optim = keras.optimizers.AdamW(\n",
    "    learning_rate=lr_schedule,\n",
    "    weight_decay=1e-5,\n",
    ")\n",
    "\n",
    "dice_ce_loss_fn = SparseDiceCELoss(\n",
    "    from_logits=False, \n",
    "    num_classes=num_classes,\n",
    "    ignore_class_ids=2,\n",
    ")\n",
    "\n",
    "cldice_loss_fn = SparseCenterlineDiceLoss(\n",
    "    from_logits=False, \n",
    "    num_classes=num_classes,\n",
    "    target_class_ids=1,\n",
    "    ignore_class_ids=2,\n",
    "    iters=20  # GPU/CPU用に削減（元は50）\n",
    ")\n",
    "\n",
    "combined_loss_fn = lambda y_true, y_pred: (\n",
    "    dice_ce_loss_fn(y_true, y_pred) + cldice_loss_fn(y_true, y_pred)\n",
    ")\n",
    "\n",
    "metrics = [\n",
    "    SparseDiceMetric(\n",
    "        from_logits=False, \n",
    "        num_classes=num_classes, \n",
    "        ignore_class_ids=2,\n",
    "        name='dice'\n",
    "    ),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optim,\n",
    "    loss=combined_loss_fn,\n",
    "    metrics=metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SlidingWindowInferenceCallback（重要！）\n",
    "swi_callback_metric = SparseDiceMetric(\n",
    "    from_logits=False,\n",
    "    ignore_class_ids=2,\n",
    "    num_classes=num_classes,\n",
    "    name='val_dice',\n",
    ")\n",
    "\n",
    "swi_callback = SlidingWindowInferenceCallback(\n",
    "    model,\n",
    "    dataset=val_ds,\n",
    "    metrics=swi_callback_metric,\n",
    "    num_classes=num_classes,\n",
    "    interval=5,  # 5エポックごとに評価\n",
    "    overlap=0.5,\n",
    "    mode='gaussian',\n",
    "    roi_size=input_shape,\n",
    "    sw_batch_size=batch_size,  # GPU/CPU用\n",
    "    save_path=\"model.weights.h5\"\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    swi_callback,\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_dice',\n",
    "        patience=15,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習実行\n",
    "print(\"Starting training...\")\n",
    "print(f\"Epochs: {epochs}\")\n",
    "print(f\"Batch size: {batch_size}\")\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベストモデルをロード\n",
    "model.load_weights(\"model.weights.h5\")\n",
    "\n",
    "# SlidingWindowInferenceで評価\n",
    "swi = SlidingWindowInference(\n",
    "    model,\n",
    "    num_classes=num_classes,\n",
    "    roi_size=input_shape,\n",
    "    mode='gaussian',\n",
    "    sw_batch_size=batch_size,\n",
    "    overlap=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diceスコア計算\n",
    "dice = SparseDiceMetric(\n",
    "    from_logits=False,\n",
    "    num_classes=num_classes,\n",
    "    ignore_class_ids=2,\n",
    "    name='dice',\n",
    ")\n",
    "\n",
    "for sample in val_ds:\n",
    "    x, y = sample\n",
    "    output = swi(x)  # SlidingWindowで推論\n",
    "    y = ops.convert_to_tensor(y)\n",
    "    output = ops.convert_to_tensor(output)\n",
    "    dice.update_state(y, output)\n",
    "\n",
    "dice_score = float(ops.convert_to_numpy(dice.result()))\n",
    "print(f\"Final Dice Score: {dice_score:.4f}\")\n",
    "dice.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 予測例の可視化\n",
    "x, y = next(iter(val_ds))\n",
    "y_pred = swi(x)\n",
    "segment = y_pred.argmax(-1).astype(np.uint8)\n",
    "\n",
    "print(f\"Input shape: {x.shape}\")\n",
    "print(f\"Prediction shape: {segment.shape}\")\n",
    "print(f\"Unique classes: {np.unique(segment)}\")\n",
    "\n",
    "plot_sample(x, segment, sample_idx=0, max_slices=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習曲線\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "if 'val_loss' in history.history:\n",
    "    plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['dice'], label='Train Dice')\n",
    "if 'val_dice' in history.history:\n",
    "    plt.plot(history.history['val_dice'], label='Val Dice')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice Score')\n",
    "plt.title('Dice Score')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終モデルの保存\n",
    "model.save_weights(\"final_model.weights.h5\")\n",
    "print(\"Model saved to final_model.weights.h5\")\n",
    "print(f\"Best Dice Score: {dice_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}